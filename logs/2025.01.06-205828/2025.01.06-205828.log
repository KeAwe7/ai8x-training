2025-01-06 20:58:28,735 - Log file for this run: C:\Users\ADMIN\Desktop\AweFiles\ai8x-training\logs\2025.01.06-205828\2025.01.06-205828.log
2025-01-06 20:58:28,735 - Configuring device: MAX78000, simulate=False.
2025-01-06 20:58:29,452 - 
2025-01-06 20:58:29,452 - --------------------------------------------------------
2025-01-06 20:58:29,452 - Logging to TensorBoard - remember to execute the server:
2025-01-06 20:58:29,452 - > tensorboard --logdir='./logs'
2025-01-06 20:58:29,452 - 
2025-01-06 20:58:30,112 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2025-01-06 20:58:30,114 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None}
2025-01-06 20:58:46,446 - 
2025-01-06 20:58:46,477 - Processing train...
2025-01-06 20:58:46,527 - train set: 87199 elements
2025-01-06 20:58:53,317 - validation set: 15219 elements
2025-01-06 20:58:53,544 - Filtering out _silence_ elements...
2025-01-06 20:58:56,423 - Remaining train set: 87181 elements
2025-01-06 20:58:57,742 - Remaining validation set: 15217 elements
2025-01-06 20:58:57,760 - Class up (# 32): 3455 elements
2025-01-06 20:58:57,764 - Class down (# 6): 25 elements
2025-01-06 20:58:57,764 - Class left (# 16): 4037 elements
2025-01-06 20:58:57,764 - Class right (# 24): 3619 elements
2025-01-06 20:58:57,764 - Class stop (# 28): 24 elements
2025-01-06 20:58:57,764 - Class go (# 12): 3272 elements
2025-01-06 20:58:57,768 - Class yes (# 35): 5094 elements
2025-01-06 20:58:57,768 - Class no (# 20): 8815 elements
2025-01-06 20:58:57,769 - Class on (# 22): 8527 elements
2025-01-06 20:58:57,770 - Class off (# 21): 4316 elements
2025-01-06 20:58:57,770 - Class one (# 23): 4183 elements
2025-01-06 20:58:57,771 - Class two (# 31): 4614 elements
2025-01-06 20:58:57,771 - Class three (# 29): 4296 elements
2025-01-06 20:58:57,772 - Class four (# 11): 4297 elements
2025-01-06 20:58:57,772 - Class five (# 8): 24 elements
2025-01-06 20:58:57,772 - Class six (# 27): 4442 elements
2025-01-06 20:58:57,773 - Class seven (# 25): 0 elements
2025-01-06 20:58:57,773 - Class eight (# 7): 24 elements
2025-01-06 20:58:57,773 - Class nine (# 19): 4623 elements
2025-01-06 20:58:57,773 - Class zero (# 36): 0 elements
2025-01-06 20:58:57,773 - Class _unknown_: 34711 elements
2025-01-06 20:59:49,860 - 
2025-01-06 20:59:49,875 - Processing test...
2025-01-06 20:59:49,938 - test set: 359 elements
2025-01-06 20:59:54,942 - Filtering out _silence_ elements...
2025-01-06 20:59:54,998 - Remaining test set: 358 elements
2025-01-06 20:59:55,002 - Class up (# 32): 34 elements
2025-01-06 20:59:55,003 - Class down (# 6): 0 elements
2025-01-06 20:59:55,003 - Class left (# 16): 23 elements
2025-01-06 20:59:55,003 - Class right (# 24): 2 elements
2025-01-06 20:59:55,004 - Class stop (# 28): 0 elements
2025-01-06 20:59:55,004 - Class go (# 12): 25 elements
2025-01-06 20:59:55,004 - Class yes (# 35): 23 elements
2025-01-06 20:59:55,005 - Class no (# 20): 12 elements
2025-01-06 20:59:55,005 - Class on (# 22): 12 elements
2025-01-06 20:59:55,005 - Class off (# 21): 14 elements
2025-01-06 20:59:55,005 - Class one (# 23): 4 elements
2025-01-06 20:59:55,006 - Class two (# 31): 16 elements
2025-01-06 20:59:55,006 - Class three (# 29): 14 elements
2025-01-06 20:59:55,006 - Class four (# 11): 14 elements
2025-01-06 20:59:55,007 - Class five (# 8): 0 elements
2025-01-06 20:59:55,007 - Class six (# 27): 15 elements
2025-01-06 20:59:55,008 - Class seven (# 25): 0 elements
2025-01-06 20:59:55,008 - Class eight (# 7): 0 elements
2025-01-06 20:59:55,008 - Class nine (# 19): 21 elements
2025-01-06 20:59:55,008 - Class zero (# 36): 0 elements
2025-01-06 20:59:55,010 - Class _unknown_: 129 elements
2025-01-06 20:59:55,244 - Reading compression schedule from: policies/schedule_kws20.yaml
2025-01-06 20:59:56,621 - torch.compile() successful, mode=default, cache limit=8
2025-01-06 20:59:56,621 - Dataset sizes:
	training=87181
	validation=15217
	test=358
2025-01-06 20:59:56,621 - 

2025-01-06 20:59:56,621 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:00:13,953 - Epoch: [0][   10/  341]    Overall Loss 2.800135    Objective Loss 2.800135                                        LR 0.001000    Time 1.733214    
2025-01-06 21:00:14,207 - Epoch: [0][   20/  341]    Overall Loss 2.724572    Objective Loss 2.724572                                        LR 0.001000    Time 0.879263    
2025-01-06 21:00:14,443 - Epoch: [0][   30/  341]    Overall Loss 2.699468    Objective Loss 2.699468                                        LR 0.001000    Time 0.593989    
2025-01-06 21:00:14,872 - Epoch: [0][   40/  341]    Overall Loss 2.686752    Objective Loss 2.686752                                        LR 0.001000    Time 0.456230    
2025-01-06 21:00:15,120 - Epoch: [0][   50/  341]    Overall Loss 2.676633    Objective Loss 2.676633                                        LR 0.001000    Time 0.369938    
2025-01-06 21:00:15,386 - Epoch: [0][   60/  341]    Overall Loss 2.668535    Objective Loss 2.668535                                        LR 0.001000    Time 0.312709    
2025-01-06 21:00:15,748 - Epoch: [0][   70/  341]    Overall Loss 2.665315    Objective Loss 2.665315                                        LR 0.001000    Time 0.273210    
2025-01-06 21:00:15,998 - Epoch: [0][   80/  341]    Overall Loss 2.662626    Objective Loss 2.662626                                        LR 0.001000    Time 0.242076    
2025-01-06 21:00:16,243 - Epoch: [0][   90/  341]    Overall Loss 2.661278    Objective Loss 2.661278                                        LR 0.001000    Time 0.217893    
2025-01-06 21:00:16,499 - Epoch: [0][  100/  341]    Overall Loss 2.658960    Objective Loss 2.658960                                        LR 0.001000    Time 0.198664    
2025-01-06 21:00:16,775 - Epoch: [0][  110/  341]    Overall Loss 2.657734    Objective Loss 2.657734                                        LR 0.001000    Time 0.183110    
2025-01-06 21:00:17,013 - Epoch: [0][  120/  341]    Overall Loss 2.656835    Objective Loss 2.656835                                        LR 0.001000    Time 0.169838    
2025-01-06 21:00:17,244 - Epoch: [0][  130/  341]    Overall Loss 2.655160    Objective Loss 2.655160                                        LR 0.001000    Time 0.158543    
2025-01-06 21:00:17,480 - Epoch: [0][  140/  341]    Overall Loss 2.652593    Objective Loss 2.652593                                        LR 0.001000    Time 0.148902    
2025-01-06 21:00:17,723 - Epoch: [0][  150/  341]    Overall Loss 2.650565    Objective Loss 2.650565                                        LR 0.001000    Time 0.140594    
2025-01-06 21:00:17,980 - Epoch: [0][  160/  341]    Overall Loss 2.649192    Objective Loss 2.649192                                        LR 0.001000    Time 0.133415    
2025-01-06 21:00:18,222 - Epoch: [0][  170/  341]    Overall Loss 2.647996    Objective Loss 2.647996                                        LR 0.001000    Time 0.126991    
2025-01-06 21:00:18,457 - Epoch: [0][  180/  341]    Overall Loss 2.647313    Objective Loss 2.647313                                        LR 0.001000    Time 0.121228    
2025-01-06 21:00:18,715 - Epoch: [0][  190/  341]    Overall Loss 2.646946    Objective Loss 2.646946                                        LR 0.001000    Time 0.116209    
2025-01-06 21:00:19,002 - Epoch: [0][  200/  341]    Overall Loss 2.646423    Objective Loss 2.646423                                        LR 0.001000    Time 0.111814    
2025-01-06 21:00:19,269 - Epoch: [0][  210/  341]    Overall Loss 2.645355    Objective Loss 2.645355                                        LR 0.001000    Time 0.107751    
2025-01-06 21:00:19,552 - Epoch: [0][  220/  341]    Overall Loss 2.644355    Objective Loss 2.644355                                        LR 0.001000    Time 0.104142    
2025-01-06 21:00:19,786 - Epoch: [0][  230/  341]    Overall Loss 2.644098    Objective Loss 2.644098                                        LR 0.001000    Time 0.100633    
2025-01-06 21:00:20,049 - Epoch: [0][  240/  341]    Overall Loss 2.644025    Objective Loss 2.644025                                        LR 0.001000    Time 0.097504    
2025-01-06 21:00:20,302 - Epoch: [0][  250/  341]    Overall Loss 2.642820    Objective Loss 2.642820                                        LR 0.001000    Time 0.094615    
2025-01-06 21:00:20,550 - Epoch: [0][  260/  341]    Overall Loss 2.642725    Objective Loss 2.642725                                        LR 0.001000    Time 0.091925    
2025-01-06 21:00:20,785 - Epoch: [0][  270/  341]    Overall Loss 2.642490    Objective Loss 2.642490                                        LR 0.001000    Time 0.089380    
2025-01-06 21:00:21,017 - Epoch: [0][  280/  341]    Overall Loss 2.642244    Objective Loss 2.642244                                        LR 0.001000    Time 0.087020    
2025-01-06 21:00:21,363 - Epoch: [0][  290/  341]    Overall Loss 2.642526    Objective Loss 2.642526                                        LR 0.001000    Time 0.085209    
2025-01-06 21:00:21,589 - Epoch: [0][  300/  341]    Overall Loss 2.642581    Objective Loss 2.642581                                        LR 0.001000    Time 0.083123    
2025-01-06 21:00:21,822 - Epoch: [0][  310/  341]    Overall Loss 2.642040    Objective Loss 2.642040                                        LR 0.001000    Time 0.081192    
2025-01-06 21:00:22,037 - Epoch: [0][  320/  341]    Overall Loss 2.642171    Objective Loss 2.642171                                        LR 0.001000    Time 0.079327    
2025-01-06 21:00:22,535 - Epoch: [0][  330/  341]    Overall Loss 2.642716    Objective Loss 2.642716                                        LR 0.001000    Time 0.078432    
2025-01-06 21:00:26,849 - Epoch: [0][  340/  341]    Overall Loss 2.642323    Objective Loss 2.642323    Top1 8.593750    Top5 35.546875    LR 0.001000    Time 0.088814    
2025-01-06 21:00:31,404 - Epoch: [0][  341/  341]    Overall Loss 2.642220    Objective Loss 2.642220    Top1 8.564232    Top5 35.768262    LR 0.001000    Time 0.101909    
2025-01-06 21:00:33,400 - --- validate (epoch=0)-----------
2025-01-06 21:00:33,400 - 15217 samples (256 per mini-batch)
2025-01-06 21:00:48,683 - Epoch: [0][   10/   60]    Loss 3.084156    Top1 0.039062    Top5 0.546875    
2025-01-06 21:00:48,892 - Epoch: [0][   20/   60]    Loss 3.086744    Top1 0.039062    Top5 0.429687    
2025-01-06 21:00:49,124 - Epoch: [0][   30/   60]    Loss 3.085574    Top1 0.078125    Top5 0.481771    
2025-01-06 21:00:49,338 - Epoch: [0][   40/   60]    Loss 3.085945    Top1 0.078125    Top5 0.439453    
2025-01-06 21:00:49,554 - Epoch: [0][   50/   60]    Loss 3.086518    Top1 0.062500    Top5 0.437500    
2025-01-06 21:00:49,805 - Epoch: [0][   60/   60]    Loss 3.087326    Top1 0.072288    Top5 0.460012    
2025-01-06 21:00:51,482 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.087

2025-01-06 21:00:51,488 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:00:52,038 - ==> Best [Top1: 0.072   Top5: 0.460   Params: 126490 on epoch: 0]
2025-01-06 21:00:52,038 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:00:52,115 - 

2025-01-06 21:00:52,115 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:01:00,757 - Epoch: [1][   10/  341]    Overall Loss 2.620761    Objective Loss 2.620761                                        LR 0.001000    Time 0.864183    
2025-01-06 21:01:01,002 - Epoch: [1][   20/  341]    Overall Loss 2.625439    Objective Loss 2.625439                                        LR 0.001000    Time 0.444240    
2025-01-06 21:01:01,268 - Epoch: [1][   30/  341]    Overall Loss 2.621072    Objective Loss 2.621072                                        LR 0.001000    Time 0.304975    
2025-01-06 21:01:01,501 - Epoch: [1][   40/  341]    Overall Loss 2.628808    Objective Loss 2.628808                                        LR 0.001000    Time 0.234552    
2025-01-06 21:01:01,743 - Epoch: [1][   50/  341]    Overall Loss 2.627556    Objective Loss 2.627556                                        LR 0.001000    Time 0.192474    
2025-01-06 21:01:01,978 - Epoch: [1][   60/  341]    Overall Loss 2.631526    Objective Loss 2.631526                                        LR 0.001000    Time 0.164310    
2025-01-06 21:01:02,234 - Epoch: [1][   70/  341]    Overall Loss 2.631895    Objective Loss 2.631895                                        LR 0.001000    Time 0.144500    
2025-01-06 21:01:02,474 - Epoch: [1][   80/  341]    Overall Loss 2.631743    Objective Loss 2.631743                                        LR 0.001000    Time 0.129376    
2025-01-06 21:01:02,707 - Epoch: [1][   90/  341]    Overall Loss 2.630976    Objective Loss 2.630976                                        LR 0.001000    Time 0.117550    
2025-01-06 21:01:02,938 - Epoch: [1][  100/  341]    Overall Loss 2.631697    Objective Loss 2.631697                                        LR 0.001000    Time 0.108102    
2025-01-06 21:01:03,183 - Epoch: [1][  110/  341]    Overall Loss 2.631464    Objective Loss 2.631464                                        LR 0.001000    Time 0.100503    
2025-01-06 21:01:03,427 - Epoch: [1][  120/  341]    Overall Loss 2.631679    Objective Loss 2.631679                                        LR 0.001000    Time 0.094162    
2025-01-06 21:01:03,667 - Epoch: [1][  130/  341]    Overall Loss 2.631092    Objective Loss 2.631092                                        LR 0.001000    Time 0.088764    
2025-01-06 21:01:03,894 - Epoch: [1][  140/  341]    Overall Loss 2.630526    Objective Loss 2.630526                                        LR 0.001000    Time 0.084047    
2025-01-06 21:01:04,157 - Epoch: [1][  150/  341]    Overall Loss 2.631585    Objective Loss 2.631585                                        LR 0.001000    Time 0.080124    
2025-01-06 21:01:04,403 - Epoch: [1][  160/  341]    Overall Loss 2.630727    Objective Loss 2.630727                                        LR 0.001000    Time 0.076654    
2025-01-06 21:01:04,644 - Epoch: [1][  170/  341]    Overall Loss 2.631064    Objective Loss 2.631064                                        LR 0.001000    Time 0.073567    
2025-01-06 21:01:04,877 - Epoch: [1][  180/  341]    Overall Loss 2.630294    Objective Loss 2.630294                                        LR 0.001000    Time 0.070770    
2025-01-06 21:01:05,129 - Epoch: [1][  190/  341]    Overall Loss 2.631735    Objective Loss 2.631735                                        LR 0.001000    Time 0.068372    
2025-01-06 21:01:05,376 - Epoch: [1][  200/  341]    Overall Loss 2.632239    Objective Loss 2.632239                                        LR 0.001000    Time 0.066191    
2025-01-06 21:01:05,720 - Epoch: [1][  210/  341]    Overall Loss 2.632209    Objective Loss 2.632209                                        LR 0.001000    Time 0.064677    
2025-01-06 21:01:06,018 - Epoch: [1][  220/  341]    Overall Loss 2.632324    Objective Loss 2.632324                                        LR 0.001000    Time 0.063054    
2025-01-06 21:01:06,250 - Epoch: [1][  230/  341]    Overall Loss 2.631794    Objective Loss 2.631794                                        LR 0.001000    Time 0.061323    
2025-01-06 21:01:06,491 - Epoch: [1][  240/  341]    Overall Loss 2.631900    Objective Loss 2.631900                                        LR 0.001000    Time 0.059769    
2025-01-06 21:01:06,725 - Epoch: [1][  250/  341]    Overall Loss 2.631556    Objective Loss 2.631556                                        LR 0.001000    Time 0.058315    
2025-01-06 21:01:06,959 - Epoch: [1][  260/  341]    Overall Loss 2.631375    Objective Loss 2.631375                                        LR 0.001000    Time 0.056973    
2025-01-06 21:01:07,201 - Epoch: [1][  270/  341]    Overall Loss 2.631050    Objective Loss 2.631050                                        LR 0.001000    Time 0.055761    
2025-01-06 21:01:07,440 - Epoch: [1][  280/  341]    Overall Loss 2.631588    Objective Loss 2.631588                                        LR 0.001000    Time 0.054621    
2025-01-06 21:01:07,664 - Epoch: [1][  290/  341]    Overall Loss 2.632190    Objective Loss 2.632190                                        LR 0.001000    Time 0.053512    
2025-01-06 21:01:07,903 - Epoch: [1][  300/  341]    Overall Loss 2.632385    Objective Loss 2.632385                                        LR 0.001000    Time 0.052525    
2025-01-06 21:01:08,143 - Epoch: [1][  310/  341]    Overall Loss 2.632827    Objective Loss 2.632827                                        LR 0.001000    Time 0.051602    
2025-01-06 21:01:08,383 - Epoch: [1][  320/  341]    Overall Loss 2.633017    Objective Loss 2.633017                                        LR 0.001000    Time 0.050741    
2025-01-06 21:01:08,663 - Epoch: [1][  330/  341]    Overall Loss 2.633186    Objective Loss 2.633186                                        LR 0.001000    Time 0.050051    
2025-01-06 21:01:08,958 - Epoch: [1][  340/  341]    Overall Loss 2.633273    Objective Loss 2.633273    Top1 10.546875    Top5 38.281250    LR 0.001000    Time 0.049446    
2025-01-06 21:01:08,982 - Epoch: [1][  341/  341]    Overall Loss 2.633365    Objective Loss 2.633365    Top1 9.068010    Top5 37.531486    LR 0.001000    Time 0.049372    
2025-01-06 21:01:10,955 - --- validate (epoch=1)-----------
2025-01-06 21:01:10,957 - 15217 samples (256 per mini-batch)
2025-01-06 21:01:19,894 - Epoch: [1][   10/   60]    Loss 3.192505    Top1 0.078125    Top5 0.429687    
2025-01-06 21:01:20,097 - Epoch: [1][   20/   60]    Loss 3.193567    Top1 0.039062    Top5 0.390625    
2025-01-06 21:01:20,314 - Epoch: [1][   30/   60]    Loss 3.192796    Top1 0.065104    Top5 0.403646    
2025-01-06 21:01:20,532 - Epoch: [1][   40/   60]    Loss 3.191513    Top1 0.058594    Top5 0.458984    
2025-01-06 21:01:20,736 - Epoch: [1][   50/   60]    Loss 3.192907    Top1 0.062500    Top5 0.437500    
2025-01-06 21:01:20,920 - Epoch: [1][   60/   60]    Loss 3.192367    Top1 0.072288    Top5 0.460012    
2025-01-06 21:01:22,578 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.192

2025-01-06 21:01:22,581 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:01:23,379 - ==> Best [Top1: 0.072   Top5: 0.460   Params: 126490 on epoch: 1]
2025-01-06 21:01:23,379 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:01:23,423 - 

2025-01-06 21:01:23,425 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:01:32,158 - Epoch: [2][   10/  341]    Overall Loss 2.629605    Objective Loss 2.629605                                        LR 0.001000    Time 0.873189    
2025-01-06 21:01:32,399 - Epoch: [2][   20/  341]    Overall Loss 2.627637    Objective Loss 2.627637                                        LR 0.001000    Time 0.448607    
2025-01-06 21:01:32,636 - Epoch: [2][   30/  341]    Overall Loss 2.634356    Objective Loss 2.634356                                        LR 0.001000    Time 0.306880    
2025-01-06 21:01:32,884 - Epoch: [2][   40/  341]    Overall Loss 2.630248    Objective Loss 2.630248                                        LR 0.001000    Time 0.236376    
2025-01-06 21:01:33,123 - Epoch: [2][   50/  341]    Overall Loss 2.630108    Objective Loss 2.630108                                        LR 0.001000    Time 0.193875    
2025-01-06 21:01:33,376 - Epoch: [2][   60/  341]    Overall Loss 2.630413    Objective Loss 2.630413                                        LR 0.001000    Time 0.165784    
2025-01-06 21:01:33,621 - Epoch: [2][   70/  341]    Overall Loss 2.632784    Objective Loss 2.632784                                        LR 0.001000    Time 0.145595    
2025-01-06 21:01:33,858 - Epoch: [2][   80/  341]    Overall Loss 2.631653    Objective Loss 2.631653                                        LR 0.001000    Time 0.130355    
2025-01-06 21:01:34,097 - Epoch: [2][   90/  341]    Overall Loss 2.632157    Objective Loss 2.632157                                        LR 0.001000    Time 0.118535    
2025-01-06 21:01:34,342 - Epoch: [2][  100/  341]    Overall Loss 2.631920    Objective Loss 2.631920                                        LR 0.001000    Time 0.109130    
2025-01-06 21:01:34,582 - Epoch: [2][  110/  341]    Overall Loss 2.635041    Objective Loss 2.635041                                        LR 0.001000    Time 0.101386    
2025-01-06 21:01:34,826 - Epoch: [2][  120/  341]    Overall Loss 2.634752    Objective Loss 2.634752                                        LR 0.001000    Time 0.094971    
2025-01-06 21:01:35,062 - Epoch: [2][  130/  341]    Overall Loss 2.634192    Objective Loss 2.634192                                        LR 0.001000    Time 0.089483    
2025-01-06 21:01:35,306 - Epoch: [2][  140/  341]    Overall Loss 2.632983    Objective Loss 2.632983                                        LR 0.001000    Time 0.084836    
2025-01-06 21:01:35,538 - Epoch: [2][  150/  341]    Overall Loss 2.634146    Objective Loss 2.634146                                        LR 0.001000    Time 0.080723    
2025-01-06 21:01:35,778 - Epoch: [2][  160/  341]    Overall Loss 2.634409    Objective Loss 2.634409                                        LR 0.001000    Time 0.077117    
2025-01-06 21:01:36,010 - Epoch: [2][  170/  341]    Overall Loss 2.633103    Objective Loss 2.633103                                        LR 0.001000    Time 0.073942    
2025-01-06 21:01:36,252 - Epoch: [2][  180/  341]    Overall Loss 2.634289    Objective Loss 2.634289                                        LR 0.001000    Time 0.071182    
2025-01-06 21:01:36,497 - Epoch: [2][  190/  341]    Overall Loss 2.634703    Objective Loss 2.634703                                        LR 0.001000    Time 0.068722    
2025-01-06 21:01:36,743 - Epoch: [2][  200/  341]    Overall Loss 2.634565    Objective Loss 2.634565                                        LR 0.001000    Time 0.066514    
2025-01-06 21:01:36,986 - Epoch: [2][  210/  341]    Overall Loss 2.633792    Objective Loss 2.633792                                        LR 0.001000    Time 0.064506    
2025-01-06 21:01:37,217 - Epoch: [2][  220/  341]    Overall Loss 2.634136    Objective Loss 2.634136                                        LR 0.001000    Time 0.062626    
2025-01-06 21:01:37,450 - Epoch: [2][  230/  341]    Overall Loss 2.633515    Objective Loss 2.633515                                        LR 0.001000    Time 0.060916    
2025-01-06 21:01:37,694 - Epoch: [2][  240/  341]    Overall Loss 2.633196    Objective Loss 2.633196                                        LR 0.001000    Time 0.059392    
2025-01-06 21:01:37,927 - Epoch: [2][  250/  341]    Overall Loss 2.632566    Objective Loss 2.632566                                        LR 0.001000    Time 0.057948    
2025-01-06 21:01:38,166 - Epoch: [2][  260/  341]    Overall Loss 2.633263    Objective Loss 2.633263                                        LR 0.001000    Time 0.056642    
2025-01-06 21:01:38,410 - Epoch: [2][  270/  341]    Overall Loss 2.632352    Objective Loss 2.632352                                        LR 0.001000    Time 0.055447    
2025-01-06 21:01:38,670 - Epoch: [2][  280/  341]    Overall Loss 2.632437    Objective Loss 2.632437                                        LR 0.001000    Time 0.054394    
2025-01-06 21:01:38,959 - Epoch: [2][  290/  341]    Overall Loss 2.631951    Objective Loss 2.631951                                        LR 0.001000    Time 0.053514    
2025-01-06 21:01:39,273 - Epoch: [2][  300/  341]    Overall Loss 2.631136    Objective Loss 2.631136                                        LR 0.001000    Time 0.052777    
2025-01-06 21:01:39,580 - Epoch: [2][  310/  341]    Overall Loss 2.630818    Objective Loss 2.630818                                        LR 0.001000    Time 0.052066    
2025-01-06 21:01:39,816 - Epoch: [2][  320/  341]    Overall Loss 2.631288    Objective Loss 2.631288                                        LR 0.001000    Time 0.051175    
2025-01-06 21:01:40,045 - Epoch: [2][  330/  341]    Overall Loss 2.631042    Objective Loss 2.631042                                        LR 0.001000    Time 0.050320    
2025-01-06 21:01:40,305 - Epoch: [2][  340/  341]    Overall Loss 2.631565    Objective Loss 2.631565    Top1 9.375000    Top5 33.984375    LR 0.001000    Time 0.049604    
2025-01-06 21:01:40,334 - Epoch: [2][  341/  341]    Overall Loss 2.631679    Objective Loss 2.631679    Top1 9.068010    Top5 34.256927    LR 0.001000    Time 0.049542    
2025-01-06 21:01:42,301 - --- validate (epoch=2)-----------
2025-01-06 21:01:42,301 - 15217 samples (256 per mini-batch)
2025-01-06 21:01:51,095 - Epoch: [2][   10/   60]    Loss 3.164677    Top1 0.078125    Top5 0.390625    
2025-01-06 21:01:51,320 - Epoch: [2][   20/   60]    Loss 3.166043    Top1 0.058594    Top5 0.390625    
2025-01-06 21:01:51,524 - Epoch: [2][   30/   60]    Loss 3.163305    Top1 0.065104    Top5 0.416667    
2025-01-06 21:01:51,719 - Epoch: [2][   40/   60]    Loss 3.161683    Top1 0.078125    Top5 0.478516    
2025-01-06 21:01:51,936 - Epoch: [2][   50/   60]    Loss 3.161391    Top1 0.085937    Top5 0.476562    
2025-01-06 21:01:52,109 - Epoch: [2][   60/   60]    Loss 3.162341    Top1 0.072288    Top5 0.460012    
2025-01-06 21:01:53,638 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.162

2025-01-06 21:01:53,638 - ==> Confusion:
[[   0    0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:01:54,329 - ==> Best [Top1: 0.072   Top5: 0.460   Params: 126490 on epoch: 2]
2025-01-06 21:01:54,330 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:01:54,360 - 

2025-01-06 21:01:54,364 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:02:02,958 - Epoch: [3][   10/  341]    Overall Loss 2.652942    Objective Loss 2.652942                                        LR 0.001000    Time 0.859277    
2025-01-06 21:02:03,185 - Epoch: [3][   20/  341]    Overall Loss 2.641000    Objective Loss 2.641000                                        LR 0.001000    Time 0.440896    
2025-01-06 21:02:03,445 - Epoch: [3][   30/  341]    Overall Loss 2.640196    Objective Loss 2.640196                                        LR 0.001000    Time 0.302630    
2025-01-06 21:02:03,688 - Epoch: [3][   40/  341]    Overall Loss 2.640247    Objective Loss 2.640247                                        LR 0.001000    Time 0.233025    
2025-01-06 21:02:03,916 - Epoch: [3][   50/  341]    Overall Loss 2.639072    Objective Loss 2.639072                                        LR 0.001000    Time 0.190997    
2025-01-06 21:02:04,156 - Epoch: [3][   60/  341]    Overall Loss 2.639385    Objective Loss 2.639385                                        LR 0.001000    Time 0.163161    
2025-01-06 21:02:04,410 - Epoch: [3][   70/  341]    Overall Loss 2.635319    Objective Loss 2.635319                                        LR 0.001000    Time 0.143460    
2025-01-06 21:02:04,651 - Epoch: [3][   80/  341]    Overall Loss 2.632270    Objective Loss 2.632270                                        LR 0.001000    Time 0.128547    
2025-01-06 21:02:04,890 - Epoch: [3][   90/  341]    Overall Loss 2.633077    Objective Loss 2.633077                                        LR 0.001000    Time 0.116899    
2025-01-06 21:02:05,122 - Epoch: [3][  100/  341]    Overall Loss 2.632554    Objective Loss 2.632554                                        LR 0.001000    Time 0.107529    
2025-01-06 21:02:05,361 - Epoch: [3][  110/  341]    Overall Loss 2.630835    Objective Loss 2.630835                                        LR 0.001000    Time 0.099926    
2025-01-06 21:02:05,597 - Epoch: [3][  120/  341]    Overall Loss 2.631187    Objective Loss 2.631187                                        LR 0.001000    Time 0.093562    
2025-01-06 21:02:05,836 - Epoch: [3][  130/  341]    Overall Loss 2.630654    Objective Loss 2.630654                                        LR 0.001000    Time 0.088207    
2025-01-06 21:02:06,075 - Epoch: [3][  140/  341]    Overall Loss 2.630577    Objective Loss 2.630577                                        LR 0.001000    Time 0.083611    
2025-01-06 21:02:06,310 - Epoch: [3][  150/  341]    Overall Loss 2.630115    Objective Loss 2.630115                                        LR 0.001000    Time 0.079607    
2025-01-06 21:02:06,554 - Epoch: [3][  160/  341]    Overall Loss 2.630970    Objective Loss 2.630970                                        LR 0.001000    Time 0.076155    
2025-01-06 21:02:06,774 - Epoch: [3][  170/  341]    Overall Loss 2.630256    Objective Loss 2.630256                                        LR 0.001000    Time 0.072971    
2025-01-06 21:02:07,015 - Epoch: [3][  180/  341]    Overall Loss 2.630157    Objective Loss 2.630157                                        LR 0.001000    Time 0.070256    
2025-01-06 21:02:07,247 - Epoch: [3][  190/  341]    Overall Loss 2.630753    Objective Loss 2.630753                                        LR 0.001000    Time 0.067779    
2025-01-06 21:02:07,483 - Epoch: [3][  200/  341]    Overall Loss 2.630567    Objective Loss 2.630567                                        LR 0.001000    Time 0.065570    
2025-01-06 21:02:07,721 - Epoch: [3][  210/  341]    Overall Loss 2.630104    Objective Loss 2.630104                                        LR 0.001000    Time 0.063569    
2025-01-06 21:02:07,957 - Epoch: [3][  220/  341]    Overall Loss 2.629366    Objective Loss 2.629366                                        LR 0.001000    Time 0.061754    
2025-01-06 21:02:08,186 - Epoch: [3][  230/  341]    Overall Loss 2.629740    Objective Loss 2.629740                                        LR 0.001000    Time 0.060064    
2025-01-06 21:02:08,442 - Epoch: [3][  240/  341]    Overall Loss 2.629807    Objective Loss 2.629807                                        LR 0.001000    Time 0.058625    
2025-01-06 21:02:08,683 - Epoch: [3][  250/  341]    Overall Loss 2.630281    Objective Loss 2.630281                                        LR 0.001000    Time 0.057245    
2025-01-06 21:02:08,914 - Epoch: [3][  260/  341]    Overall Loss 2.630306    Objective Loss 2.630306                                        LR 0.001000    Time 0.055933    
2025-01-06 21:02:09,156 - Epoch: [3][  270/  341]    Overall Loss 2.630495    Objective Loss 2.630495                                        LR 0.001000    Time 0.054721    
2025-01-06 21:02:09,402 - Epoch: [3][  280/  341]    Overall Loss 2.630383    Objective Loss 2.630383                                        LR 0.001000    Time 0.053645    
2025-01-06 21:02:09,644 - Epoch: [3][  290/  341]    Overall Loss 2.630224    Objective Loss 2.630224                                        LR 0.001000    Time 0.052628    
2025-01-06 21:02:09,871 - Epoch: [3][  300/  341]    Overall Loss 2.629940    Objective Loss 2.629940                                        LR 0.001000    Time 0.051624    
2025-01-06 21:02:10,110 - Epoch: [3][  310/  341]    Overall Loss 2.629851    Objective Loss 2.629851                                        LR 0.001000    Time 0.050698    
2025-01-06 21:02:10,346 - Epoch: [3][  320/  341]    Overall Loss 2.630358    Objective Loss 2.630358                                        LR 0.001000    Time 0.049852    
2025-01-06 21:02:10,585 - Epoch: [3][  330/  341]    Overall Loss 2.630456    Objective Loss 2.630456                                        LR 0.001000    Time 0.049057    
2025-01-06 21:02:10,844 - Epoch: [3][  340/  341]    Overall Loss 2.630400    Objective Loss 2.630400    Top1 11.718750    Top5 37.109375    LR 0.001000    Time 0.048378    
2025-01-06 21:02:10,863 - Epoch: [3][  341/  341]    Overall Loss 2.630508    Objective Loss 2.630508    Top1 10.831234    Top5 35.516373    LR 0.001000    Time 0.048291    
2025-01-06 21:02:12,530 - --- validate (epoch=3)-----------
2025-01-06 21:02:12,530 - 15217 samples (256 per mini-batch)
2025-01-06 21:02:21,293 - Epoch: [3][   10/   60]    Loss 3.051283    Top1 0.078125    Top5 0.742188    
2025-01-06 21:02:21,516 - Epoch: [3][   20/   60]    Loss 3.053454    Top1 0.078125    Top5 0.546875    
2025-01-06 21:02:21,729 - Epoch: [3][   30/   60]    Loss 3.055133    Top1 0.052083    Top5 0.533854    
2025-01-06 21:02:21,932 - Epoch: [3][   40/   60]    Loss 3.055548    Top1 0.078125    Top5 0.507813    
2025-01-06 21:02:22,144 - Epoch: [3][   50/   60]    Loss 3.055967    Top1 0.085937    Top5 0.492187    
2025-01-06 21:02:22,319 - Epoch: [3][   60/   60]    Loss 3.056679    Top1 0.072288    Top5 0.473155    
2025-01-06 21:02:23,823 - ==> Top1: 0.072    Top5: 0.473    Loss: 3.057

2025-01-06 21:02:23,823 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:02:24,296 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:02:24,302 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:02:24,333 - 

2025-01-06 21:02:24,333 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:02:32,948 - Epoch: [4][   10/  341]    Overall Loss 2.641511    Objective Loss 2.641511                                        LR 0.001000    Time 0.861509    
2025-01-06 21:02:33,176 - Epoch: [4][   20/  341]    Overall Loss 2.633880    Objective Loss 2.633880                                        LR 0.001000    Time 0.442145    
2025-01-06 21:02:33,417 - Epoch: [4][   30/  341]    Overall Loss 2.634661    Objective Loss 2.634661                                        LR 0.001000    Time 0.302820    
2025-01-06 21:02:33,668 - Epoch: [4][   40/  341]    Overall Loss 2.635896    Objective Loss 2.635896                                        LR 0.001000    Time 0.233389    
2025-01-06 21:02:33,900 - Epoch: [4][   50/  341]    Overall Loss 2.636440    Objective Loss 2.636440                                        LR 0.001000    Time 0.191337    
2025-01-06 21:02:34,134 - Epoch: [4][   60/  341]    Overall Loss 2.633779    Objective Loss 2.633779                                        LR 0.001000    Time 0.163357    
2025-01-06 21:02:34,369 - Epoch: [4][   70/  341]    Overall Loss 2.632197    Objective Loss 2.632197                                        LR 0.001000    Time 0.143378    
2025-01-06 21:02:34,617 - Epoch: [4][   80/  341]    Overall Loss 2.631698    Objective Loss 2.631698                                        LR 0.001000    Time 0.128557    
2025-01-06 21:02:34,848 - Epoch: [4][   90/  341]    Overall Loss 2.631567    Objective Loss 2.631567                                        LR 0.001000    Time 0.116831    
2025-01-06 21:02:35,084 - Epoch: [4][  100/  341]    Overall Loss 2.630811    Objective Loss 2.630811                                        LR 0.001000    Time 0.107516    
2025-01-06 21:02:35,324 - Epoch: [4][  110/  341]    Overall Loss 2.631406    Objective Loss 2.631406                                        LR 0.001000    Time 0.099919    
2025-01-06 21:02:35,560 - Epoch: [4][  120/  341]    Overall Loss 2.631941    Objective Loss 2.631941                                        LR 0.001000    Time 0.093563    
2025-01-06 21:02:35,805 - Epoch: [4][  130/  341]    Overall Loss 2.631826    Objective Loss 2.631826                                        LR 0.001000    Time 0.088251    
2025-01-06 21:02:36,029 - Epoch: [4][  140/  341]    Overall Loss 2.631871    Objective Loss 2.631871                                        LR 0.001000    Time 0.083547    
2025-01-06 21:02:36,272 - Epoch: [4][  150/  341]    Overall Loss 2.630940    Objective Loss 2.630940                                        LR 0.001000    Time 0.079526    
2025-01-06 21:02:36,504 - Epoch: [4][  160/  341]    Overall Loss 2.630830    Objective Loss 2.630830                                        LR 0.001000    Time 0.076006    
2025-01-06 21:02:36,749 - Epoch: [4][  170/  341]    Overall Loss 2.630460    Objective Loss 2.630460                                        LR 0.001000    Time 0.072975    
2025-01-06 21:02:36,983 - Epoch: [4][  180/  341]    Overall Loss 2.629233    Objective Loss 2.629233                                        LR 0.001000    Time 0.070224    
2025-01-06 21:02:37,211 - Epoch: [4][  190/  341]    Overall Loss 2.628925    Objective Loss 2.628925                                        LR 0.001000    Time 0.067724    
2025-01-06 21:02:37,457 - Epoch: [4][  200/  341]    Overall Loss 2.629156    Objective Loss 2.629156                                        LR 0.001000    Time 0.065519    
2025-01-06 21:02:37,705 - Epoch: [4][  210/  341]    Overall Loss 2.629717    Objective Loss 2.629717                                        LR 0.001000    Time 0.063569    
2025-01-06 21:02:37,940 - Epoch: [4][  220/  341]    Overall Loss 2.629947    Objective Loss 2.629947                                        LR 0.001000    Time 0.061750    
2025-01-06 21:02:38,179 - Epoch: [4][  230/  341]    Overall Loss 2.629514    Objective Loss 2.629514                                        LR 0.001000    Time 0.060103    
2025-01-06 21:02:38,422 - Epoch: [4][  240/  341]    Overall Loss 2.629307    Objective Loss 2.629307                                        LR 0.001000    Time 0.058569    
2025-01-06 21:02:38,665 - Epoch: [4][  250/  341]    Overall Loss 2.629512    Objective Loss 2.629512                                        LR 0.001000    Time 0.057197    
2025-01-06 21:02:38,894 - Epoch: [4][  260/  341]    Overall Loss 2.629677    Objective Loss 2.629677                                        LR 0.001000    Time 0.055872    
2025-01-06 21:02:39,136 - Epoch: [4][  270/  341]    Overall Loss 2.629812    Objective Loss 2.629812                                        LR 0.001000    Time 0.054661    
2025-01-06 21:02:39,367 - Epoch: [4][  280/  341]    Overall Loss 2.630093    Objective Loss 2.630093                                        LR 0.001000    Time 0.053533    
2025-01-06 21:02:39,603 - Epoch: [4][  290/  341]    Overall Loss 2.630818    Objective Loss 2.630818                                        LR 0.001000    Time 0.052500    
2025-01-06 21:02:39,826 - Epoch: [4][  300/  341]    Overall Loss 2.630781    Objective Loss 2.630781                                        LR 0.001000    Time 0.051496    
2025-01-06 21:02:40,057 - Epoch: [4][  310/  341]    Overall Loss 2.631196    Objective Loss 2.631196                                        LR 0.001000    Time 0.050579    
2025-01-06 21:02:40,289 - Epoch: [4][  320/  341]    Overall Loss 2.630675    Objective Loss 2.630675                                        LR 0.001000    Time 0.049723    
2025-01-06 21:02:40,536 - Epoch: [4][  330/  341]    Overall Loss 2.630847    Objective Loss 2.630847                                        LR 0.001000    Time 0.048964    
2025-01-06 21:02:40,788 - Epoch: [4][  340/  341]    Overall Loss 2.630629    Objective Loss 2.630629    Top1 10.546875    Top5 39.062500    LR 0.001000    Time 0.048266    
2025-01-06 21:02:40,815 - Epoch: [4][  341/  341]    Overall Loss 2.630651    Objective Loss 2.630651    Top1 10.075567    Top5 38.035264    LR 0.001000    Time 0.048202    
2025-01-06 21:02:42,707 - --- validate (epoch=4)-----------
2025-01-06 21:02:42,707 - 15217 samples (256 per mini-batch)
2025-01-06 21:02:51,606 - Epoch: [4][   10/   60]    Loss 3.164671    Top1 0.039062    Top5 0.546875    
2025-01-06 21:02:51,806 - Epoch: [4][   20/   60]    Loss 3.164916    Top1 0.058594    Top5 0.468750    
2025-01-06 21:02:52,018 - Epoch: [4][   30/   60]    Loss 3.164397    Top1 0.052083    Top5 0.507813    
2025-01-06 21:02:52,238 - Epoch: [4][   40/   60]    Loss 3.163513    Top1 0.058594    Top5 0.498047    
2025-01-06 21:02:52,441 - Epoch: [4][   50/   60]    Loss 3.164292    Top1 0.070313    Top5 0.468750    
2025-01-06 21:02:52,625 - Epoch: [4][   60/   60]    Loss 3.164216    Top1 0.072288    Top5 0.460012    
2025-01-06 21:02:54,120 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.164

2025-01-06 21:02:54,120 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:02:54,572 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:02:54,572 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:02:54,591 - 

2025-01-06 21:02:54,593 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:03:03,345 - Epoch: [5][   10/  341]    Overall Loss 2.645125    Objective Loss 2.645125                                        LR 0.001000    Time 0.875184    
2025-01-06 21:03:03,570 - Epoch: [5][   20/  341]    Overall Loss 2.637072    Objective Loss 2.637072                                        LR 0.001000    Time 0.448729    
2025-01-06 21:03:03,824 - Epoch: [5][   30/  341]    Overall Loss 2.629789    Objective Loss 2.629789                                        LR 0.001000    Time 0.307636    
2025-01-06 21:03:04,068 - Epoch: [5][   40/  341]    Overall Loss 2.632399    Objective Loss 2.632399                                        LR 0.001000    Time 0.236571    
2025-01-06 21:03:04,304 - Epoch: [5][   50/  341]    Overall Loss 2.631310    Objective Loss 2.631310                                        LR 0.001000    Time 0.193983    
2025-01-06 21:03:04,535 - Epoch: [5][   60/  341]    Overall Loss 2.631816    Objective Loss 2.631816                                        LR 0.001000    Time 0.165466    
2025-01-06 21:03:04,774 - Epoch: [5][   70/  341]    Overall Loss 2.631349    Objective Loss 2.631349                                        LR 0.001000    Time 0.145241    
2025-01-06 21:03:04,992 - Epoch: [5][   80/  341]    Overall Loss 2.632762    Objective Loss 2.632762                                        LR 0.001000    Time 0.129809    
2025-01-06 21:03:05,232 - Epoch: [5][   90/  341]    Overall Loss 2.633129    Objective Loss 2.633129                                        LR 0.001000    Time 0.117941    
2025-01-06 21:03:05,466 - Epoch: [5][  100/  341]    Overall Loss 2.631743    Objective Loss 2.631743                                        LR 0.001000    Time 0.108467    
2025-01-06 21:03:05,702 - Epoch: [5][  110/  341]    Overall Loss 2.631421    Objective Loss 2.631421                                        LR 0.001000    Time 0.100755    
2025-01-06 21:03:05,930 - Epoch: [5][  120/  341]    Overall Loss 2.631811    Objective Loss 2.631811                                        LR 0.001000    Time 0.094252    
2025-01-06 21:03:06,164 - Epoch: [5][  130/  341]    Overall Loss 2.632522    Objective Loss 2.632522                                        LR 0.001000    Time 0.088792    
2025-01-06 21:03:06,389 - Epoch: [5][  140/  341]    Overall Loss 2.632588    Objective Loss 2.632588                                        LR 0.001000    Time 0.084057    
2025-01-06 21:03:06,674 - Epoch: [5][  150/  341]    Overall Loss 2.631484    Objective Loss 2.631484                                        LR 0.001000    Time 0.080351    
2025-01-06 21:03:06,909 - Epoch: [5][  160/  341]    Overall Loss 2.630637    Objective Loss 2.630637                                        LR 0.001000    Time 0.076785    
2025-01-06 21:03:07,150 - Epoch: [5][  170/  341]    Overall Loss 2.629838    Objective Loss 2.629838                                        LR 0.001000    Time 0.073684    
2025-01-06 21:03:07,385 - Epoch: [5][  180/  341]    Overall Loss 2.629843    Objective Loss 2.629843                                        LR 0.001000    Time 0.070852    
2025-01-06 21:03:07,633 - Epoch: [5][  190/  341]    Overall Loss 2.629612    Objective Loss 2.629612                                        LR 0.001000    Time 0.068419    
2025-01-06 21:03:07,867 - Epoch: [5][  200/  341]    Overall Loss 2.630050    Objective Loss 2.630050                                        LR 0.001000    Time 0.066165    
2025-01-06 21:03:08,107 - Epoch: [5][  210/  341]    Overall Loss 2.630305    Objective Loss 2.630305                                        LR 0.001000    Time 0.064159    
2025-01-06 21:03:08,334 - Epoch: [5][  220/  341]    Overall Loss 2.630454    Objective Loss 2.630454                                        LR 0.001000    Time 0.062274    
2025-01-06 21:03:08,573 - Epoch: [5][  230/  341]    Overall Loss 2.631155    Objective Loss 2.631155                                        LR 0.001000    Time 0.060596    
2025-01-06 21:03:08,813 - Epoch: [5][  240/  341]    Overall Loss 2.631157    Objective Loss 2.631157                                        LR 0.001000    Time 0.059073    
2025-01-06 21:03:09,050 - Epoch: [5][  250/  341]    Overall Loss 2.630856    Objective Loss 2.630856                                        LR 0.001000    Time 0.057657    
2025-01-06 21:03:09,278 - Epoch: [5][  260/  341]    Overall Loss 2.630327    Objective Loss 2.630327                                        LR 0.001000    Time 0.056319    
2025-01-06 21:03:09,513 - Epoch: [5][  270/  341]    Overall Loss 2.629975    Objective Loss 2.629975                                        LR 0.001000    Time 0.055102    
2025-01-06 21:03:09,757 - Epoch: [5][  280/  341]    Overall Loss 2.630400    Objective Loss 2.630400                                        LR 0.001000    Time 0.054005    
2025-01-06 21:03:10,005 - Epoch: [5][  290/  341]    Overall Loss 2.630280    Objective Loss 2.630280                                        LR 0.001000    Time 0.052992    
2025-01-06 21:03:10,239 - Epoch: [5][  300/  341]    Overall Loss 2.630790    Objective Loss 2.630790                                        LR 0.001000    Time 0.052006    
2025-01-06 21:03:10,461 - Epoch: [5][  310/  341]    Overall Loss 2.630591    Objective Loss 2.630591                                        LR 0.001000    Time 0.051042    
2025-01-06 21:03:10,691 - Epoch: [5][  320/  341]    Overall Loss 2.630369    Objective Loss 2.630369                                        LR 0.001000    Time 0.050143    
2025-01-06 21:03:10,930 - Epoch: [5][  330/  341]    Overall Loss 2.630542    Objective Loss 2.630542                                        LR 0.001000    Time 0.049316    
2025-01-06 21:03:11,180 - Epoch: [5][  340/  341]    Overall Loss 2.630818    Objective Loss 2.630818    Top1 8.593750    Top5 40.234375    LR 0.001000    Time 0.048601    
2025-01-06 21:03:11,201 - Epoch: [5][  341/  341]    Overall Loss 2.630856    Objective Loss 2.630856    Top1 8.312343    Top5 38.539043    LR 0.001000    Time 0.048518    
2025-01-06 21:03:12,913 - --- validate (epoch=5)-----------
2025-01-06 21:03:12,913 - 15217 samples (256 per mini-batch)
2025-01-06 21:03:21,128 - Epoch: [5][   10/   60]    Loss 3.084837    Top1 0.000000    Top5 0.585938    
2025-01-06 21:03:21,362 - Epoch: [5][   20/   60]    Loss 3.083547    Top1 0.019531    Top5 0.585938    
2025-01-06 21:03:21,559 - Epoch: [5][   30/   60]    Loss 3.083434    Top1 0.078125    Top5 0.546875    
2025-01-06 21:03:21,762 - Epoch: [5][   40/   60]    Loss 3.084876    Top1 0.068359    Top5 0.478516    
2025-01-06 21:03:21,978 - Epoch: [5][   50/   60]    Loss 3.085426    Top1 0.062500    Top5 0.484375    
2025-01-06 21:03:22,150 - Epoch: [5][   60/   60]    Loss 3.085889    Top1 0.072288    Top5 0.460012    
2025-01-06 21:03:23,769 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.086

2025-01-06 21:03:23,769 - ==> Confusion:
[[   0    0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:03:24,226 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:03:24,226 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:03:24,244 - 

2025-01-06 21:03:24,244 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:03:32,907 - Epoch: [6][   10/  341]    Overall Loss 2.633089    Objective Loss 2.633089                                        LR 0.001000    Time 0.866256    
2025-01-06 21:03:33,148 - Epoch: [6][   20/  341]    Overall Loss 2.630486    Objective Loss 2.630486                                        LR 0.001000    Time 0.445082    
2025-01-06 21:03:33,377 - Epoch: [6][   30/  341]    Overall Loss 2.629151    Objective Loss 2.629151                                        LR 0.001000    Time 0.304358    
2025-01-06 21:03:33,625 - Epoch: [6][   40/  341]    Overall Loss 2.630601    Objective Loss 2.630601                                        LR 0.001000    Time 0.234467    
2025-01-06 21:03:33,859 - Epoch: [6][   50/  341]    Overall Loss 2.629503    Objective Loss 2.629503                                        LR 0.001000    Time 0.192268    
2025-01-06 21:03:34,091 - Epoch: [6][   60/  341]    Overall Loss 2.630195    Objective Loss 2.630195                                        LR 0.001000    Time 0.164078    
2025-01-06 21:03:34,311 - Epoch: [6][   70/  341]    Overall Loss 2.629958    Objective Loss 2.629958                                        LR 0.001000    Time 0.143787    
2025-01-06 21:03:34,545 - Epoch: [6][   80/  341]    Overall Loss 2.630592    Objective Loss 2.630592                                        LR 0.001000    Time 0.128733    
2025-01-06 21:03:34,797 - Epoch: [6][   90/  341]    Overall Loss 2.629869    Objective Loss 2.629869                                        LR 0.001000    Time 0.117210    
2025-01-06 21:03:35,021 - Epoch: [6][  100/  341]    Overall Loss 2.630510    Objective Loss 2.630510                                        LR 0.001000    Time 0.107734    
2025-01-06 21:03:35,261 - Epoch: [6][  110/  341]    Overall Loss 2.628819    Objective Loss 2.628819                                        LR 0.001000    Time 0.100122    
2025-01-06 21:03:35,484 - Epoch: [6][  120/  341]    Overall Loss 2.628774    Objective Loss 2.628774                                        LR 0.001000    Time 0.093635    
2025-01-06 21:03:35,726 - Epoch: [6][  130/  341]    Overall Loss 2.628898    Objective Loss 2.628898                                        LR 0.001000    Time 0.088291    
2025-01-06 21:03:35,964 - Epoch: [6][  140/  341]    Overall Loss 2.628404    Objective Loss 2.628404                                        LR 0.001000    Time 0.083687    
2025-01-06 21:03:36,193 - Epoch: [6][  150/  341]    Overall Loss 2.629039    Objective Loss 2.629039                                        LR 0.001000    Time 0.079620    
2025-01-06 21:03:36,425 - Epoch: [6][  160/  341]    Overall Loss 2.628854    Objective Loss 2.628854                                        LR 0.001000    Time 0.076094    
2025-01-06 21:03:36,663 - Epoch: [6][  170/  341]    Overall Loss 2.629058    Objective Loss 2.629058                                        LR 0.001000    Time 0.073017    
2025-01-06 21:03:36,895 - Epoch: [6][  180/  341]    Overall Loss 2.629766    Objective Loss 2.629766                                        LR 0.001000    Time 0.070251    
2025-01-06 21:03:37,129 - Epoch: [6][  190/  341]    Overall Loss 2.630019    Objective Loss 2.630019                                        LR 0.001000    Time 0.067786    
2025-01-06 21:03:37,352 - Epoch: [6][  200/  341]    Overall Loss 2.629356    Objective Loss 2.629356                                        LR 0.001000    Time 0.065512    
2025-01-06 21:03:37,597 - Epoch: [6][  210/  341]    Overall Loss 2.629548    Objective Loss 2.629548                                        LR 0.001000    Time 0.063559    
2025-01-06 21:03:37,837 - Epoch: [6][  220/  341]    Overall Loss 2.629186    Objective Loss 2.629186                                        LR 0.001000    Time 0.061761    
2025-01-06 21:03:38,069 - Epoch: [6][  230/  341]    Overall Loss 2.629436    Objective Loss 2.629436                                        LR 0.001000    Time 0.060082    
2025-01-06 21:03:38,310 - Epoch: [6][  240/  341]    Overall Loss 2.629298    Objective Loss 2.629298                                        LR 0.001000    Time 0.058584    
2025-01-06 21:03:38,542 - Epoch: [6][  250/  341]    Overall Loss 2.628962    Objective Loss 2.628962                                        LR 0.001000    Time 0.057169    
2025-01-06 21:03:38,782 - Epoch: [6][  260/  341]    Overall Loss 2.628238    Objective Loss 2.628238                                        LR 0.001000    Time 0.055891    
2025-01-06 21:03:39,024 - Epoch: [6][  270/  341]    Overall Loss 2.628031    Objective Loss 2.628031                                        LR 0.001000    Time 0.054718    
2025-01-06 21:03:39,264 - Epoch: [6][  280/  341]    Overall Loss 2.628029    Objective Loss 2.628029                                        LR 0.001000    Time 0.053622    
2025-01-06 21:03:39,505 - Epoch: [6][  290/  341]    Overall Loss 2.628173    Objective Loss 2.628173                                        LR 0.001000    Time 0.052605    
2025-01-06 21:03:39,734 - Epoch: [6][  300/  341]    Overall Loss 2.628342    Objective Loss 2.628342                                        LR 0.001000    Time 0.051613    
2025-01-06 21:03:39,971 - Epoch: [6][  310/  341]    Overall Loss 2.628987    Objective Loss 2.628987                                        LR 0.001000    Time 0.050695    
2025-01-06 21:03:40,191 - Epoch: [6][  320/  341]    Overall Loss 2.630085    Objective Loss 2.630085                                        LR 0.001000    Time 0.049798    
2025-01-06 21:03:40,428 - Epoch: [6][  330/  341]    Overall Loss 2.630083    Objective Loss 2.630083                                        LR 0.001000    Time 0.049007    
2025-01-06 21:03:40,685 - Epoch: [6][  340/  341]    Overall Loss 2.630393    Objective Loss 2.630393    Top1 9.765625    Top5 36.718750    LR 0.001000    Time 0.048321    
2025-01-06 21:03:40,705 - Epoch: [6][  341/  341]    Overall Loss 2.630421    Objective Loss 2.630421    Top1 9.823678    Top5 36.775819    LR 0.001000    Time 0.048238    
2025-01-06 21:03:42,674 - --- validate (epoch=6)-----------
2025-01-06 21:03:42,674 - 15217 samples (256 per mini-batch)
2025-01-06 21:03:51,225 - Epoch: [6][   10/   60]    Loss 3.048311    Top1 0.117188    Top5 0.507813    
2025-01-06 21:03:51,431 - Epoch: [6][   20/   60]    Loss 3.048128    Top1 0.078125    Top5 0.488281    
2025-01-06 21:03:51,648 - Epoch: [6][   30/   60]    Loss 3.049033    Top1 0.091146    Top5 0.442708    
2025-01-06 21:03:51,870 - Epoch: [6][   40/   60]    Loss 3.049068    Top1 0.087891    Top5 0.439453    
2025-01-06 21:03:52,065 - Epoch: [6][   50/   60]    Loss 3.049589    Top1 0.078125    Top5 0.398438    
2025-01-06 21:03:52,234 - Epoch: [6][   60/   60]    Loss 3.049071    Top1 0.072288    Top5 0.400867    
2025-01-06 21:03:53,810 - ==> Top1: 0.072    Top5: 0.401    Loss: 3.049

2025-01-06 21:03:53,820 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:03:54,258 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:03:54,266 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:03:54,268 - 

2025-01-06 21:03:54,268 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:04:02,822 - Epoch: [7][   10/  341]    Overall Loss 2.625948    Objective Loss 2.625948                                        LR 0.001000    Time 0.854309    
2025-01-06 21:04:03,051 - Epoch: [7][   20/  341]    Overall Loss 2.626406    Objective Loss 2.626406                                        LR 0.001000    Time 0.438609    
2025-01-06 21:04:03,289 - Epoch: [7][   30/  341]    Overall Loss 2.627467    Objective Loss 2.627467                                        LR 0.001000    Time 0.300326    
2025-01-06 21:04:03,522 - Epoch: [7][   40/  341]    Overall Loss 2.628099    Objective Loss 2.628099                                        LR 0.001000    Time 0.231079    
2025-01-06 21:04:03,761 - Epoch: [7][   50/  341]    Overall Loss 2.633017    Objective Loss 2.633017                                        LR 0.001000    Time 0.189645    
2025-01-06 21:04:04,000 - Epoch: [7][   60/  341]    Overall Loss 2.632793    Objective Loss 2.632793                                        LR 0.001000    Time 0.162008    
2025-01-06 21:04:04,227 - Epoch: [7][   70/  341]    Overall Loss 2.634339    Objective Loss 2.634339                                        LR 0.001000    Time 0.142110    
2025-01-06 21:04:04,457 - Epoch: [7][   80/  341]    Overall Loss 2.635372    Objective Loss 2.635372                                        LR 0.001000    Time 0.127224    
2025-01-06 21:04:04,697 - Epoch: [7][   90/  341]    Overall Loss 2.633647    Objective Loss 2.633647                                        LR 0.001000    Time 0.115752    
2025-01-06 21:04:04,926 - Epoch: [7][  100/  341]    Overall Loss 2.632072    Objective Loss 2.632072                                        LR 0.001000    Time 0.106473    
2025-01-06 21:04:05,156 - Epoch: [7][  110/  341]    Overall Loss 2.631558    Objective Loss 2.631558                                        LR 0.001000    Time 0.098858    
2025-01-06 21:04:05,375 - Epoch: [7][  120/  341]    Overall Loss 2.631385    Objective Loss 2.631385                                        LR 0.001000    Time 0.092441    
2025-01-06 21:04:05,618 - Epoch: [7][  130/  341]    Overall Loss 2.631460    Objective Loss 2.631460                                        LR 0.001000    Time 0.087205    
2025-01-06 21:04:05,860 - Epoch: [7][  140/  341]    Overall Loss 2.630513    Objective Loss 2.630513                                        LR 0.001000    Time 0.082700    
2025-01-06 21:04:06,090 - Epoch: [7][  150/  341]    Overall Loss 2.629421    Objective Loss 2.629421                                        LR 0.001000    Time 0.078723    
2025-01-06 21:04:06,325 - Epoch: [7][  160/  341]    Overall Loss 2.629607    Objective Loss 2.629607                                        LR 0.001000    Time 0.075273    
2025-01-06 21:04:06,562 - Epoch: [7][  170/  341]    Overall Loss 2.629369    Objective Loss 2.629369                                        LR 0.001000    Time 0.072237    
2025-01-06 21:04:06,814 - Epoch: [7][  180/  341]    Overall Loss 2.629088    Objective Loss 2.629088                                        LR 0.001000    Time 0.069623    
2025-01-06 21:04:07,044 - Epoch: [7][  190/  341]    Overall Loss 2.629157    Objective Loss 2.629157                                        LR 0.001000    Time 0.067171    
2025-01-06 21:04:07,274 - Epoch: [7][  200/  341]    Overall Loss 2.629132    Objective Loss 2.629132                                        LR 0.001000    Time 0.064958    
2025-01-06 21:04:07,494 - Epoch: [7][  210/  341]    Overall Loss 2.629917    Objective Loss 2.629917                                        LR 0.001000    Time 0.062909    
2025-01-06 21:04:07,735 - Epoch: [7][  220/  341]    Overall Loss 2.629988    Objective Loss 2.629988                                        LR 0.001000    Time 0.061147    
2025-01-06 21:04:07,977 - Epoch: [7][  230/  341]    Overall Loss 2.630011    Objective Loss 2.630011                                        LR 0.001000    Time 0.059541    
2025-01-06 21:04:08,202 - Epoch: [7][  240/  341]    Overall Loss 2.629191    Objective Loss 2.629191                                        LR 0.001000    Time 0.057999    
2025-01-06 21:04:08,443 - Epoch: [7][  250/  341]    Overall Loss 2.628801    Objective Loss 2.628801                                        LR 0.001000    Time 0.056641    
2025-01-06 21:04:08,679 - Epoch: [7][  260/  341]    Overall Loss 2.629023    Objective Loss 2.629023                                        LR 0.001000    Time 0.055371    
2025-01-06 21:04:08,921 - Epoch: [7][  270/  341]    Overall Loss 2.629069    Objective Loss 2.629069                                        LR 0.001000    Time 0.054214    
2025-01-06 21:04:09,153 - Epoch: [7][  280/  341]    Overall Loss 2.629701    Objective Loss 2.629701                                        LR 0.001000    Time 0.053107    
2025-01-06 21:04:09,379 - Epoch: [7][  290/  341]    Overall Loss 2.629956    Objective Loss 2.629956                                        LR 0.001000    Time 0.052058    
2025-01-06 21:04:09,612 - Epoch: [7][  300/  341]    Overall Loss 2.629594    Objective Loss 2.629594                                        LR 0.001000    Time 0.051098    
2025-01-06 21:04:09,858 - Epoch: [7][  310/  341]    Overall Loss 2.629538    Objective Loss 2.629538                                        LR 0.001000    Time 0.050242    
2025-01-06 21:04:10,098 - Epoch: [7][  320/  341]    Overall Loss 2.629119    Objective Loss 2.629119                                        LR 0.001000    Time 0.049423    
2025-01-06 21:04:10,331 - Epoch: [7][  330/  341]    Overall Loss 2.629263    Objective Loss 2.629263                                        LR 0.001000    Time 0.048630    
2025-01-06 21:04:10,586 - Epoch: [7][  340/  341]    Overall Loss 2.629923    Objective Loss 2.629923    Top1 7.031250    Top5 32.812500    LR 0.001000    Time 0.047950    
2025-01-06 21:04:10,603 - Epoch: [7][  341/  341]    Overall Loss 2.629684    Objective Loss 2.629684    Top1 9.319899    Top5 35.768262    LR 0.001000    Time 0.047861    
2025-01-06 21:04:12,158 - --- validate (epoch=7)-----------
2025-01-06 21:04:12,158 - 15217 samples (256 per mini-batch)
2025-01-06 21:04:20,644 - Epoch: [7][   10/   60]    Loss 3.165803    Top1 0.117188    Top5 0.429687    
2025-01-06 21:04:20,858 - Epoch: [7][   20/   60]    Loss 3.164827    Top1 0.078125    Top5 0.390625    
2025-01-06 21:04:21,071 - Epoch: [7][   30/   60]    Loss 3.166315    Top1 0.065104    Top5 0.442708    
2025-01-06 21:04:21,271 - Epoch: [7][   40/   60]    Loss 3.166293    Top1 0.078125    Top5 0.439453    
2025-01-06 21:04:21,505 - Epoch: [7][   50/   60]    Loss 3.166559    Top1 0.070313    Top5 0.414063    
2025-01-06 21:04:21,682 - Epoch: [7][   60/   60]    Loss 3.165961    Top1 0.072288    Top5 0.460012    
2025-01-06 21:04:23,172 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.166

2025-01-06 21:04:23,172 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:04:23,626 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:04:23,626 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:04:23,642 - 

2025-01-06 21:04:23,642 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:04:32,113 - Epoch: [8][   10/  341]    Overall Loss 2.602921    Objective Loss 2.602921                                        LR 0.001000    Time 0.846880    
2025-01-06 21:04:32,345 - Epoch: [8][   20/  341]    Overall Loss 2.611133    Objective Loss 2.611133                                        LR 0.001000    Time 0.435083    
2025-01-06 21:04:32,585 - Epoch: [8][   30/  341]    Overall Loss 2.616041    Objective Loss 2.616041                                        LR 0.001000    Time 0.298055    
2025-01-06 21:04:32,833 - Epoch: [8][   40/  341]    Overall Loss 2.617377    Objective Loss 2.617377                                        LR 0.001000    Time 0.229719    
2025-01-06 21:04:33,062 - Epoch: [8][   50/  341]    Overall Loss 2.615651    Objective Loss 2.615651                                        LR 0.001000    Time 0.188361    
2025-01-06 21:04:33,300 - Epoch: [8][   60/  341]    Overall Loss 2.619729    Objective Loss 2.619729                                        LR 0.001000    Time 0.160936    
2025-01-06 21:04:33,536 - Epoch: [8][   70/  341]    Overall Loss 2.622060    Objective Loss 2.622060                                        LR 0.001000    Time 0.141296    
2025-01-06 21:04:33,772 - Epoch: [8][   80/  341]    Overall Loss 2.621698    Objective Loss 2.621698                                        LR 0.001000    Time 0.126590    
2025-01-06 21:04:34,007 - Epoch: [8][   90/  341]    Overall Loss 2.620048    Objective Loss 2.620048                                        LR 0.001000    Time 0.115132    
2025-01-06 21:04:34,233 - Epoch: [8][  100/  341]    Overall Loss 2.620846    Objective Loss 2.620846                                        LR 0.001000    Time 0.105878    
2025-01-06 21:04:34,474 - Epoch: [8][  110/  341]    Overall Loss 2.622365    Objective Loss 2.622365                                        LR 0.001000    Time 0.098443    
2025-01-06 21:04:34,716 - Epoch: [8][  120/  341]    Overall Loss 2.623753    Objective Loss 2.623753                                        LR 0.001000    Time 0.092258    
2025-01-06 21:04:34,946 - Epoch: [8][  130/  341]    Overall Loss 2.624264    Objective Loss 2.624264                                        LR 0.001000    Time 0.086935    
2025-01-06 21:04:35,171 - Epoch: [8][  140/  341]    Overall Loss 2.624808    Objective Loss 2.624808                                        LR 0.001000    Time 0.082331    
2025-01-06 21:04:35,414 - Epoch: [8][  150/  341]    Overall Loss 2.625942    Objective Loss 2.625942                                        LR 0.001000    Time 0.078390    
2025-01-06 21:04:35,653 - Epoch: [8][  160/  341]    Overall Loss 2.626230    Objective Loss 2.626230                                        LR 0.001000    Time 0.074980    
2025-01-06 21:04:35,889 - Epoch: [8][  170/  341]    Overall Loss 2.625250    Objective Loss 2.625250                                        LR 0.001000    Time 0.071961    
2025-01-06 21:04:36,123 - Epoch: [8][  180/  341]    Overall Loss 2.626332    Objective Loss 2.626332                                        LR 0.001000    Time 0.069203    
2025-01-06 21:04:36,359 - Epoch: [8][  190/  341]    Overall Loss 2.625658    Objective Loss 2.625658                                        LR 0.001000    Time 0.066751    
2025-01-06 21:04:36,592 - Epoch: [8][  200/  341]    Overall Loss 2.626215    Objective Loss 2.626215                                        LR 0.001000    Time 0.064578    
2025-01-06 21:04:36,844 - Epoch: [8][  210/  341]    Overall Loss 2.626943    Objective Loss 2.626943                                        LR 0.001000    Time 0.062655    
2025-01-06 21:04:37,081 - Epoch: [8][  220/  341]    Overall Loss 2.627655    Objective Loss 2.627655                                        LR 0.001000    Time 0.060879    
2025-01-06 21:04:37,322 - Epoch: [8][  230/  341]    Overall Loss 2.627478    Objective Loss 2.627478                                        LR 0.001000    Time 0.059280    
2025-01-06 21:04:37,562 - Epoch: [8][  240/  341]    Overall Loss 2.628007    Objective Loss 2.628007                                        LR 0.001000    Time 0.057807    
2025-01-06 21:04:37,816 - Epoch: [8][  250/  341]    Overall Loss 2.627970    Objective Loss 2.627970                                        LR 0.001000    Time 0.056504    
2025-01-06 21:04:38,039 - Epoch: [8][  260/  341]    Overall Loss 2.627737    Objective Loss 2.627737                                        LR 0.001000    Time 0.055188    
2025-01-06 21:04:38,286 - Epoch: [8][  270/  341]    Overall Loss 2.628167    Objective Loss 2.628167                                        LR 0.001000    Time 0.054058    
2025-01-06 21:04:38,519 - Epoch: [8][  280/  341]    Overall Loss 2.628226    Objective Loss 2.628226                                        LR 0.001000    Time 0.052960    
2025-01-06 21:04:38,767 - Epoch: [8][  290/  341]    Overall Loss 2.628834    Objective Loss 2.628834                                        LR 0.001000    Time 0.051990    
2025-01-06 21:04:39,010 - Epoch: [8][  300/  341]    Overall Loss 2.629445    Objective Loss 2.629445                                        LR 0.001000    Time 0.051068    
2025-01-06 21:04:39,244 - Epoch: [8][  310/  341]    Overall Loss 2.629755    Objective Loss 2.629755                                        LR 0.001000    Time 0.050174    
2025-01-06 21:04:39,476 - Epoch: [8][  320/  341]    Overall Loss 2.629663    Objective Loss 2.629663                                        LR 0.001000    Time 0.049331    
2025-01-06 21:04:39,710 - Epoch: [8][  330/  341]    Overall Loss 2.629176    Objective Loss 2.629176                                        LR 0.001000    Time 0.048544    
2025-01-06 21:04:39,964 - Epoch: [8][  340/  341]    Overall Loss 2.629532    Objective Loss 2.629532    Top1 11.718750    Top5 37.500000    LR 0.001000    Time 0.047862    
2025-01-06 21:04:39,981 - Epoch: [8][  341/  341]    Overall Loss 2.629664    Objective Loss 2.629664    Top1 10.327456    Top5 34.256927    LR 0.001000    Time 0.047771    
2025-01-06 21:04:41,658 - --- validate (epoch=8)-----------
2025-01-06 21:04:41,658 - 15217 samples (256 per mini-batch)
2025-01-06 21:04:50,262 - Epoch: [8][   10/   60]    Loss 3.131041    Top1 0.078125    Top5 0.273437    
2025-01-06 21:04:50,469 - Epoch: [8][   20/   60]    Loss 3.130321    Top1 0.039062    Top5 0.371094    
2025-01-06 21:04:50,685 - Epoch: [8][   30/   60]    Loss 3.128698    Top1 0.039062    Top5 0.442708    
2025-01-06 21:04:50,893 - Epoch: [8][   40/   60]    Loss 3.127920    Top1 0.039062    Top5 0.458984    
2025-01-06 21:04:51,095 - Epoch: [8][   50/   60]    Loss 3.128897    Top1 0.046875    Top5 0.429687    
2025-01-06 21:04:51,280 - Epoch: [8][   60/   60]    Loss 3.128353    Top1 0.072288    Top5 0.460012    
2025-01-06 21:04:52,776 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.128

2025-01-06 21:04:52,776 - ==> Confusion:
[[   0    0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:04:53,451 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:04:53,451 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:04:53,464 - 

2025-01-06 21:04:53,464 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:05:02,285 - Epoch: [9][   10/  341]    Overall Loss 2.631427    Objective Loss 2.631427                                        LR 0.001000    Time 0.882050    
2025-01-06 21:05:02,523 - Epoch: [9][   20/  341]    Overall Loss 2.628935    Objective Loss 2.628935                                        LR 0.001000    Time 0.452921    
2025-01-06 21:05:02,763 - Epoch: [9][   30/  341]    Overall Loss 2.628040    Objective Loss 2.628040                                        LR 0.001000    Time 0.309897    
2025-01-06 21:05:03,002 - Epoch: [9][   40/  341]    Overall Loss 2.622965    Objective Loss 2.622965                                        LR 0.001000    Time 0.238379    
2025-01-06 21:05:03,233 - Epoch: [9][   50/  341]    Overall Loss 2.620813    Objective Loss 2.620813                                        LR 0.001000    Time 0.195335    
2025-01-06 21:05:03,485 - Epoch: [9][   60/  341]    Overall Loss 2.623403    Objective Loss 2.623403                                        LR 0.001000    Time 0.166970    
2025-01-06 21:05:03,722 - Epoch: [9][   70/  341]    Overall Loss 2.622959    Objective Loss 2.622959                                        LR 0.001000    Time 0.146508    
2025-01-06 21:05:03,971 - Epoch: [9][   80/  341]    Overall Loss 2.625670    Objective Loss 2.625670                                        LR 0.001000    Time 0.131313    
2025-01-06 21:05:04,204 - Epoch: [9][   90/  341]    Overall Loss 2.623442    Objective Loss 2.623442                                        LR 0.001000    Time 0.119309    
2025-01-06 21:05:04,445 - Epoch: [9][  100/  341]    Overall Loss 2.622285    Objective Loss 2.622285                                        LR 0.001000    Time 0.109783    
2025-01-06 21:05:04,666 - Epoch: [9][  110/  341]    Overall Loss 2.623003    Objective Loss 2.623003                                        LR 0.001000    Time 0.101818    
2025-01-06 21:05:04,911 - Epoch: [9][  120/  341]    Overall Loss 2.624693    Objective Loss 2.624693                                        LR 0.001000    Time 0.095369    
2025-01-06 21:05:05,150 - Epoch: [9][  130/  341]    Overall Loss 2.625783    Objective Loss 2.625783                                        LR 0.001000    Time 0.089877    
2025-01-06 21:05:05,385 - Epoch: [9][  140/  341]    Overall Loss 2.626322    Objective Loss 2.626322                                        LR 0.001000    Time 0.085136    
2025-01-06 21:05:05,622 - Epoch: [9][  150/  341]    Overall Loss 2.628512    Objective Loss 2.628512                                        LR 0.001000    Time 0.081037    
2025-01-06 21:05:05,864 - Epoch: [9][  160/  341]    Overall Loss 2.630924    Objective Loss 2.630924                                        LR 0.001000    Time 0.077484    
2025-01-06 21:05:06,101 - Epoch: [9][  170/  341]    Overall Loss 2.631065    Objective Loss 2.631065                                        LR 0.001000    Time 0.074323    
2025-01-06 21:05:06,337 - Epoch: [9][  180/  341]    Overall Loss 2.630142    Objective Loss 2.630142                                        LR 0.001000    Time 0.071505    
2025-01-06 21:05:06,571 - Epoch: [9][  190/  341]    Overall Loss 2.629808    Objective Loss 2.629808                                        LR 0.001000    Time 0.068973    
2025-01-06 21:05:06,812 - Epoch: [9][  200/  341]    Overall Loss 2.629934    Objective Loss 2.629934                                        LR 0.001000    Time 0.066667    
2025-01-06 21:05:07,058 - Epoch: [9][  210/  341]    Overall Loss 2.629732    Objective Loss 2.629732                                        LR 0.001000    Time 0.064661    
2025-01-06 21:05:07,288 - Epoch: [9][  220/  341]    Overall Loss 2.629071    Objective Loss 2.629071                                        LR 0.001000    Time 0.062769    
2025-01-06 21:05:07,520 - Epoch: [9][  230/  341]    Overall Loss 2.629073    Objective Loss 2.629073                                        LR 0.001000    Time 0.061048    
2025-01-06 21:05:07,752 - Epoch: [9][  240/  341]    Overall Loss 2.628902    Objective Loss 2.628902                                        LR 0.001000    Time 0.059472    
2025-01-06 21:05:07,993 - Epoch: [9][  250/  341]    Overall Loss 2.628820    Objective Loss 2.628820                                        LR 0.001000    Time 0.058056    
2025-01-06 21:05:08,224 - Epoch: [9][  260/  341]    Overall Loss 2.628240    Objective Loss 2.628240                                        LR 0.001000    Time 0.056712    
2025-01-06 21:05:08,461 - Epoch: [9][  270/  341]    Overall Loss 2.627606    Objective Loss 2.627606                                        LR 0.001000    Time 0.055491    
2025-01-06 21:05:08,694 - Epoch: [9][  280/  341]    Overall Loss 2.627812    Objective Loss 2.627812                                        LR 0.001000    Time 0.054340    
2025-01-06 21:05:08,933 - Epoch: [9][  290/  341]    Overall Loss 2.627901    Objective Loss 2.627901                                        LR 0.001000    Time 0.053290    
2025-01-06 21:05:09,160 - Epoch: [9][  300/  341]    Overall Loss 2.628251    Objective Loss 2.628251                                        LR 0.001000    Time 0.052271    
2025-01-06 21:05:09,405 - Epoch: [9][  310/  341]    Overall Loss 2.629356    Objective Loss 2.629356                                        LR 0.001000    Time 0.051341    
2025-01-06 21:05:09,635 - Epoch: [9][  320/  341]    Overall Loss 2.629283    Objective Loss 2.629283                                        LR 0.001000    Time 0.050455    
2025-01-06 21:05:09,870 - Epoch: [9][  330/  341]    Overall Loss 2.629828    Objective Loss 2.629828                                        LR 0.001000    Time 0.049639    
2025-01-06 21:05:10,132 - Epoch: [9][  340/  341]    Overall Loss 2.629304    Objective Loss 2.629304    Top1 12.890625    Top5 36.328125    LR 0.001000    Time 0.048951    
2025-01-06 21:05:10,149 - Epoch: [9][  341/  341]    Overall Loss 2.629204    Objective Loss 2.629204    Top1 12.846348    Top5 37.027708    LR 0.001000    Time 0.048857    
2025-01-06 21:05:11,807 - --- validate (epoch=9)-----------
2025-01-06 21:05:11,807 - 15217 samples (256 per mini-batch)
2025-01-06 21:05:20,230 - Epoch: [9][   10/   60]    Loss 3.367765    Top1 0.000000    Top5 0.234375    
2025-01-06 21:05:20,440 - Epoch: [9][   20/   60]    Loss 3.363136    Top1 0.058594    Top5 0.332031    
2025-01-06 21:05:20,636 - Epoch: [9][   30/   60]    Loss 3.361263    Top1 0.065104    Top5 0.390625    
2025-01-06 21:05:20,858 - Epoch: [9][   40/   60]    Loss 3.360522    Top1 0.078125    Top5 0.429687    
2025-01-06 21:05:21,068 - Epoch: [9][   50/   60]    Loss 3.360716    Top1 0.062500    Top5 0.429687    
2025-01-06 21:05:21,277 - Epoch: [9][   60/   60]    Loss 3.359534    Top1 0.072288    Top5 0.460012    
2025-01-06 21:05:22,785 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.360

2025-01-06 21:05:22,785 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:05:23,441 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:05:23,445 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:05:23,453 - 

2025-01-06 21:05:23,453 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:05:31,897 - Epoch: [10][   10/  341]    Overall Loss 2.617495    Objective Loss 2.617495                                        LR 0.001000    Time 0.844342    
2025-01-06 21:05:32,155 - Epoch: [10][   20/  341]    Overall Loss 2.622785    Objective Loss 2.622785                                        LR 0.001000    Time 0.435086    
2025-01-06 21:05:32,383 - Epoch: [10][   30/  341]    Overall Loss 2.632312    Objective Loss 2.632312                                        LR 0.001000    Time 0.297601    
2025-01-06 21:05:32,627 - Epoch: [10][   40/  341]    Overall Loss 2.634138    Objective Loss 2.634138                                        LR 0.001000    Time 0.228897    
2025-01-06 21:05:32,895 - Epoch: [10][   50/  341]    Overall Loss 2.631431    Objective Loss 2.631431                                        LR 0.001000    Time 0.188272    
2025-01-06 21:05:33,139 - Epoch: [10][   60/  341]    Overall Loss 2.631986    Objective Loss 2.631986                                        LR 0.001000    Time 0.160948    
2025-01-06 21:05:33,384 - Epoch: [10][   70/  341]    Overall Loss 2.631764    Objective Loss 2.631764                                        LR 0.001000    Time 0.141448    
2025-01-06 21:05:33,607 - Epoch: [10][   80/  341]    Overall Loss 2.631958    Objective Loss 2.631958                                        LR 0.001000    Time 0.126558    
2025-01-06 21:05:33,843 - Epoch: [10][   90/  341]    Overall Loss 2.632132    Objective Loss 2.632132                                        LR 0.001000    Time 0.115103    
2025-01-06 21:05:34,092 - Epoch: [10][  100/  341]    Overall Loss 2.631568    Objective Loss 2.631568                                        LR 0.001000    Time 0.106082    
2025-01-06 21:05:34,331 - Epoch: [10][  110/  341]    Overall Loss 2.630648    Objective Loss 2.630648                                        LR 0.001000    Time 0.098613    
2025-01-06 21:05:34,560 - Epoch: [10][  120/  341]    Overall Loss 2.631000    Objective Loss 2.631000                                        LR 0.001000    Time 0.092307    
2025-01-06 21:05:34,787 - Epoch: [10][  130/  341]    Overall Loss 2.631943    Objective Loss 2.631943                                        LR 0.001000    Time 0.086946    
2025-01-06 21:05:35,037 - Epoch: [10][  140/  341]    Overall Loss 2.632232    Objective Loss 2.632232                                        LR 0.001000    Time 0.082525    
2025-01-06 21:05:35,269 - Epoch: [10][  150/  341]    Overall Loss 2.631646    Objective Loss 2.631646                                        LR 0.001000    Time 0.078570    
2025-01-06 21:05:35,502 - Epoch: [10][  160/  341]    Overall Loss 2.631137    Objective Loss 2.631137                                        LR 0.001000    Time 0.075118    
2025-01-06 21:05:35,738 - Epoch: [10][  170/  341]    Overall Loss 2.631252    Objective Loss 2.631252                                        LR 0.001000    Time 0.072087    
2025-01-06 21:05:35,988 - Epoch: [10][  180/  341]    Overall Loss 2.631015    Objective Loss 2.631015                                        LR 0.001000    Time 0.069469    
2025-01-06 21:05:36,231 - Epoch: [10][  190/  341]    Overall Loss 2.631049    Objective Loss 2.631049                                        LR 0.001000    Time 0.067092    
2025-01-06 21:05:36,474 - Epoch: [10][  200/  341]    Overall Loss 2.631027    Objective Loss 2.631027                                        LR 0.001000    Time 0.064951    
2025-01-06 21:05:36,697 - Epoch: [10][  210/  341]    Overall Loss 2.630957    Objective Loss 2.630957                                        LR 0.001000    Time 0.062922    
2025-01-06 21:05:36,945 - Epoch: [10][  220/  341]    Overall Loss 2.630482    Objective Loss 2.630482                                        LR 0.001000    Time 0.061190    
2025-01-06 21:05:37,188 - Epoch: [10][  230/  341]    Overall Loss 2.630294    Objective Loss 2.630294                                        LR 0.001000    Time 0.059586    
2025-01-06 21:05:37,428 - Epoch: [10][  240/  341]    Overall Loss 2.629884    Objective Loss 2.629884                                        LR 0.001000    Time 0.058085    
2025-01-06 21:05:37,662 - Epoch: [10][  250/  341]    Overall Loss 2.629744    Objective Loss 2.629744                                        LR 0.001000    Time 0.056694    
2025-01-06 21:05:37,894 - Epoch: [10][  260/  341]    Overall Loss 2.629636    Objective Loss 2.629636                                        LR 0.001000    Time 0.055409    
2025-01-06 21:05:38,140 - Epoch: [10][  270/  341]    Overall Loss 2.629924    Objective Loss 2.629924                                        LR 0.001000    Time 0.054266    
2025-01-06 21:05:38,364 - Epoch: [10][  280/  341]    Overall Loss 2.629732    Objective Loss 2.629732                                        LR 0.001000    Time 0.053129    
2025-01-06 21:05:38,609 - Epoch: [10][  290/  341]    Overall Loss 2.630032    Objective Loss 2.630032                                        LR 0.001000    Time 0.052142    
2025-01-06 21:05:38,844 - Epoch: [10][  300/  341]    Overall Loss 2.629202    Objective Loss 2.629202                                        LR 0.001000    Time 0.051187    
2025-01-06 21:05:39,079 - Epoch: [10][  310/  341]    Overall Loss 2.629914    Objective Loss 2.629914                                        LR 0.001000    Time 0.050293    
2025-01-06 21:05:39,321 - Epoch: [10][  320/  341]    Overall Loss 2.629718    Objective Loss 2.629718                                        LR 0.001000    Time 0.049445    
2025-01-06 21:05:39,553 - Epoch: [10][  330/  341]    Overall Loss 2.630129    Objective Loss 2.630129                                        LR 0.001000    Time 0.048651    
2025-01-06 21:05:39,816 - Epoch: [10][  340/  341]    Overall Loss 2.630098    Objective Loss 2.630098    Top1 8.984375    Top5 38.671875    LR 0.001000    Time 0.047964    
2025-01-06 21:05:39,840 - Epoch: [10][  341/  341]    Overall Loss 2.630008    Objective Loss 2.630008    Top1 9.068010    Top5 38.035264    LR 0.001000    Time 0.047892    
2025-01-06 21:05:41,778 - --- validate (epoch=10)-----------
2025-01-06 21:05:41,780 - 15217 samples (256 per mini-batch)
2025-01-06 21:05:50,615 - Epoch: [10][   10/   60]    Loss 3.145936    Top1 0.078125    Top5 0.390625    
2025-01-06 21:05:50,833 - Epoch: [10][   20/   60]    Loss 3.146400    Top1 0.078125    Top5 0.449219    
2025-01-06 21:05:51,037 - Epoch: [10][   30/   60]    Loss 3.146204    Top1 0.091146    Top5 0.481771    
2025-01-06 21:05:51,262 - Epoch: [10][   40/   60]    Loss 3.146587    Top1 0.087891    Top5 0.449219    
2025-01-06 21:05:51,455 - Epoch: [10][   50/   60]    Loss 3.146555    Top1 0.078125    Top5 0.460938    
2025-01-06 21:05:51,640 - Epoch: [10][   60/   60]    Loss 3.146305    Top1 0.072288    Top5 0.460012    
2025-01-06 21:05:53,167 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.146

2025-01-06 21:05:53,167 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:05:53,638 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:05:53,641 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:05:53,654 - 

2025-01-06 21:05:53,655 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:06:02,137 - Epoch: [11][   10/  341]    Overall Loss 2.632550    Objective Loss 2.632550                                        LR 0.001000    Time 0.848245    
2025-01-06 21:06:02,371 - Epoch: [11][   20/  341]    Overall Loss 2.630369    Objective Loss 2.630369                                        LR 0.001000    Time 0.435818    
2025-01-06 21:06:02,603 - Epoch: [11][   30/  341]    Overall Loss 2.629636    Objective Loss 2.629636                                        LR 0.001000    Time 0.298280    
2025-01-06 21:06:02,858 - Epoch: [11][   40/  341]    Overall Loss 2.627294    Objective Loss 2.627294                                        LR 0.001000    Time 0.229816    
2025-01-06 21:06:03,099 - Epoch: [11][   50/  341]    Overall Loss 2.631514    Objective Loss 2.631514                                        LR 0.001000    Time 0.188671    
2025-01-06 21:06:03,331 - Epoch: [11][   60/  341]    Overall Loss 2.635186    Objective Loss 2.635186                                        LR 0.001000    Time 0.161102    
2025-01-06 21:06:03,567 - Epoch: [11][   70/  341]    Overall Loss 2.633582    Objective Loss 2.633582                                        LR 0.001000    Time 0.141458    
2025-01-06 21:06:03,807 - Epoch: [11][   80/  341]    Overall Loss 2.629200    Objective Loss 2.629200                                        LR 0.001000    Time 0.126782    
2025-01-06 21:06:04,042 - Epoch: [11][   90/  341]    Overall Loss 2.630374    Objective Loss 2.630374                                        LR 0.001000    Time 0.115278    
2025-01-06 21:06:04,324 - Epoch: [11][  100/  341]    Overall Loss 2.632020    Objective Loss 2.632020                                        LR 0.001000    Time 0.106568    
2025-01-06 21:06:04,559 - Epoch: [11][  110/  341]    Overall Loss 2.631622    Objective Loss 2.631622                                        LR 0.001000    Time 0.099018    
2025-01-06 21:06:04,793 - Epoch: [11][  120/  341]    Overall Loss 2.630428    Objective Loss 2.630428                                        LR 0.001000    Time 0.092712    
2025-01-06 21:06:05,034 - Epoch: [11][  130/  341]    Overall Loss 2.631719    Objective Loss 2.631719                                        LR 0.001000    Time 0.087436    
2025-01-06 21:06:05,270 - Epoch: [11][  140/  341]    Overall Loss 2.631442    Objective Loss 2.631442                                        LR 0.001000    Time 0.082879    
2025-01-06 21:06:05,514 - Epoch: [11][  150/  341]    Overall Loss 2.630900    Objective Loss 2.630900                                        LR 0.001000    Time 0.078967    
2025-01-06 21:06:05,753 - Epoch: [11][  160/  341]    Overall Loss 2.630409    Objective Loss 2.630409                                        LR 0.001000    Time 0.075523    
2025-01-06 21:06:05,986 - Epoch: [11][  170/  341]    Overall Loss 2.631257    Objective Loss 2.631257                                        LR 0.001000    Time 0.072453    
2025-01-06 21:06:06,229 - Epoch: [11][  180/  341]    Overall Loss 2.631174    Objective Loss 2.631174                                        LR 0.001000    Time 0.069776    
2025-01-06 21:06:06,460 - Epoch: [11][  190/  341]    Overall Loss 2.629983    Objective Loss 2.629983                                        LR 0.001000    Time 0.067317    
2025-01-06 21:06:06,696 - Epoch: [11][  200/  341]    Overall Loss 2.629583    Objective Loss 2.629583                                        LR 0.001000    Time 0.065135    
2025-01-06 21:06:06,929 - Epoch: [11][  210/  341]    Overall Loss 2.630132    Objective Loss 2.630132                                        LR 0.001000    Time 0.063143    
2025-01-06 21:06:07,170 - Epoch: [11][  220/  341]    Overall Loss 2.629357    Objective Loss 2.629357                                        LR 0.001000    Time 0.061366    
2025-01-06 21:06:07,404 - Epoch: [11][  230/  341]    Overall Loss 2.629606    Objective Loss 2.629606                                        LR 0.001000    Time 0.059715    
2025-01-06 21:06:07,639 - Epoch: [11][  240/  341]    Overall Loss 2.629539    Objective Loss 2.629539                                        LR 0.001000    Time 0.058207    
2025-01-06 21:06:07,886 - Epoch: [11][  250/  341]    Overall Loss 2.629760    Objective Loss 2.629760                                        LR 0.001000    Time 0.056867    
2025-01-06 21:06:08,133 - Epoch: [11][  260/  341]    Overall Loss 2.629692    Objective Loss 2.629692                                        LR 0.001000    Time 0.055591    
2025-01-06 21:06:08,376 - Epoch: [11][  270/  341]    Overall Loss 2.629765    Objective Loss 2.629765                                        LR 0.001000    Time 0.054424    
2025-01-06 21:06:08,612 - Epoch: [11][  280/  341]    Overall Loss 2.630151    Objective Loss 2.630151                                        LR 0.001000    Time 0.053323    
2025-01-06 21:06:08,856 - Epoch: [11][  290/  341]    Overall Loss 2.630413    Objective Loss 2.630413                                        LR 0.001000    Time 0.052326    
2025-01-06 21:06:09,111 - Epoch: [11][  300/  341]    Overall Loss 2.630279    Objective Loss 2.630279                                        LR 0.001000    Time 0.051432    
2025-01-06 21:06:09,352 - Epoch: [11][  310/  341]    Overall Loss 2.629462    Objective Loss 2.629462                                        LR 0.001000    Time 0.050551    
2025-01-06 21:06:09,591 - Epoch: [11][  320/  341]    Overall Loss 2.630070    Objective Loss 2.630070                                        LR 0.001000    Time 0.049717    
2025-01-06 21:06:09,818 - Epoch: [11][  330/  341]    Overall Loss 2.630183    Objective Loss 2.630183                                        LR 0.001000    Time 0.048887    
2025-01-06 21:06:10,072 - Epoch: [11][  340/  341]    Overall Loss 2.629870    Objective Loss 2.629870    Top1 10.156250    Top5 33.984375    LR 0.001000    Time 0.048168    
2025-01-06 21:06:10,092 - Epoch: [11][  341/  341]    Overall Loss 2.629717    Objective Loss 2.629717    Top1 10.327456    Top5 35.768262    LR 0.001000    Time 0.048085    
2025-01-06 21:06:11,749 - --- validate (epoch=11)-----------
2025-01-06 21:06:11,749 - 15217 samples (256 per mini-batch)
2025-01-06 21:06:20,575 - Epoch: [11][   10/   60]    Loss 3.154503    Top1 0.117188    Top5 0.546875    
2025-01-06 21:06:20,773 - Epoch: [11][   20/   60]    Loss 3.153269    Top1 0.058594    Top5 0.605469    
2025-01-06 21:06:20,979 - Epoch: [11][   30/   60]    Loss 3.154220    Top1 0.065104    Top5 0.546875    
2025-01-06 21:06:21,193 - Epoch: [11][   40/   60]    Loss 3.154267    Top1 0.068359    Top5 0.527344    
2025-01-06 21:06:21,384 - Epoch: [11][   50/   60]    Loss 3.154736    Top1 0.078125    Top5 0.476562    
2025-01-06 21:06:21,580 - Epoch: [11][   60/   60]    Loss 3.155087    Top1 0.072288    Top5 0.460012    
2025-01-06 21:06:23,179 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.155

2025-01-06 21:06:23,181 - ==> Confusion:
[[   0    0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:06:23,641 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:06:23,641 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:06:23,664 - 

2025-01-06 21:06:23,664 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:06:32,452 - Epoch: [12][   10/  341]    Overall Loss 2.609952    Objective Loss 2.609952                                        LR 0.001000    Time 0.878693    
2025-01-06 21:06:32,685 - Epoch: [12][   20/  341]    Overall Loss 2.608883    Objective Loss 2.608883                                        LR 0.001000    Time 0.450987    
2025-01-06 21:06:32,901 - Epoch: [12][   30/  341]    Overall Loss 2.619591    Objective Loss 2.619591                                        LR 0.001000    Time 0.307866    
2025-01-06 21:06:33,150 - Epoch: [12][   40/  341]    Overall Loss 2.620654    Objective Loss 2.620654                                        LR 0.001000    Time 0.236718    
2025-01-06 21:06:33,375 - Epoch: [12][   50/  341]    Overall Loss 2.622538    Objective Loss 2.622538                                        LR 0.001000    Time 0.193880    
2025-01-06 21:06:33,608 - Epoch: [12][   60/  341]    Overall Loss 2.626057    Objective Loss 2.626057                                        LR 0.001000    Time 0.165438    
2025-01-06 21:06:33,834 - Epoch: [12][   70/  341]    Overall Loss 2.624097    Objective Loss 2.624097                                        LR 0.001000    Time 0.145045    
2025-01-06 21:06:34,070 - Epoch: [12][   80/  341]    Overall Loss 2.626663    Objective Loss 2.626663                                        LR 0.001000    Time 0.129861    
2025-01-06 21:06:34,296 - Epoch: [12][   90/  341]    Overall Loss 2.627506    Objective Loss 2.627506                                        LR 0.001000    Time 0.117937    
2025-01-06 21:06:34,540 - Epoch: [12][  100/  341]    Overall Loss 2.628069    Objective Loss 2.628069                                        LR 0.001000    Time 0.108586    
2025-01-06 21:06:34,771 - Epoch: [12][  110/  341]    Overall Loss 2.628080    Objective Loss 2.628080                                        LR 0.001000    Time 0.100816    
2025-01-06 21:06:35,012 - Epoch: [12][  120/  341]    Overall Loss 2.627576    Objective Loss 2.627576                                        LR 0.001000    Time 0.094336    
2025-01-06 21:06:35,255 - Epoch: [12][  130/  341]    Overall Loss 2.627513    Objective Loss 2.627513                                        LR 0.001000    Time 0.088947    
2025-01-06 21:06:35,489 - Epoch: [12][  140/  341]    Overall Loss 2.627292    Objective Loss 2.627292                                        LR 0.001000    Time 0.084257    
2025-01-06 21:06:35,725 - Epoch: [12][  150/  341]    Overall Loss 2.627512    Objective Loss 2.627512                                        LR 0.001000    Time 0.080217    
2025-01-06 21:06:35,955 - Epoch: [12][  160/  341]    Overall Loss 2.626542    Objective Loss 2.626542                                        LR 0.001000    Time 0.076636    
2025-01-06 21:06:36,208 - Epoch: [12][  170/  341]    Overall Loss 2.626480    Objective Loss 2.626480                                        LR 0.001000    Time 0.073557    
2025-01-06 21:06:36,434 - Epoch: [12][  180/  341]    Overall Loss 2.627669    Objective Loss 2.627669                                        LR 0.001000    Time 0.070725    
2025-01-06 21:06:36,667 - Epoch: [12][  190/  341]    Overall Loss 2.627124    Objective Loss 2.627124                                        LR 0.001000    Time 0.068232    
2025-01-06 21:06:36,900 - Epoch: [12][  200/  341]    Overall Loss 2.626547    Objective Loss 2.626547                                        LR 0.001000    Time 0.065981    
2025-01-06 21:06:37,140 - Epoch: [12][  210/  341]    Overall Loss 2.627761    Objective Loss 2.627761                                        LR 0.001000    Time 0.063986    
2025-01-06 21:06:37,377 - Epoch: [12][  220/  341]    Overall Loss 2.628020    Objective Loss 2.628020                                        LR 0.001000    Time 0.062153    
2025-01-06 21:06:37,616 - Epoch: [12][  230/  341]    Overall Loss 2.627472    Objective Loss 2.627472                                        LR 0.001000    Time 0.060489    
2025-01-06 21:06:37,869 - Epoch: [12][  240/  341]    Overall Loss 2.628220    Objective Loss 2.628220                                        LR 0.001000    Time 0.058974    
2025-01-06 21:06:38,105 - Epoch: [12][  250/  341]    Overall Loss 2.628645    Objective Loss 2.628645                                        LR 0.001000    Time 0.057558    
2025-01-06 21:06:38,337 - Epoch: [12][  260/  341]    Overall Loss 2.628995    Objective Loss 2.628995                                        LR 0.001000    Time 0.056237    
2025-01-06 21:06:38,578 - Epoch: [12][  270/  341]    Overall Loss 2.629299    Objective Loss 2.629299                                        LR 0.001000    Time 0.055046    
2025-01-06 21:06:38,810 - Epoch: [12][  280/  341]    Overall Loss 2.629099    Objective Loss 2.629099                                        LR 0.001000    Time 0.053909    
2025-01-06 21:06:39,056 - Epoch: [12][  290/  341]    Overall Loss 2.629343    Objective Loss 2.629343                                        LR 0.001000    Time 0.052897    
2025-01-06 21:06:39,302 - Epoch: [12][  300/  341]    Overall Loss 2.629703    Objective Loss 2.629703                                        LR 0.001000    Time 0.051955    
2025-01-06 21:06:39,539 - Epoch: [12][  310/  341]    Overall Loss 2.629712    Objective Loss 2.629712                                        LR 0.001000    Time 0.051043    
2025-01-06 21:06:39,771 - Epoch: [12][  320/  341]    Overall Loss 2.629841    Objective Loss 2.629841                                        LR 0.001000    Time 0.050172    
2025-01-06 21:06:40,008 - Epoch: [12][  330/  341]    Overall Loss 2.629566    Objective Loss 2.629566                                        LR 0.001000    Time 0.049340    
2025-01-06 21:06:40,270 - Epoch: [12][  340/  341]    Overall Loss 2.629533    Objective Loss 2.629533    Top1 12.500000    Top5 35.546875    LR 0.001000    Time 0.048661    
2025-01-06 21:06:40,297 - Epoch: [12][  341/  341]    Overall Loss 2.629451    Objective Loss 2.629451    Top1 12.594458    Top5 36.775819    LR 0.001000    Time 0.048597    
2025-01-06 21:06:42,206 - --- validate (epoch=12)-----------
2025-01-06 21:06:42,206 - 15217 samples (256 per mini-batch)
2025-01-06 21:06:50,783 - Epoch: [12][   10/   60]    Loss 3.081765    Top1 0.000000    Top5 0.273437    
2025-01-06 21:06:51,006 - Epoch: [12][   20/   60]    Loss 3.076992    Top1 0.058594    Top5 0.449219    
2025-01-06 21:06:51,207 - Epoch: [12][   30/   60]    Loss 3.075013    Top1 0.104167    Top5 0.429687    
2025-01-06 21:06:51,410 - Epoch: [12][   40/   60]    Loss 3.074065    Top1 0.087891    Top5 0.439453    
2025-01-06 21:06:51,595 - Epoch: [12][   50/   60]    Loss 3.073597    Top1 0.078125    Top5 0.445312    
2025-01-06 21:06:51,790 - Epoch: [12][   60/   60]    Loss 3.073321    Top1 0.072288    Top5 0.460012    
2025-01-06 21:06:53,263 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.073

2025-01-06 21:06:53,263 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:06:53,733 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:06:53,735 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:06:53,749 - 

2025-01-06 21:06:53,749 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:07:02,436 - Epoch: [13][   10/  341]    Overall Loss 2.614172    Objective Loss 2.614172                                        LR 0.001000    Time 0.868627    
2025-01-06 21:07:02,662 - Epoch: [13][   20/  341]    Overall Loss 2.615159    Objective Loss 2.615159                                        LR 0.001000    Time 0.445620    
2025-01-06 21:07:02,898 - Epoch: [13][   30/  341]    Overall Loss 2.614978    Objective Loss 2.614978                                        LR 0.001000    Time 0.304944    
2025-01-06 21:07:03,130 - Epoch: [13][   40/  341]    Overall Loss 2.618326    Objective Loss 2.618326                                        LR 0.001000    Time 0.234501    
2025-01-06 21:07:03,359 - Epoch: [13][   50/  341]    Overall Loss 2.620580    Objective Loss 2.620580                                        LR 0.001000    Time 0.192188    
2025-01-06 21:07:03,591 - Epoch: [13][   60/  341]    Overall Loss 2.626098    Objective Loss 2.626098                                        LR 0.001000    Time 0.164022    
2025-01-06 21:07:03,823 - Epoch: [13][   70/  341]    Overall Loss 2.628763    Objective Loss 2.628763                                        LR 0.001000    Time 0.143905    
2025-01-06 21:07:04,052 - Epoch: [13][   80/  341]    Overall Loss 2.629126    Objective Loss 2.629126                                        LR 0.001000    Time 0.128777    
2025-01-06 21:07:04,282 - Epoch: [13][   90/  341]    Overall Loss 2.629241    Objective Loss 2.629241                                        LR 0.001000    Time 0.116983    
2025-01-06 21:07:04,511 - Epoch: [13][  100/  341]    Overall Loss 2.628670    Objective Loss 2.628670                                        LR 0.001000    Time 0.107539    
2025-01-06 21:07:04,750 - Epoch: [13][  110/  341]    Overall Loss 2.629883    Objective Loss 2.629883                                        LR 0.001000    Time 0.099924    
2025-01-06 21:07:04,989 - Epoch: [13][  120/  341]    Overall Loss 2.630315    Objective Loss 2.630315                                        LR 0.001000    Time 0.093586    
2025-01-06 21:07:05,221 - Epoch: [13][  130/  341]    Overall Loss 2.628313    Objective Loss 2.628313                                        LR 0.001000    Time 0.088169    
2025-01-06 21:07:05,448 - Epoch: [13][  140/  341]    Overall Loss 2.627991    Objective Loss 2.627991                                        LR 0.001000    Time 0.083486    
2025-01-06 21:07:05,691 - Epoch: [13][  150/  341]    Overall Loss 2.628725    Objective Loss 2.628725                                        LR 0.001000    Time 0.079538    
2025-01-06 21:07:05,925 - Epoch: [13][  160/  341]    Overall Loss 2.628045    Objective Loss 2.628045                                        LR 0.001000    Time 0.076029    
2025-01-06 21:07:06,158 - Epoch: [13][  170/  341]    Overall Loss 2.627729    Objective Loss 2.627729                                        LR 0.001000    Time 0.072929    
2025-01-06 21:07:06,385 - Epoch: [13][  180/  341]    Overall Loss 2.627728    Objective Loss 2.627728                                        LR 0.001000    Time 0.070138    
2025-01-06 21:07:06,619 - Epoch: [13][  190/  341]    Overall Loss 2.628445    Objective Loss 2.628445                                        LR 0.001000    Time 0.067677    
2025-01-06 21:07:06,849 - Epoch: [13][  200/  341]    Overall Loss 2.628606    Objective Loss 2.628606                                        LR 0.001000    Time 0.065434    
2025-01-06 21:07:07,089 - Epoch: [13][  210/  341]    Overall Loss 2.627955    Objective Loss 2.627955                                        LR 0.001000    Time 0.063454    
2025-01-06 21:07:07,314 - Epoch: [13][  220/  341]    Overall Loss 2.628110    Objective Loss 2.628110                                        LR 0.001000    Time 0.061592    
2025-01-06 21:07:07,556 - Epoch: [13][  230/  341]    Overall Loss 2.627603    Objective Loss 2.627603                                        LR 0.001000    Time 0.059966    
2025-01-06 21:07:07,799 - Epoch: [13][  240/  341]    Overall Loss 2.627138    Objective Loss 2.627138                                        LR 0.001000    Time 0.058478    
2025-01-06 21:07:08,039 - Epoch: [13][  250/  341]    Overall Loss 2.627250    Objective Loss 2.627250                                        LR 0.001000    Time 0.057098    
2025-01-06 21:07:08,272 - Epoch: [13][  260/  341]    Overall Loss 2.627449    Objective Loss 2.627449                                        LR 0.001000    Time 0.055798    
2025-01-06 21:07:08,512 - Epoch: [13][  270/  341]    Overall Loss 2.627642    Objective Loss 2.627642                                        LR 0.001000    Time 0.054623    
2025-01-06 21:07:08,744 - Epoch: [13][  280/  341]    Overall Loss 2.628242    Objective Loss 2.628242                                        LR 0.001000    Time 0.053498    
2025-01-06 21:07:08,989 - Epoch: [13][  290/  341]    Overall Loss 2.628381    Objective Loss 2.628381                                        LR 0.001000    Time 0.052501    
2025-01-06 21:07:09,229 - Epoch: [13][  300/  341]    Overall Loss 2.628408    Objective Loss 2.628408                                        LR 0.001000    Time 0.051550    
2025-01-06 21:07:09,460 - Epoch: [13][  310/  341]    Overall Loss 2.628436    Objective Loss 2.628436                                        LR 0.001000    Time 0.050630    
2025-01-06 21:07:09,692 - Epoch: [13][  320/  341]    Overall Loss 2.628815    Objective Loss 2.628815                                        LR 0.001000    Time 0.049775    
2025-01-06 21:07:09,922 - Epoch: [13][  330/  341]    Overall Loss 2.628647    Objective Loss 2.628647                                        LR 0.001000    Time 0.048963    
2025-01-06 21:07:10,172 - Epoch: [13][  340/  341]    Overall Loss 2.628801    Objective Loss 2.628801    Top1 9.375000    Top5 36.718750    LR 0.001000    Time 0.048257    
2025-01-06 21:07:10,188 - Epoch: [13][  341/  341]    Overall Loss 2.628870    Objective Loss 2.628870    Top1 10.831234    Top5 36.523929    LR 0.001000    Time 0.048158    
2025-01-06 21:07:11,837 - --- validate (epoch=13)-----------
2025-01-06 21:07:11,837 - 15217 samples (256 per mini-batch)
2025-01-06 21:07:20,781 - Epoch: [13][   10/   60]    Loss 3.084801    Top1 0.039062    Top5 0.312500    
2025-01-06 21:07:20,992 - Epoch: [13][   20/   60]    Loss 3.083281    Top1 0.039062    Top5 0.312500    
2025-01-06 21:07:21,199 - Epoch: [13][   30/   60]    Loss 3.083034    Top1 0.052083    Top5 0.325521    
2025-01-06 21:07:21,398 - Epoch: [13][   40/   60]    Loss 3.083157    Top1 0.039062    Top5 0.322266    
2025-01-06 21:07:21,591 - Epoch: [13][   50/   60]    Loss 3.081707    Top1 0.062500    Top5 0.421875    
2025-01-06 21:07:21,775 - Epoch: [13][   60/   60]    Loss 3.080981    Top1 0.072288    Top5 0.460012    
2025-01-06 21:07:23,290 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.081

2025-01-06 21:07:23,292 - ==> Confusion:
[[   0    0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:07:23,738 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:07:23,738 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:07:23,758 - 

2025-01-06 21:07:23,760 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:07:32,244 - Epoch: [14][   10/  341]    Overall Loss 2.627785    Objective Loss 2.627785                                        LR 0.001000    Time 0.848362    
2025-01-06 21:07:32,471 - Epoch: [14][   20/  341]    Overall Loss 2.630974    Objective Loss 2.630974                                        LR 0.001000    Time 0.435473    
2025-01-06 21:07:32,721 - Epoch: [14][   30/  341]    Overall Loss 2.635280    Objective Loss 2.635280                                        LR 0.001000    Time 0.298657    
2025-01-06 21:07:32,953 - Epoch: [14][   40/  341]    Overall Loss 2.632798    Objective Loss 2.632798                                        LR 0.001000    Time 0.229781    
2025-01-06 21:07:33,177 - Epoch: [14][   50/  341]    Overall Loss 2.631081    Objective Loss 2.631081                                        LR 0.001000    Time 0.188269    
2025-01-06 21:07:33,420 - Epoch: [14][   60/  341]    Overall Loss 2.631250    Objective Loss 2.631250                                        LR 0.001000    Time 0.160949    
2025-01-06 21:07:33,644 - Epoch: [14][   70/  341]    Overall Loss 2.629863    Objective Loss 2.629863                                        LR 0.001000    Time 0.141155    
2025-01-06 21:07:33,878 - Epoch: [14][   80/  341]    Overall Loss 2.628001    Objective Loss 2.628001                                        LR 0.001000    Time 0.126430    
2025-01-06 21:07:34,111 - Epoch: [14][   90/  341]    Overall Loss 2.628355    Objective Loss 2.628355                                        LR 0.001000    Time 0.114974    
2025-01-06 21:07:34,341 - Epoch: [14][  100/  341]    Overall Loss 2.629878    Objective Loss 2.629878                                        LR 0.001000    Time 0.105773    
2025-01-06 21:07:34,574 - Epoch: [14][  110/  341]    Overall Loss 2.630245    Objective Loss 2.630245                                        LR 0.001000    Time 0.098263    
2025-01-06 21:07:34,798 - Epoch: [14][  120/  341]    Overall Loss 2.631611    Objective Loss 2.631611                                        LR 0.001000    Time 0.091932    
2025-01-06 21:07:35,050 - Epoch: [14][  130/  341]    Overall Loss 2.631440    Objective Loss 2.631440                                        LR 0.001000    Time 0.086797    
2025-01-06 21:07:35,281 - Epoch: [14][  140/  341]    Overall Loss 2.630876    Objective Loss 2.630876                                        LR 0.001000    Time 0.082250    
2025-01-06 21:07:35,513 - Epoch: [14][  150/  341]    Overall Loss 2.629835    Objective Loss 2.629835                                        LR 0.001000    Time 0.078311    
2025-01-06 21:07:35,748 - Epoch: [14][  160/  341]    Overall Loss 2.629060    Objective Loss 2.629060                                        LR 0.001000    Time 0.074885    
2025-01-06 21:07:35,980 - Epoch: [14][  170/  341]    Overall Loss 2.629026    Objective Loss 2.629026                                        LR 0.001000    Time 0.071847    
2025-01-06 21:07:36,219 - Epoch: [14][  180/  341]    Overall Loss 2.629938    Objective Loss 2.629938                                        LR 0.001000    Time 0.069181    
2025-01-06 21:07:36,452 - Epoch: [14][  190/  341]    Overall Loss 2.628862    Objective Loss 2.628862                                        LR 0.001000    Time 0.066763    
2025-01-06 21:07:36,685 - Epoch: [14][  200/  341]    Overall Loss 2.629108    Objective Loss 2.629108                                        LR 0.001000    Time 0.064592    
2025-01-06 21:07:36,909 - Epoch: [14][  210/  341]    Overall Loss 2.629320    Objective Loss 2.629320                                        LR 0.001000    Time 0.062585    
2025-01-06 21:07:37,144 - Epoch: [14][  220/  341]    Overall Loss 2.629109    Objective Loss 2.629109                                        LR 0.001000    Time 0.060805    
2025-01-06 21:07:37,380 - Epoch: [14][  230/  341]    Overall Loss 2.628446    Objective Loss 2.628446                                        LR 0.001000    Time 0.059190    
2025-01-06 21:07:37,611 - Epoch: [14][  240/  341]    Overall Loss 2.629236    Objective Loss 2.629236                                        LR 0.001000    Time 0.057687    
2025-01-06 21:07:37,846 - Epoch: [14][  250/  341]    Overall Loss 2.629254    Objective Loss 2.629254                                        LR 0.001000    Time 0.056278    
2025-01-06 21:07:38,068 - Epoch: [14][  260/  341]    Overall Loss 2.629498    Objective Loss 2.629498                                        LR 0.001000    Time 0.054966    
2025-01-06 21:07:38,311 - Epoch: [14][  270/  341]    Overall Loss 2.629979    Objective Loss 2.629979                                        LR 0.001000    Time 0.053829    
2025-01-06 21:07:38,533 - Epoch: [14][  280/  341]    Overall Loss 2.630762    Objective Loss 2.630762                                        LR 0.001000    Time 0.052701    
2025-01-06 21:07:38,770 - Epoch: [14][  290/  341]    Overall Loss 2.630732    Objective Loss 2.630732                                        LR 0.001000    Time 0.051700    
2025-01-06 21:07:39,001 - Epoch: [14][  300/  341]    Overall Loss 2.630748    Objective Loss 2.630748                                        LR 0.001000    Time 0.050747    
2025-01-06 21:07:39,239 - Epoch: [14][  310/  341]    Overall Loss 2.629845    Objective Loss 2.629845                                        LR 0.001000    Time 0.049877    
2025-01-06 21:07:39,467 - Epoch: [14][  320/  341]    Overall Loss 2.629448    Objective Loss 2.629448                                        LR 0.001000    Time 0.049033    
2025-01-06 21:07:39,699 - Epoch: [14][  330/  341]    Overall Loss 2.629074    Objective Loss 2.629074                                        LR 0.001000    Time 0.048251    
2025-01-06 21:07:39,950 - Epoch: [14][  340/  341]    Overall Loss 2.628886    Objective Loss 2.628886    Top1 10.546875    Top5 40.625000    LR 0.001000    Time 0.047569    
2025-01-06 21:07:39,978 - Epoch: [14][  341/  341]    Overall Loss 2.629006    Objective Loss 2.629006    Top1 9.571788    Top5 38.035264    LR 0.001000    Time 0.047511    
2025-01-06 21:07:41,709 - --- validate (epoch=14)-----------
2025-01-06 21:07:41,709 - 15217 samples (256 per mini-batch)
2025-01-06 21:07:50,388 - Epoch: [14][   10/   60]    Loss 3.096850    Top1 0.039062    Top5 0.312500    
2025-01-06 21:07:50,604 - Epoch: [14][   20/   60]    Loss 3.094289    Top1 0.078125    Top5 0.429687    
2025-01-06 21:07:50,810 - Epoch: [14][   30/   60]    Loss 3.092726    Top1 0.078125    Top5 0.455729    
2025-01-06 21:07:51,023 - Epoch: [14][   40/   60]    Loss 3.093000    Top1 0.087891    Top5 0.468750    
2025-01-06 21:07:51,221 - Epoch: [14][   50/   60]    Loss 3.092679    Top1 0.085937    Top5 0.500000    
2025-01-06 21:07:51,397 - Epoch: [14][   60/   60]    Loss 3.093343    Top1 0.072288    Top5 0.460012    
2025-01-06 21:07:52,927 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.093

2025-01-06 21:07:52,927 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:07:53,392 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:07:53,392 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:07:53,407 - 

2025-01-06 21:07:53,407 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:08:01,777 - Epoch: [15][   10/  341]    Overall Loss 2.639042    Objective Loss 2.639042                                        LR 0.001000    Time 0.836904    
2025-01-06 21:08:01,998 - Epoch: [15][   20/  341]    Overall Loss 2.637905    Objective Loss 2.637905                                        LR 0.001000    Time 0.429514    
2025-01-06 21:08:02,225 - Epoch: [15][   30/  341]    Overall Loss 2.633628    Objective Loss 2.633628                                        LR 0.001000    Time 0.293911    
2025-01-06 21:08:02,472 - Epoch: [15][   40/  341]    Overall Loss 2.630711    Objective Loss 2.630711                                        LR 0.001000    Time 0.226047    
2025-01-06 21:08:02,703 - Epoch: [15][   50/  341]    Overall Loss 2.631774    Objective Loss 2.631774                                        LR 0.001000    Time 0.185462    
2025-01-06 21:08:02,965 - Epoch: [15][   60/  341]    Overall Loss 2.630948    Objective Loss 2.630948                                        LR 0.001000    Time 0.158847    
2025-01-06 21:08:03,195 - Epoch: [15][   70/  341]    Overall Loss 2.630842    Objective Loss 2.630842                                        LR 0.001000    Time 0.139411    
2025-01-06 21:08:03,426 - Epoch: [15][   80/  341]    Overall Loss 2.633158    Objective Loss 2.633158                                        LR 0.001000    Time 0.124873    
2025-01-06 21:08:03,659 - Epoch: [15][   90/  341]    Overall Loss 2.631868    Objective Loss 2.631868                                        LR 0.001000    Time 0.113572    
2025-01-06 21:08:03,893 - Epoch: [15][  100/  341]    Overall Loss 2.630128    Objective Loss 2.630128                                        LR 0.001000    Time 0.104550    
2025-01-06 21:08:04,118 - Epoch: [15][  110/  341]    Overall Loss 2.630898    Objective Loss 2.630898                                        LR 0.001000    Time 0.097090    
2025-01-06 21:08:04,352 - Epoch: [15][  120/  341]    Overall Loss 2.629804    Objective Loss 2.629804                                        LR 0.001000    Time 0.090947    
2025-01-06 21:08:04,584 - Epoch: [15][  130/  341]    Overall Loss 2.629660    Objective Loss 2.629660                                        LR 0.001000    Time 0.085738    
2025-01-06 21:08:04,820 - Epoch: [15][  140/  341]    Overall Loss 2.629842    Objective Loss 2.629842                                        LR 0.001000    Time 0.081303    
2025-01-06 21:08:05,054 - Epoch: [15][  150/  341]    Overall Loss 2.629554    Objective Loss 2.629554                                        LR 0.001000    Time 0.077443    
2025-01-06 21:08:05,296 - Epoch: [15][  160/  341]    Overall Loss 2.628352    Objective Loss 2.628352                                        LR 0.001000    Time 0.074111    
2025-01-06 21:08:05,523 - Epoch: [15][  170/  341]    Overall Loss 2.627899    Objective Loss 2.627899                                        LR 0.001000    Time 0.071086    
2025-01-06 21:08:05,754 - Epoch: [15][  180/  341]    Overall Loss 2.628440    Objective Loss 2.628440                                        LR 0.001000    Time 0.068426    
2025-01-06 21:08:05,995 - Epoch: [15][  190/  341]    Overall Loss 2.628731    Objective Loss 2.628731                                        LR 0.001000    Time 0.066092    
2025-01-06 21:08:06,250 - Epoch: [15][  200/  341]    Overall Loss 2.628168    Objective Loss 2.628168                                        LR 0.001000    Time 0.064062    
2025-01-06 21:08:06,490 - Epoch: [15][  210/  341]    Overall Loss 2.627953    Objective Loss 2.627953                                        LR 0.001000    Time 0.062154    
2025-01-06 21:08:06,730 - Epoch: [15][  220/  341]    Overall Loss 2.628474    Objective Loss 2.628474                                        LR 0.001000    Time 0.060419    
2025-01-06 21:08:06,960 - Epoch: [15][  230/  341]    Overall Loss 2.628217    Objective Loss 2.628217                                        LR 0.001000    Time 0.058791    
2025-01-06 21:08:07,189 - Epoch: [15][  240/  341]    Overall Loss 2.628383    Objective Loss 2.628383                                        LR 0.001000    Time 0.057297    
2025-01-06 21:08:07,438 - Epoch: [15][  250/  341]    Overall Loss 2.629305    Objective Loss 2.629305                                        LR 0.001000    Time 0.056001    
2025-01-06 21:08:07,668 - Epoch: [15][  260/  341]    Overall Loss 2.628807    Objective Loss 2.628807                                        LR 0.001000    Time 0.054732    
2025-01-06 21:08:07,900 - Epoch: [15][  270/  341]    Overall Loss 2.629100    Objective Loss 2.629100                                        LR 0.001000    Time 0.053563    
2025-01-06 21:08:08,133 - Epoch: [15][  280/  341]    Overall Loss 2.629494    Objective Loss 2.629494                                        LR 0.001000    Time 0.052482    
2025-01-06 21:08:08,380 - Epoch: [15][  290/  341]    Overall Loss 2.629288    Objective Loss 2.629288                                        LR 0.001000    Time 0.051510    
2025-01-06 21:08:08,615 - Epoch: [15][  300/  341]    Overall Loss 2.629280    Objective Loss 2.629280                                        LR 0.001000    Time 0.050571    
2025-01-06 21:08:08,862 - Epoch: [15][  310/  341]    Overall Loss 2.629153    Objective Loss 2.629153                                        LR 0.001000    Time 0.049734    
2025-01-06 21:08:09,093 - Epoch: [15][  320/  341]    Overall Loss 2.629299    Objective Loss 2.629299                                        LR 0.001000    Time 0.048903    
2025-01-06 21:08:09,340 - Epoch: [15][  330/  341]    Overall Loss 2.628965    Objective Loss 2.628965                                        LR 0.001000    Time 0.048154    
2025-01-06 21:08:09,585 - Epoch: [15][  340/  341]    Overall Loss 2.629166    Objective Loss 2.629166    Top1 8.203125    Top5 34.765625    LR 0.001000    Time 0.047460    
2025-01-06 21:08:09,614 - Epoch: [15][  341/  341]    Overall Loss 2.628871    Objective Loss 2.628871    Top1 9.319899    Top5 37.279597    LR 0.001000    Time 0.047377    
2025-01-06 21:08:11,460 - --- validate (epoch=15)-----------
2025-01-06 21:08:11,462 - 15217 samples (256 per mini-batch)
2025-01-06 21:08:20,367 - Epoch: [15][   10/   60]    Loss 3.125911    Top1 0.078125    Top5 0.429687    
2025-01-06 21:08:20,562 - Epoch: [15][   20/   60]    Loss 3.126467    Top1 0.078125    Top5 0.351563    
2025-01-06 21:08:20,779 - Epoch: [15][   30/   60]    Loss 3.126982    Top1 0.078125    Top5 0.390625    
2025-01-06 21:08:20,985 - Epoch: [15][   40/   60]    Loss 3.126145    Top1 0.068359    Top5 0.429687    
2025-01-06 21:08:21,196 - Epoch: [15][   50/   60]    Loss 3.126232    Top1 0.070313    Top5 0.437500    
2025-01-06 21:08:21,385 - Epoch: [15][   60/   60]    Loss 3.125912    Top1 0.072288    Top5 0.460012    
2025-01-06 21:08:22,836 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.126

2025-01-06 21:08:22,836 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:08:23,505 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:08:23,509 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:08:23,522 - 

2025-01-06 21:08:23,523 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:08:31,901 - Epoch: [16][   10/  341]    Overall Loss 2.634812    Objective Loss 2.634812                                        LR 0.001000    Time 0.836182    
2025-01-06 21:08:32,127 - Epoch: [16][   20/  341]    Overall Loss 2.635213    Objective Loss 2.635213                                        LR 0.001000    Time 0.429375    
2025-01-06 21:08:32,373 - Epoch: [16][   30/  341]    Overall Loss 2.627324    Objective Loss 2.627324                                        LR 0.001000    Time 0.294446    
2025-01-06 21:08:32,610 - Epoch: [16][   40/  341]    Overall Loss 2.629037    Objective Loss 2.629037                                        LR 0.001000    Time 0.226756    
2025-01-06 21:08:32,839 - Epoch: [16][   50/  341]    Overall Loss 2.626479    Objective Loss 2.626479                                        LR 0.001000    Time 0.185998    
2025-01-06 21:08:33,081 - Epoch: [16][   60/  341]    Overall Loss 2.624667    Objective Loss 2.624667                                        LR 0.001000    Time 0.159016    
2025-01-06 21:08:33,315 - Epoch: [16][   70/  341]    Overall Loss 2.624545    Objective Loss 2.624545                                        LR 0.001000    Time 0.139646    
2025-01-06 21:08:33,561 - Epoch: [16][   80/  341]    Overall Loss 2.623883    Objective Loss 2.623883                                        LR 0.001000    Time 0.125271    
2025-01-06 21:08:33,790 - Epoch: [16][   90/  341]    Overall Loss 2.624229    Objective Loss 2.624229                                        LR 0.001000    Time 0.113898    
2025-01-06 21:08:34,029 - Epoch: [16][  100/  341]    Overall Loss 2.624733    Objective Loss 2.624733                                        LR 0.001000    Time 0.104897    
2025-01-06 21:08:34,252 - Epoch: [16][  110/  341]    Overall Loss 2.624354    Objective Loss 2.624354                                        LR 0.001000    Time 0.097369    
2025-01-06 21:08:34,492 - Epoch: [16][  120/  341]    Overall Loss 2.625498    Objective Loss 2.625498                                        LR 0.001000    Time 0.091254    
2025-01-06 21:08:34,729 - Epoch: [16][  130/  341]    Overall Loss 2.625171    Objective Loss 2.625171                                        LR 0.001000    Time 0.086055    
2025-01-06 21:08:34,965 - Epoch: [16][  140/  341]    Overall Loss 2.624907    Objective Loss 2.624907                                        LR 0.001000    Time 0.081594    
2025-01-06 21:08:35,191 - Epoch: [16][  150/  341]    Overall Loss 2.625548    Objective Loss 2.625548                                        LR 0.001000    Time 0.077659    
2025-01-06 21:08:35,444 - Epoch: [16][  160/  341]    Overall Loss 2.624773    Objective Loss 2.624773                                        LR 0.001000    Time 0.074386    
2025-01-06 21:08:35,674 - Epoch: [16][  170/  341]    Overall Loss 2.625322    Objective Loss 2.625322                                        LR 0.001000    Time 0.071362    
2025-01-06 21:08:35,938 - Epoch: [16][  180/  341]    Overall Loss 2.625151    Objective Loss 2.625151                                        LR 0.001000    Time 0.068863    
2025-01-06 21:08:36,166 - Epoch: [16][  190/  341]    Overall Loss 2.626243    Objective Loss 2.626243                                        LR 0.001000    Time 0.066439    
2025-01-06 21:08:36,419 - Epoch: [16][  200/  341]    Overall Loss 2.626619    Objective Loss 2.626619                                        LR 0.001000    Time 0.064384    
2025-01-06 21:08:36,669 - Epoch: [16][  210/  341]    Overall Loss 2.627119    Objective Loss 2.627119                                        LR 0.001000    Time 0.062495    
2025-01-06 21:08:36,902 - Epoch: [16][  220/  341]    Overall Loss 2.627154    Objective Loss 2.627154                                        LR 0.001000    Time 0.060717    
2025-01-06 21:08:37,134 - Epoch: [16][  230/  341]    Overall Loss 2.627263    Objective Loss 2.627263                                        LR 0.001000    Time 0.059085    
2025-01-06 21:08:37,378 - Epoch: [16][  240/  341]    Overall Loss 2.627346    Objective Loss 2.627346                                        LR 0.001000    Time 0.057640    
2025-01-06 21:08:37,621 - Epoch: [16][  250/  341]    Overall Loss 2.627157    Objective Loss 2.627157                                        LR 0.001000    Time 0.056302    
2025-01-06 21:08:37,872 - Epoch: [16][  260/  341]    Overall Loss 2.627481    Objective Loss 2.627481                                        LR 0.001000    Time 0.055100    
2025-01-06 21:08:38,111 - Epoch: [16][  270/  341]    Overall Loss 2.627751    Objective Loss 2.627751                                        LR 0.001000    Time 0.053939    
2025-01-06 21:08:38,347 - Epoch: [16][  280/  341]    Overall Loss 2.628601    Objective Loss 2.628601                                        LR 0.001000    Time 0.052855    
2025-01-06 21:08:38,582 - Epoch: [16][  290/  341]    Overall Loss 2.628109    Objective Loss 2.628109                                        LR 0.001000    Time 0.051842    
2025-01-06 21:08:38,825 - Epoch: [16][  300/  341]    Overall Loss 2.628444    Objective Loss 2.628444                                        LR 0.001000    Time 0.050925    
2025-01-06 21:08:39,061 - Epoch: [16][  310/  341]    Overall Loss 2.628641    Objective Loss 2.628641                                        LR 0.001000    Time 0.050044    
2025-01-06 21:08:39,295 - Epoch: [16][  320/  341]    Overall Loss 2.629005    Objective Loss 2.629005                                        LR 0.001000    Time 0.049212    
2025-01-06 21:08:39,546 - Epoch: [16][  330/  341]    Overall Loss 2.629218    Objective Loss 2.629218                                        LR 0.001000    Time 0.048481    
2025-01-06 21:08:39,799 - Epoch: [16][  340/  341]    Overall Loss 2.629485    Objective Loss 2.629485    Top1 8.593750    Top5 36.328125    LR 0.001000    Time 0.047798    
2025-01-06 21:08:39,819 - Epoch: [16][  341/  341]    Overall Loss 2.629419    Objective Loss 2.629419    Top1 9.319899    Top5 38.539043    LR 0.001000    Time 0.047716    
2025-01-06 21:08:41,713 - --- validate (epoch=16)-----------
2025-01-06 21:08:41,713 - 15217 samples (256 per mini-batch)
2025-01-06 21:08:50,352 - Epoch: [16][   10/   60]    Loss 3.083955    Top1 0.000000    Top5 0.507813    
2025-01-06 21:08:50,559 - Epoch: [16][   20/   60]    Loss 3.085202    Top1 0.058594    Top5 0.449219    
2025-01-06 21:08:50,782 - Epoch: [16][   30/   60]    Loss 3.082890    Top1 0.104167    Top5 0.481771    
2025-01-06 21:08:50,982 - Epoch: [16][   40/   60]    Loss 3.083802    Top1 0.097656    Top5 0.498047    
2025-01-06 21:08:51,181 - Epoch: [16][   50/   60]    Loss 3.083697    Top1 0.078125    Top5 0.484375    
2025-01-06 21:08:51,354 - Epoch: [16][   60/   60]    Loss 3.084323    Top1 0.072288    Top5 0.460012    
2025-01-06 21:08:52,959 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.084

2025-01-06 21:08:52,959 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:08:53,616 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:08:53,616 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:08:53,633 - 

2025-01-06 21:08:53,633 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:09:02,049 - Epoch: [17][   10/  341]    Overall Loss 2.632866    Objective Loss 2.632866                                        LR 0.001000    Time 0.841580    
2025-01-06 21:09:02,287 - Epoch: [17][   20/  341]    Overall Loss 2.629844    Objective Loss 2.629844                                        LR 0.001000    Time 0.432672    
2025-01-06 21:09:02,530 - Epoch: [17][   30/  341]    Overall Loss 2.627676    Objective Loss 2.627676                                        LR 0.001000    Time 0.296526    
2025-01-06 21:09:02,768 - Epoch: [17][   40/  341]    Overall Loss 2.625403    Objective Loss 2.625403                                        LR 0.001000    Time 0.228349    
2025-01-06 21:09:03,001 - Epoch: [17][   50/  341]    Overall Loss 2.627157    Objective Loss 2.627157                                        LR 0.001000    Time 0.187237    
2025-01-06 21:09:03,237 - Epoch: [17][   60/  341]    Overall Loss 2.626463    Objective Loss 2.626463                                        LR 0.001000    Time 0.159955    
2025-01-06 21:09:03,473 - Epoch: [17][   70/  341]    Overall Loss 2.626090    Objective Loss 2.626090                                        LR 0.001000    Time 0.140477    
2025-01-06 21:09:03,715 - Epoch: [17][   80/  341]    Overall Loss 2.627871    Objective Loss 2.627871                                        LR 0.001000    Time 0.125940    
2025-01-06 21:09:03,950 - Epoch: [17][   90/  341]    Overall Loss 2.627175    Objective Loss 2.627175                                        LR 0.001000    Time 0.114544    
2025-01-06 21:09:04,183 - Epoch: [17][  100/  341]    Overall Loss 2.627949    Objective Loss 2.627949                                        LR 0.001000    Time 0.105419    
2025-01-06 21:09:04,417 - Epoch: [17][  110/  341]    Overall Loss 2.628889    Objective Loss 2.628889                                        LR 0.001000    Time 0.097957    
2025-01-06 21:09:04,666 - Epoch: [17][  120/  341]    Overall Loss 2.628489    Objective Loss 2.628489                                        LR 0.001000    Time 0.091871    
2025-01-06 21:09:04,894 - Epoch: [17][  130/  341]    Overall Loss 2.628343    Objective Loss 2.628343                                        LR 0.001000    Time 0.086551    
2025-01-06 21:09:05,125 - Epoch: [17][  140/  341]    Overall Loss 2.628909    Objective Loss 2.628909                                        LR 0.001000    Time 0.082020    
2025-01-06 21:09:05,358 - Epoch: [17][  150/  341]    Overall Loss 2.629185    Objective Loss 2.629185                                        LR 0.001000    Time 0.078104    
2025-01-06 21:09:05,603 - Epoch: [17][  160/  341]    Overall Loss 2.628474    Objective Loss 2.628474                                        LR 0.001000    Time 0.074753    
2025-01-06 21:09:05,856 - Epoch: [17][  170/  341]    Overall Loss 2.628557    Objective Loss 2.628557                                        LR 0.001000    Time 0.071786    
2025-01-06 21:09:06,087 - Epoch: [17][  180/  341]    Overall Loss 2.628626    Objective Loss 2.628626                                        LR 0.001000    Time 0.069081    
2025-01-06 21:09:06,322 - Epoch: [17][  190/  341]    Overall Loss 2.628737    Objective Loss 2.628737                                        LR 0.001000    Time 0.066679    
2025-01-06 21:09:06,574 - Epoch: [17][  200/  341]    Overall Loss 2.629683    Objective Loss 2.629683                                        LR 0.001000    Time 0.064605    
2025-01-06 21:09:06,820 - Epoch: [17][  210/  341]    Overall Loss 2.629200    Objective Loss 2.629200                                        LR 0.001000    Time 0.062644    
2025-01-06 21:09:07,059 - Epoch: [17][  220/  341]    Overall Loss 2.629028    Objective Loss 2.629028                                        LR 0.001000    Time 0.060880    
2025-01-06 21:09:07,289 - Epoch: [17][  230/  341]    Overall Loss 2.629999    Objective Loss 2.629999                                        LR 0.001000    Time 0.059236    
2025-01-06 21:09:07,539 - Epoch: [17][  240/  341]    Overall Loss 2.630102    Objective Loss 2.630102                                        LR 0.001000    Time 0.057806    
2025-01-06 21:09:07,769 - Epoch: [17][  250/  341]    Overall Loss 2.630171    Objective Loss 2.630171                                        LR 0.001000    Time 0.056413    
2025-01-06 21:09:08,014 - Epoch: [17][  260/  341]    Overall Loss 2.629692    Objective Loss 2.629692                                        LR 0.001000    Time 0.055144    
2025-01-06 21:09:08,252 - Epoch: [17][  270/  341]    Overall Loss 2.629609    Objective Loss 2.629609                                        LR 0.001000    Time 0.053984    
2025-01-06 21:09:08,492 - Epoch: [17][  280/  341]    Overall Loss 2.629647    Objective Loss 2.629647                                        LR 0.001000    Time 0.052914    
2025-01-06 21:09:08,733 - Epoch: [17][  290/  341]    Overall Loss 2.629702    Objective Loss 2.629702                                        LR 0.001000    Time 0.051919    
2025-01-06 21:09:08,981 - Epoch: [17][  300/  341]    Overall Loss 2.629319    Objective Loss 2.629319                                        LR 0.001000    Time 0.051017    
2025-01-06 21:09:09,223 - Epoch: [17][  310/  341]    Overall Loss 2.628678    Objective Loss 2.628678                                        LR 0.001000    Time 0.050149    
2025-01-06 21:09:09,482 - Epoch: [17][  320/  341]    Overall Loss 2.629121    Objective Loss 2.629121                                        LR 0.001000    Time 0.049394    
2025-01-06 21:09:09,725 - Epoch: [17][  330/  341]    Overall Loss 2.628945    Objective Loss 2.628945                                        LR 0.001000    Time 0.048633    
2025-01-06 21:09:09,978 - Epoch: [17][  340/  341]    Overall Loss 2.628960    Objective Loss 2.628960    Top1 11.328125    Top5 36.328125    LR 0.001000    Time 0.047946    
2025-01-06 21:09:09,996 - Epoch: [17][  341/  341]    Overall Loss 2.628891    Objective Loss 2.628891    Top1 10.831234    Top5 37.279597    LR 0.001000    Time 0.047854    
2025-01-06 21:09:11,983 - --- validate (epoch=17)-----------
2025-01-06 21:09:11,983 - 15217 samples (256 per mini-batch)
2025-01-06 21:09:20,553 - Epoch: [17][   10/   60]    Loss 3.114769    Top1 0.117188    Top5 0.546875    
2025-01-06 21:09:20,759 - Epoch: [17][   20/   60]    Loss 3.113639    Top1 0.136719    Top5 0.527344    
2025-01-06 21:09:20,969 - Epoch: [17][   30/   60]    Loss 3.114273    Top1 0.091146    Top5 0.533854    
2025-01-06 21:09:21,178 - Epoch: [17][   40/   60]    Loss 3.113619    Top1 0.068359    Top5 0.507813    
2025-01-06 21:09:21,381 - Epoch: [17][   50/   60]    Loss 3.114058    Top1 0.062500    Top5 0.468750    
2025-01-06 21:09:21,546 - Epoch: [17][   60/   60]    Loss 3.114600    Top1 0.072288    Top5 0.460012    
2025-01-06 21:09:23,057 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.115

2025-01-06 21:09:23,059 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:09:23,528 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:09:23,532 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:09:23,550 - 

2025-01-06 21:09:23,550 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:09:32,032 - Epoch: [18][   10/  341]    Overall Loss 2.626680    Objective Loss 2.626680                                        LR 0.001000    Time 0.848156    
2025-01-06 21:09:32,269 - Epoch: [18][   20/  341]    Overall Loss 2.629432    Objective Loss 2.629432                                        LR 0.001000    Time 0.435894    
2025-01-06 21:09:32,504 - Epoch: [18][   30/  341]    Overall Loss 2.628991    Objective Loss 2.628991                                        LR 0.001000    Time 0.298434    
2025-01-06 21:09:32,731 - Epoch: [18][   40/  341]    Overall Loss 2.625276    Objective Loss 2.625276                                        LR 0.001000    Time 0.229495    
2025-01-06 21:09:32,970 - Epoch: [18][   50/  341]    Overall Loss 2.625536    Objective Loss 2.625536                                        LR 0.001000    Time 0.188390    
2025-01-06 21:09:33,213 - Epoch: [18][   60/  341]    Overall Loss 2.632238    Objective Loss 2.632238                                        LR 0.001000    Time 0.161033    
2025-01-06 21:09:33,442 - Epoch: [18][   70/  341]    Overall Loss 2.632917    Objective Loss 2.632917                                        LR 0.001000    Time 0.141308    
2025-01-06 21:09:33,680 - Epoch: [18][   80/  341]    Overall Loss 2.631426    Objective Loss 2.631426                                        LR 0.001000    Time 0.126595    
2025-01-06 21:09:33,919 - Epoch: [18][   90/  341]    Overall Loss 2.630723    Objective Loss 2.630723                                        LR 0.001000    Time 0.115176    
2025-01-06 21:09:34,141 - Epoch: [18][  100/  341]    Overall Loss 2.629274    Objective Loss 2.629274                                        LR 0.001000    Time 0.105880    
2025-01-06 21:09:34,381 - Epoch: [18][  110/  341]    Overall Loss 2.629394    Objective Loss 2.629394                                        LR 0.001000    Time 0.098431    
2025-01-06 21:09:34,626 - Epoch: [18][  120/  341]    Overall Loss 2.629837    Objective Loss 2.629837                                        LR 0.001000    Time 0.092271    
2025-01-06 21:09:34,863 - Epoch: [18][  130/  341]    Overall Loss 2.629126    Objective Loss 2.629126                                        LR 0.001000    Time 0.086992    
2025-01-06 21:09:35,092 - Epoch: [18][  140/  341]    Overall Loss 2.629554    Objective Loss 2.629554                                        LR 0.001000    Time 0.082410    
2025-01-06 21:09:35,331 - Epoch: [18][  150/  341]    Overall Loss 2.629288    Objective Loss 2.629288                                        LR 0.001000    Time 0.078508    
2025-01-06 21:09:35,561 - Epoch: [18][  160/  341]    Overall Loss 2.629903    Objective Loss 2.629903                                        LR 0.001000    Time 0.075029    
2025-01-06 21:09:35,803 - Epoch: [18][  170/  341]    Overall Loss 2.629393    Objective Loss 2.629393                                        LR 0.001000    Time 0.072035    
2025-01-06 21:09:36,039 - Epoch: [18][  180/  341]    Overall Loss 2.629638    Objective Loss 2.629638                                        LR 0.001000    Time 0.069348    
2025-01-06 21:09:36,271 - Epoch: [18][  190/  341]    Overall Loss 2.629345    Objective Loss 2.629345                                        LR 0.001000    Time 0.066916    
2025-01-06 21:09:36,496 - Epoch: [18][  200/  341]    Overall Loss 2.629364    Objective Loss 2.629364                                        LR 0.001000    Time 0.064694    
2025-01-06 21:09:36,742 - Epoch: [18][  210/  341]    Overall Loss 2.629638    Objective Loss 2.629638                                        LR 0.001000    Time 0.062782    
2025-01-06 21:09:36,978 - Epoch: [18][  220/  341]    Overall Loss 2.629278    Objective Loss 2.629278                                        LR 0.001000    Time 0.060999    
2025-01-06 21:09:37,213 - Epoch: [18][  230/  341]    Overall Loss 2.628960    Objective Loss 2.628960                                        LR 0.001000    Time 0.059373    
2025-01-06 21:09:37,443 - Epoch: [18][  240/  341]    Overall Loss 2.628852    Objective Loss 2.628852                                        LR 0.001000    Time 0.057855    
2025-01-06 21:09:37,676 - Epoch: [18][  250/  341]    Overall Loss 2.628978    Objective Loss 2.628978                                        LR 0.001000    Time 0.056475    
2025-01-06 21:09:37,917 - Epoch: [18][  260/  341]    Overall Loss 2.629013    Objective Loss 2.629013                                        LR 0.001000    Time 0.055228    
2025-01-06 21:09:38,155 - Epoch: [18][  270/  341]    Overall Loss 2.628488    Objective Loss 2.628488                                        LR 0.001000    Time 0.054063    
2025-01-06 21:09:38,385 - Epoch: [18][  280/  341]    Overall Loss 2.628482    Objective Loss 2.628482                                        LR 0.001000    Time 0.052955    
2025-01-06 21:09:38,629 - Epoch: [18][  290/  341]    Overall Loss 2.628502    Objective Loss 2.628502                                        LR 0.001000    Time 0.051968    
2025-01-06 21:09:38,867 - Epoch: [18][  300/  341]    Overall Loss 2.628951    Objective Loss 2.628951                                        LR 0.001000    Time 0.051025    
2025-01-06 21:09:39,102 - Epoch: [18][  310/  341]    Overall Loss 2.629101    Objective Loss 2.629101                                        LR 0.001000    Time 0.050137    
2025-01-06 21:09:39,343 - Epoch: [18][  320/  341]    Overall Loss 2.629429    Objective Loss 2.629429                                        LR 0.001000    Time 0.049315    
2025-01-06 21:09:39,583 - Epoch: [18][  330/  341]    Overall Loss 2.629516    Objective Loss 2.629516                                        LR 0.001000    Time 0.048550    
2025-01-06 21:09:39,843 - Epoch: [18][  340/  341]    Overall Loss 2.629056    Objective Loss 2.629056    Top1 9.375000    Top5 36.328125    LR 0.001000    Time 0.047881    
2025-01-06 21:09:39,862 - Epoch: [18][  341/  341]    Overall Loss 2.628978    Objective Loss 2.628978    Top1 9.068010    Top5 36.020151    LR 0.001000    Time 0.047794    
2025-01-06 21:09:41,712 - --- validate (epoch=18)-----------
2025-01-06 21:09:41,712 - 15217 samples (256 per mini-batch)
2025-01-06 21:09:50,348 - Epoch: [18][   10/   60]    Loss 3.127031    Top1 0.039062    Top5 0.234375    
2025-01-06 21:09:50,550 - Epoch: [18][   20/   60]    Loss 3.125688    Top1 0.078125    Top5 0.390625    
2025-01-06 21:09:50,766 - Epoch: [18][   30/   60]    Loss 3.124713    Top1 0.065104    Top5 0.429687    
2025-01-06 21:09:50,974 - Epoch: [18][   40/   60]    Loss 3.123089    Top1 0.078125    Top5 0.410156    
2025-01-06 21:09:51,176 - Epoch: [18][   50/   60]    Loss 3.122548    Top1 0.070313    Top5 0.468750    
2025-01-06 21:09:51,361 - Epoch: [18][   60/   60]    Loss 3.122512    Top1 0.072288    Top5 0.460012    
2025-01-06 21:09:52,928 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.123

2025-01-06 21:09:52,928 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:09:53,439 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:09:53,449 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:09:53,462 - 

2025-01-06 21:09:53,462 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:10:02,199 - Epoch: [19][   10/  341]    Overall Loss 2.639656    Objective Loss 2.639656                                        LR 0.001000    Time 0.873600    
2025-01-06 21:10:02,431 - Epoch: [19][   20/  341]    Overall Loss 2.630311    Objective Loss 2.630311                                        LR 0.001000    Time 0.448420    
2025-01-06 21:10:02,704 - Epoch: [19][   30/  341]    Overall Loss 2.631170    Objective Loss 2.631170                                        LR 0.001000    Time 0.308061    
2025-01-06 21:10:02,943 - Epoch: [19][   40/  341]    Overall Loss 2.631044    Objective Loss 2.631044                                        LR 0.001000    Time 0.236969    
2025-01-06 21:10:03,188 - Epoch: [19][   50/  341]    Overall Loss 2.631391    Objective Loss 2.631391                                        LR 0.001000    Time 0.194474    
2025-01-06 21:10:03,436 - Epoch: [19][   60/  341]    Overall Loss 2.632048    Objective Loss 2.632048                                        LR 0.001000    Time 0.166196    
2025-01-06 21:10:03,697 - Epoch: [19][   70/  341]    Overall Loss 2.630537    Objective Loss 2.630537                                        LR 0.001000    Time 0.146150    
2025-01-06 21:10:03,937 - Epoch: [19][   80/  341]    Overall Loss 2.630593    Objective Loss 2.630593                                        LR 0.001000    Time 0.130879    
2025-01-06 21:10:04,184 - Epoch: [19][   90/  341]    Overall Loss 2.631053    Objective Loss 2.631053                                        LR 0.001000    Time 0.119079    
2025-01-06 21:10:04,427 - Epoch: [19][  100/  341]    Overall Loss 2.629328    Objective Loss 2.629328                                        LR 0.001000    Time 0.109604    
2025-01-06 21:10:04,668 - Epoch: [19][  110/  341]    Overall Loss 2.630530    Objective Loss 2.630530                                        LR 0.001000    Time 0.101831    
2025-01-06 21:10:04,909 - Epoch: [19][  120/  341]    Overall Loss 2.629829    Objective Loss 2.629829                                        LR 0.001000    Time 0.095351    
2025-01-06 21:10:05,151 - Epoch: [19][  130/  341]    Overall Loss 2.630676    Objective Loss 2.630676                                        LR 0.001000    Time 0.089863    
2025-01-06 21:10:05,397 - Epoch: [19][  140/  341]    Overall Loss 2.630460    Objective Loss 2.630460                                        LR 0.001000    Time 0.085205    
2025-01-06 21:10:05,642 - Epoch: [19][  150/  341]    Overall Loss 2.630451    Objective Loss 2.630451                                        LR 0.001000    Time 0.081153    
2025-01-06 21:10:05,892 - Epoch: [19][  160/  341]    Overall Loss 2.630329    Objective Loss 2.630329                                        LR 0.001000    Time 0.077644    
2025-01-06 21:10:06,147 - Epoch: [19][  170/  341]    Overall Loss 2.630973    Objective Loss 2.630973                                        LR 0.001000    Time 0.074578    
2025-01-06 21:10:06,390 - Epoch: [19][  180/  341]    Overall Loss 2.631026    Objective Loss 2.631026                                        LR 0.001000    Time 0.071787    
2025-01-06 21:10:06,640 - Epoch: [19][  190/  341]    Overall Loss 2.630942    Objective Loss 2.630942                                        LR 0.001000    Time 0.069324    
2025-01-06 21:10:06,910 - Epoch: [19][  200/  341]    Overall Loss 2.630966    Objective Loss 2.630966                                        LR 0.001000    Time 0.067205    
2025-01-06 21:10:07,151 - Epoch: [19][  210/  341]    Overall Loss 2.631157    Objective Loss 2.631157                                        LR 0.001000    Time 0.065155    
2025-01-06 21:10:07,419 - Epoch: [19][  220/  341]    Overall Loss 2.630427    Objective Loss 2.630427                                        LR 0.001000    Time 0.063386    
2025-01-06 21:10:07,671 - Epoch: [19][  230/  341]    Overall Loss 2.629590    Objective Loss 2.629590                                        LR 0.001000    Time 0.061718    
2025-01-06 21:10:07,919 - Epoch: [19][  240/  341]    Overall Loss 2.630059    Objective Loss 2.630059                                        LR 0.001000    Time 0.060177    
2025-01-06 21:10:08,175 - Epoch: [19][  250/  341]    Overall Loss 2.629690    Objective Loss 2.629690                                        LR 0.001000    Time 0.058795    
2025-01-06 21:10:08,418 - Epoch: [19][  260/  341]    Overall Loss 2.629930    Objective Loss 2.629930                                        LR 0.001000    Time 0.057468    
2025-01-06 21:10:08,668 - Epoch: [19][  270/  341]    Overall Loss 2.630178    Objective Loss 2.630178                                        LR 0.001000    Time 0.056267    
2025-01-06 21:10:08,923 - Epoch: [19][  280/  341]    Overall Loss 2.630742    Objective Loss 2.630742                                        LR 0.001000    Time 0.055167    
2025-01-06 21:10:09,176 - Epoch: [19][  290/  341]    Overall Loss 2.630222    Objective Loss 2.630222                                        LR 0.001000    Time 0.054139    
2025-01-06 21:10:09,411 - Epoch: [19][  300/  341]    Overall Loss 2.630485    Objective Loss 2.630485                                        LR 0.001000    Time 0.053108    
2025-01-06 21:10:09,650 - Epoch: [19][  310/  341]    Overall Loss 2.629915    Objective Loss 2.629915                                        LR 0.001000    Time 0.052166    
2025-01-06 21:10:09,899 - Epoch: [19][  320/  341]    Overall Loss 2.629723    Objective Loss 2.629723                                        LR 0.001000    Time 0.051316    
2025-01-06 21:10:10,141 - Epoch: [19][  330/  341]    Overall Loss 2.629255    Objective Loss 2.629255                                        LR 0.001000    Time 0.050495    
2025-01-06 21:10:10,391 - Epoch: [19][  340/  341]    Overall Loss 2.629016    Objective Loss 2.629016    Top1 10.937500    Top5 37.109375    LR 0.001000    Time 0.049730    
2025-01-06 21:10:10,419 - Epoch: [19][  341/  341]    Overall Loss 2.628993    Objective Loss 2.628993    Top1 11.083123    Top5 36.775819    LR 0.001000    Time 0.049666    
2025-01-06 21:10:12,152 - --- validate (epoch=19)-----------
2025-01-06 21:10:12,152 - 15217 samples (256 per mini-batch)
2025-01-06 21:10:20,929 - Epoch: [19][   10/   60]    Loss 3.088318    Top1 0.078125    Top5 0.312500    
2025-01-06 21:10:21,134 - Epoch: [19][   20/   60]    Loss 3.087288    Top1 0.078125    Top5 0.468750    
2025-01-06 21:10:21,353 - Epoch: [19][   30/   60]    Loss 3.086071    Top1 0.065104    Top5 0.520833    
2025-01-06 21:10:21,563 - Epoch: [19][   40/   60]    Loss 3.086378    Top1 0.058594    Top5 0.507813    
2025-01-06 21:10:21,769 - Epoch: [19][   50/   60]    Loss 3.087143    Top1 0.078125    Top5 0.468750    
2025-01-06 21:10:21,952 - Epoch: [19][   60/   60]    Loss 3.086815    Top1 0.072288    Top5 0.460012    
2025-01-06 21:10:23,513 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.087

2025-01-06 21:10:23,523 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:10:24,000 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:10:24,000 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:10:24,017 - 

2025-01-06 21:10:24,017 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:10:32,558 - Epoch: [20][   10/  341]    Overall Loss 2.648987    Objective Loss 2.648987                                        LR 0.001000    Time 0.854013    
2025-01-06 21:10:32,808 - Epoch: [20][   20/  341]    Overall Loss 2.634408    Objective Loss 2.634408                                        LR 0.001000    Time 0.439476    
2025-01-06 21:10:33,051 - Epoch: [20][   30/  341]    Overall Loss 2.633455    Objective Loss 2.633455                                        LR 0.001000    Time 0.301101    
2025-01-06 21:10:33,296 - Epoch: [20][   40/  341]    Overall Loss 2.634243    Objective Loss 2.634243                                        LR 0.001000    Time 0.231943    
2025-01-06 21:10:33,528 - Epoch: [20][   50/  341]    Overall Loss 2.633301    Objective Loss 2.633301                                        LR 0.001000    Time 0.190159    
2025-01-06 21:10:33,762 - Epoch: [20][   60/  341]    Overall Loss 2.635621    Objective Loss 2.635621                                        LR 0.001000    Time 0.162362    
2025-01-06 21:10:34,004 - Epoch: [20][   70/  341]    Overall Loss 2.633947    Objective Loss 2.633947                                        LR 0.001000    Time 0.142474    
2025-01-06 21:10:34,236 - Epoch: [20][   80/  341]    Overall Loss 2.635019    Objective Loss 2.635019                                        LR 0.001000    Time 0.127565    
2025-01-06 21:10:34,476 - Epoch: [20][   90/  341]    Overall Loss 2.635636    Objective Loss 2.635636                                        LR 0.001000    Time 0.116059    
2025-01-06 21:10:34,707 - Epoch: [20][  100/  341]    Overall Loss 2.635171    Objective Loss 2.635171                                        LR 0.001000    Time 0.106770    
2025-01-06 21:10:34,941 - Epoch: [20][  110/  341]    Overall Loss 2.634090    Objective Loss 2.634090                                        LR 0.001000    Time 0.099190    
2025-01-06 21:10:35,184 - Epoch: [20][  120/  341]    Overall Loss 2.634357    Objective Loss 2.634357                                        LR 0.001000    Time 0.092949    
2025-01-06 21:10:35,417 - Epoch: [20][  130/  341]    Overall Loss 2.633679    Objective Loss 2.633679                                        LR 0.001000    Time 0.087590    
2025-01-06 21:10:35,653 - Epoch: [20][  140/  341]    Overall Loss 2.631878    Objective Loss 2.631878                                        LR 0.001000    Time 0.083015    
2025-01-06 21:10:35,900 - Epoch: [20][  150/  341]    Overall Loss 2.632078    Objective Loss 2.632078                                        LR 0.001000    Time 0.079065    
2025-01-06 21:10:36,142 - Epoch: [20][  160/  341]    Overall Loss 2.632314    Objective Loss 2.632314                                        LR 0.001000    Time 0.075635    
2025-01-06 21:10:36,397 - Epoch: [20][  170/  341]    Overall Loss 2.632430    Objective Loss 2.632430                                        LR 0.001000    Time 0.072622    
2025-01-06 21:10:36,640 - Epoch: [20][  180/  341]    Overall Loss 2.632445    Objective Loss 2.632445                                        LR 0.001000    Time 0.069936    
2025-01-06 21:10:36,885 - Epoch: [20][  190/  341]    Overall Loss 2.630814    Objective Loss 2.630814                                        LR 0.001000    Time 0.067545    
2025-01-06 21:10:37,121 - Epoch: [20][  200/  341]    Overall Loss 2.629875    Objective Loss 2.629875                                        LR 0.001000    Time 0.065352    
2025-01-06 21:10:37,365 - Epoch: [20][  210/  341]    Overall Loss 2.629775    Objective Loss 2.629775                                        LR 0.001000    Time 0.063400    
2025-01-06 21:10:37,606 - Epoch: [20][  220/  341]    Overall Loss 2.629550    Objective Loss 2.629550                                        LR 0.001000    Time 0.061614    
2025-01-06 21:10:37,836 - Epoch: [20][  230/  341]    Overall Loss 2.629969    Objective Loss 2.629969                                        LR 0.001000    Time 0.059936    
2025-01-06 21:10:38,072 - Epoch: [20][  240/  341]    Overall Loss 2.629539    Objective Loss 2.629539                                        LR 0.001000    Time 0.058420    
2025-01-06 21:10:38,308 - Epoch: [20][  250/  341]    Overall Loss 2.629253    Objective Loss 2.629253                                        LR 0.001000    Time 0.057028    
2025-01-06 21:10:38,546 - Epoch: [20][  260/  341]    Overall Loss 2.629545    Objective Loss 2.629545                                        LR 0.001000    Time 0.055749    
2025-01-06 21:10:38,797 - Epoch: [20][  270/  341]    Overall Loss 2.628660    Objective Loss 2.628660                                        LR 0.001000    Time 0.054578    
2025-01-06 21:10:39,054 - Epoch: [20][  280/  341]    Overall Loss 2.628790    Objective Loss 2.628790                                        LR 0.001000    Time 0.053544    
2025-01-06 21:10:39,310 - Epoch: [20][  290/  341]    Overall Loss 2.628493    Objective Loss 2.628493                                        LR 0.001000    Time 0.052583    
2025-01-06 21:10:39,550 - Epoch: [20][  300/  341]    Overall Loss 2.628963    Objective Loss 2.628963                                        LR 0.001000    Time 0.051622    
2025-01-06 21:10:39,797 - Epoch: [20][  310/  341]    Overall Loss 2.629245    Objective Loss 2.629245                                        LR 0.001000    Time 0.050753    
2025-01-06 21:10:40,045 - Epoch: [20][  320/  341]    Overall Loss 2.629602    Objective Loss 2.629602                                        LR 0.001000    Time 0.049911    
2025-01-06 21:10:40,322 - Epoch: [20][  330/  341]    Overall Loss 2.629103    Objective Loss 2.629103                                        LR 0.001000    Time 0.049233    
2025-01-06 21:10:40,592 - Epoch: [20][  340/  341]    Overall Loss 2.628939    Objective Loss 2.628939    Top1 9.765625    Top5 35.156250    LR 0.001000    Time 0.048579    
2025-01-06 21:10:40,616 - Epoch: [20][  341/  341]    Overall Loss 2.628804    Objective Loss 2.628804    Top1 8.816121    Top5 37.279597    LR 0.001000    Time 0.048507    
2025-01-06 21:10:42,577 - --- validate (epoch=20)-----------
2025-01-06 21:10:42,577 - 15217 samples (256 per mini-batch)
2025-01-06 21:10:51,079 - Epoch: [20][   10/   60]    Loss 3.104486    Top1 0.039062    Top5 0.351563    
2025-01-06 21:10:51,307 - Epoch: [20][   20/   60]    Loss 3.102508    Top1 0.078125    Top5 0.429687    
2025-01-06 21:10:51,523 - Epoch: [20][   30/   60]    Loss 3.102692    Top1 0.078125    Top5 0.455729    
2025-01-06 21:10:51,732 - Epoch: [20][   40/   60]    Loss 3.103505    Top1 0.078125    Top5 0.458984    
2025-01-06 21:10:51,948 - Epoch: [20][   50/   60]    Loss 3.103702    Top1 0.078125    Top5 0.437500    
2025-01-06 21:10:52,138 - Epoch: [20][   60/   60]    Loss 3.104288    Top1 0.072288    Top5 0.460012    
2025-01-06 21:10:53,620 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.104

2025-01-06 21:10:53,620 - ==> Confusion:
[[   0    0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:10:54,123 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:10:54,124 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:10:54,134 - 

2025-01-06 21:10:54,136 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:11:02,901 - Epoch: [21][   10/  341]    Overall Loss 2.640023    Objective Loss 2.640023                                        LR 0.001000    Time 0.876372    
2025-01-06 21:11:03,148 - Epoch: [21][   20/  341]    Overall Loss 2.631799    Objective Loss 2.631799                                        LR 0.001000    Time 0.449773    
2025-01-06 21:11:03,396 - Epoch: [21][   30/  341]    Overall Loss 2.626124    Objective Loss 2.626124                                        LR 0.001000    Time 0.308114    
2025-01-06 21:11:03,622 - Epoch: [21][   40/  341]    Overall Loss 2.630689    Objective Loss 2.630689                                        LR 0.001000    Time 0.236685    
2025-01-06 21:11:03,864 - Epoch: [21][   50/  341]    Overall Loss 2.632342    Objective Loss 2.632342                                        LR 0.001000    Time 0.194188    
2025-01-06 21:11:04,129 - Epoch: [21][   60/  341]    Overall Loss 2.631541    Objective Loss 2.631541                                        LR 0.001000    Time 0.166236    
2025-01-06 21:11:04,349 - Epoch: [21][   70/  341]    Overall Loss 2.629456    Objective Loss 2.629456                                        LR 0.001000    Time 0.145635    
2025-01-06 21:11:04,586 - Epoch: [21][   80/  341]    Overall Loss 2.630213    Objective Loss 2.630213                                        LR 0.001000    Time 0.130389    
2025-01-06 21:11:04,826 - Epoch: [21][   90/  341]    Overall Loss 2.629421    Objective Loss 2.629421                                        LR 0.001000    Time 0.118567    
2025-01-06 21:11:05,063 - Epoch: [21][  100/  341]    Overall Loss 2.629121    Objective Loss 2.629121                                        LR 0.001000    Time 0.109087    
2025-01-06 21:11:05,298 - Epoch: [21][  110/  341]    Overall Loss 2.630507    Objective Loss 2.630507                                        LR 0.001000    Time 0.101280    
2025-01-06 21:11:05,526 - Epoch: [21][  120/  341]    Overall Loss 2.630050    Objective Loss 2.630050                                        LR 0.001000    Time 0.094745    
2025-01-06 21:11:05,756 - Epoch: [21][  130/  341]    Overall Loss 2.629501    Objective Loss 2.629501                                        LR 0.001000    Time 0.089224    
2025-01-06 21:11:06,003 - Epoch: [21][  140/  341]    Overall Loss 2.627241    Objective Loss 2.627241                                        LR 0.001000    Time 0.084618    
2025-01-06 21:11:06,231 - Epoch: [21][  150/  341]    Overall Loss 2.627119    Objective Loss 2.627119                                        LR 0.001000    Time 0.080498    
2025-01-06 21:11:06,465 - Epoch: [21][  160/  341]    Overall Loss 2.626818    Objective Loss 2.626818                                        LR 0.001000    Time 0.076927    
2025-01-06 21:11:06,707 - Epoch: [21][  170/  341]    Overall Loss 2.626965    Objective Loss 2.626965                                        LR 0.001000    Time 0.073825    
2025-01-06 21:11:06,943 - Epoch: [21][  180/  341]    Overall Loss 2.626980    Objective Loss 2.626980                                        LR 0.001000    Time 0.071024    
2025-01-06 21:11:07,184 - Epoch: [21][  190/  341]    Overall Loss 2.626992    Objective Loss 2.626992                                        LR 0.001000    Time 0.068552    
2025-01-06 21:11:07,414 - Epoch: [21][  200/  341]    Overall Loss 2.627497    Objective Loss 2.627497                                        LR 0.001000    Time 0.066275    
2025-01-06 21:11:07,654 - Epoch: [21][  210/  341]    Overall Loss 2.628409    Objective Loss 2.628409                                        LR 0.001000    Time 0.064262    
2025-01-06 21:11:07,906 - Epoch: [21][  220/  341]    Overall Loss 2.628365    Objective Loss 2.628365                                        LR 0.001000    Time 0.062440    
2025-01-06 21:11:08,157 - Epoch: [21][  230/  341]    Overall Loss 2.628720    Objective Loss 2.628720                                        LR 0.001000    Time 0.060816    
2025-01-06 21:11:08,383 - Epoch: [21][  240/  341]    Overall Loss 2.628522    Objective Loss 2.628522                                        LR 0.001000    Time 0.059222    
2025-01-06 21:11:08,621 - Epoch: [21][  250/  341]    Overall Loss 2.628470    Objective Loss 2.628470                                        LR 0.001000    Time 0.057764    
2025-01-06 21:11:08,878 - Epoch: [21][  260/  341]    Overall Loss 2.628394    Objective Loss 2.628394                                        LR 0.001000    Time 0.056529    
2025-01-06 21:11:09,126 - Epoch: [21][  270/  341]    Overall Loss 2.628878    Objective Loss 2.628878                                        LR 0.001000    Time 0.055347    
2025-01-06 21:11:09,359 - Epoch: [21][  280/  341]    Overall Loss 2.629256    Objective Loss 2.629256                                        LR 0.001000    Time 0.054204    
2025-01-06 21:11:09,592 - Epoch: [21][  290/  341]    Overall Loss 2.629632    Objective Loss 2.629632                                        LR 0.001000    Time 0.053138    
2025-01-06 21:11:09,828 - Epoch: [21][  300/  341]    Overall Loss 2.629286    Objective Loss 2.629286                                        LR 0.001000    Time 0.052121    
2025-01-06 21:11:10,061 - Epoch: [21][  310/  341]    Overall Loss 2.629499    Objective Loss 2.629499                                        LR 0.001000    Time 0.051189    
2025-01-06 21:11:10,298 - Epoch: [21][  320/  341]    Overall Loss 2.629475    Objective Loss 2.629475                                        LR 0.001000    Time 0.050332    
2025-01-06 21:11:10,522 - Epoch: [21][  330/  341]    Overall Loss 2.629675    Objective Loss 2.629675                                        LR 0.001000    Time 0.049484    
2025-01-06 21:11:10,791 - Epoch: [21][  340/  341]    Overall Loss 2.629002    Objective Loss 2.629002    Top1 8.984375    Top5 35.546875    LR 0.001000    Time 0.048789    
2025-01-06 21:11:10,811 - Epoch: [21][  341/  341]    Overall Loss 2.629065    Objective Loss 2.629065    Top1 9.319899    Top5 34.508816    LR 0.001000    Time 0.048689    
2025-01-06 21:11:12,458 - --- validate (epoch=21)-----------
2025-01-06 21:11:12,458 - 15217 samples (256 per mini-batch)
2025-01-06 21:11:20,908 - Epoch: [21][   10/   60]    Loss 3.193004    Top1 0.078125    Top5 0.351563    
2025-01-06 21:11:21,122 - Epoch: [21][   20/   60]    Loss 3.192988    Top1 0.058594    Top5 0.390625    
2025-01-06 21:11:21,345 - Epoch: [21][   30/   60]    Loss 3.191287    Top1 0.091146    Top5 0.442708    
2025-01-06 21:11:21,555 - Epoch: [21][   40/   60]    Loss 3.191932    Top1 0.087891    Top5 0.458984    
2025-01-06 21:11:21,756 - Epoch: [21][   50/   60]    Loss 3.192571    Top1 0.078125    Top5 0.429687    
2025-01-06 21:11:21,956 - Epoch: [21][   60/   60]    Loss 3.191961    Top1 0.072288    Top5 0.460012    
2025-01-06 21:11:23,632 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.192

2025-01-06 21:11:23,632 - ==> Confusion:
[[   0    0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:11:24,098 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:11:24,098 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:11:24,109 - 

2025-01-06 21:11:24,109 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:11:32,720 - Epoch: [22][   10/  341]    Overall Loss 2.609816    Objective Loss 2.609816                                        LR 0.001000    Time 0.861071    
2025-01-06 21:11:32,941 - Epoch: [22][   20/  341]    Overall Loss 2.625651    Objective Loss 2.625651                                        LR 0.001000    Time 0.441576    
2025-01-06 21:11:33,186 - Epoch: [22][   30/  341]    Overall Loss 2.626293    Objective Loss 2.626293                                        LR 0.001000    Time 0.302553    
2025-01-06 21:11:33,417 - Epoch: [22][   40/  341]    Overall Loss 2.626199    Objective Loss 2.626199                                        LR 0.001000    Time 0.232687    
2025-01-06 21:11:33,645 - Epoch: [22][   50/  341]    Overall Loss 2.629147    Objective Loss 2.629147                                        LR 0.001000    Time 0.190713    
2025-01-06 21:11:33,886 - Epoch: [22][   60/  341]    Overall Loss 2.625915    Objective Loss 2.625915                                        LR 0.001000    Time 0.162781    
2025-01-06 21:11:34,119 - Epoch: [22][   70/  341]    Overall Loss 2.629823    Objective Loss 2.629823                                        LR 0.001000    Time 0.142851    
2025-01-06 21:11:34,350 - Epoch: [22][   80/  341]    Overall Loss 2.629977    Objective Loss 2.629977                                        LR 0.001000    Time 0.127877    
2025-01-06 21:11:34,589 - Epoch: [22][   90/  341]    Overall Loss 2.631285    Objective Loss 2.631285                                        LR 0.001000    Time 0.116333    
2025-01-06 21:11:34,823 - Epoch: [22][  100/  341]    Overall Loss 2.632469    Objective Loss 2.632469                                        LR 0.001000    Time 0.107037    
2025-01-06 21:11:35,064 - Epoch: [22][  110/  341]    Overall Loss 2.631137    Objective Loss 2.631137                                        LR 0.001000    Time 0.099491    
2025-01-06 21:11:35,300 - Epoch: [22][  120/  341]    Overall Loss 2.631895    Objective Loss 2.631895                                        LR 0.001000    Time 0.093173    
2025-01-06 21:11:35,534 - Epoch: [22][  130/  341]    Overall Loss 2.631805    Objective Loss 2.631805                                        LR 0.001000    Time 0.087801    
2025-01-06 21:11:35,766 - Epoch: [22][  140/  341]    Overall Loss 2.630714    Objective Loss 2.630714                                        LR 0.001000    Time 0.083192    
2025-01-06 21:11:36,009 - Epoch: [22][  150/  341]    Overall Loss 2.630733    Objective Loss 2.630733                                        LR 0.001000    Time 0.079196    
2025-01-06 21:11:36,253 - Epoch: [22][  160/  341]    Overall Loss 2.630075    Objective Loss 2.630075                                        LR 0.001000    Time 0.075771    
2025-01-06 21:11:36,478 - Epoch: [22][  170/  341]    Overall Loss 2.630053    Objective Loss 2.630053                                        LR 0.001000    Time 0.072635    
2025-01-06 21:11:36,714 - Epoch: [22][  180/  341]    Overall Loss 2.629538    Objective Loss 2.629538                                        LR 0.001000    Time 0.069910    
2025-01-06 21:11:36,966 - Epoch: [22][  190/  341]    Overall Loss 2.630165    Objective Loss 2.630165                                        LR 0.001000    Time 0.067558    
2025-01-06 21:11:37,203 - Epoch: [22][  200/  341]    Overall Loss 2.630424    Objective Loss 2.630424                                        LR 0.001000    Time 0.065367    
2025-01-06 21:11:37,466 - Epoch: [22][  210/  341]    Overall Loss 2.630516    Objective Loss 2.630516                                        LR 0.001000    Time 0.063504    
2025-01-06 21:11:37,702 - Epoch: [22][  220/  341]    Overall Loss 2.630654    Objective Loss 2.630654                                        LR 0.001000    Time 0.061689    
2025-01-06 21:11:37,939 - Epoch: [22][  230/  341]    Overall Loss 2.629954    Objective Loss 2.629954                                        LR 0.001000    Time 0.060041    
2025-01-06 21:11:38,172 - Epoch: [22][  240/  341]    Overall Loss 2.629292    Objective Loss 2.629292                                        LR 0.001000    Time 0.058509    
2025-01-06 21:11:38,402 - Epoch: [22][  250/  341]    Overall Loss 2.629017    Objective Loss 2.629017                                        LR 0.001000    Time 0.057087    
2025-01-06 21:11:38,637 - Epoch: [22][  260/  341]    Overall Loss 2.628789    Objective Loss 2.628789                                        LR 0.001000    Time 0.055795    
2025-01-06 21:11:38,869 - Epoch: [22][  270/  341]    Overall Loss 2.628348    Objective Loss 2.628348                                        LR 0.001000    Time 0.054588    
2025-01-06 21:11:39,109 - Epoch: [22][  280/  341]    Overall Loss 2.628336    Objective Loss 2.628336                                        LR 0.001000    Time 0.053498    
2025-01-06 21:11:39,341 - Epoch: [22][  290/  341]    Overall Loss 2.628329    Objective Loss 2.628329                                        LR 0.001000    Time 0.052450    
2025-01-06 21:11:39,569 - Epoch: [22][  300/  341]    Overall Loss 2.629029    Objective Loss 2.629029                                        LR 0.001000    Time 0.051463    
2025-01-06 21:11:39,811 - Epoch: [22][  310/  341]    Overall Loss 2.629231    Objective Loss 2.629231                                        LR 0.001000    Time 0.050583    
2025-01-06 21:11:40,065 - Epoch: [22][  320/  341]    Overall Loss 2.629381    Objective Loss 2.629381                                        LR 0.001000    Time 0.049795    
2025-01-06 21:11:40,309 - Epoch: [22][  330/  341]    Overall Loss 2.629534    Objective Loss 2.629534                                        LR 0.001000    Time 0.049026    
2025-01-06 21:11:40,568 - Epoch: [22][  340/  341]    Overall Loss 2.629366    Objective Loss 2.629366    Top1 7.421875    Top5 32.421875    LR 0.001000    Time 0.048347    
2025-01-06 21:11:40,591 - Epoch: [22][  341/  341]    Overall Loss 2.629587    Objective Loss 2.629587    Top1 8.312343    Top5 30.478589    LR 0.001000    Time 0.048273    
2025-01-06 21:11:42,365 - --- validate (epoch=22)-----------
2025-01-06 21:11:42,369 - 15217 samples (256 per mini-batch)
2025-01-06 21:11:51,044 - Epoch: [22][   10/   60]    Loss 3.142102    Top1 0.078125    Top5 0.507813    
2025-01-06 21:11:51,258 - Epoch: [22][   20/   60]    Loss 3.144046    Top1 0.078125    Top5 0.429687    
2025-01-06 21:11:51,470 - Epoch: [22][   30/   60]    Loss 3.141715    Top1 0.078125    Top5 0.546875    
2025-01-06 21:11:51,681 - Epoch: [22][   40/   60]    Loss 3.141562    Top1 0.078125    Top5 0.537109    
2025-01-06 21:11:51,894 - Epoch: [22][   50/   60]    Loss 3.142590    Top1 0.078125    Top5 0.468750    
2025-01-06 21:11:52,076 - Epoch: [22][   60/   60]    Loss 3.143198    Top1 0.072288    Top5 0.460012    
2025-01-06 21:11:53,584 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.143

2025-01-06 21:11:53,584 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:11:54,269 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:11:54,272 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:11:54,284 - 

2025-01-06 21:11:54,284 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:12:03,167 - Epoch: [23][   10/  341]    Overall Loss 2.620514    Objective Loss 2.620514                                        LR 0.001000    Time 0.888242    
2025-01-06 21:12:03,400 - Epoch: [23][   20/  341]    Overall Loss 2.622942    Objective Loss 2.622942                                        LR 0.001000    Time 0.455808    
2025-01-06 21:12:03,638 - Epoch: [23][   30/  341]    Overall Loss 2.625881    Objective Loss 2.625881                                        LR 0.001000    Time 0.311248    
2025-01-06 21:12:03,879 - Epoch: [23][   40/  341]    Overall Loss 2.628433    Objective Loss 2.628433                                        LR 0.001000    Time 0.239059    
2025-01-06 21:12:04,126 - Epoch: [23][   50/  341]    Overall Loss 2.629009    Objective Loss 2.629009                                        LR 0.001000    Time 0.196143    
2025-01-06 21:12:04,360 - Epoch: [23][   60/  341]    Overall Loss 2.629159    Objective Loss 2.629159                                        LR 0.001000    Time 0.167341    
2025-01-06 21:12:04,584 - Epoch: [23][   70/  341]    Overall Loss 2.632235    Objective Loss 2.632235                                        LR 0.001000    Time 0.146633    
2025-01-06 21:12:04,821 - Epoch: [23][   80/  341]    Overall Loss 2.630565    Objective Loss 2.630565                                        LR 0.001000    Time 0.131265    
2025-01-06 21:12:05,045 - Epoch: [23][   90/  341]    Overall Loss 2.629339    Objective Loss 2.629339                                        LR 0.001000    Time 0.119172    
2025-01-06 21:12:05,290 - Epoch: [23][  100/  341]    Overall Loss 2.629394    Objective Loss 2.629394                                        LR 0.001000    Time 0.109710    
2025-01-06 21:12:05,514 - Epoch: [23][  110/  341]    Overall Loss 2.630408    Objective Loss 2.630408                                        LR 0.001000    Time 0.101766    
2025-01-06 21:12:05,748 - Epoch: [23][  120/  341]    Overall Loss 2.630088    Objective Loss 2.630088                                        LR 0.001000    Time 0.095235    
2025-01-06 21:12:05,971 - Epoch: [23][  130/  341]    Overall Loss 2.630459    Objective Loss 2.630459                                        LR 0.001000    Time 0.089628    
2025-01-06 21:12:06,213 - Epoch: [23][  140/  341]    Overall Loss 2.630900    Objective Loss 2.630900                                        LR 0.001000    Time 0.084953    
2025-01-06 21:12:06,448 - Epoch: [23][  150/  341]    Overall Loss 2.631044    Objective Loss 2.631044                                        LR 0.001000    Time 0.080856    
2025-01-06 21:12:06,681 - Epoch: [23][  160/  341]    Overall Loss 2.630457    Objective Loss 2.630457                                        LR 0.001000    Time 0.077261    
2025-01-06 21:12:06,910 - Epoch: [23][  170/  341]    Overall Loss 2.630608    Objective Loss 2.630608                                        LR 0.001000    Time 0.074065    
2025-01-06 21:12:07,165 - Epoch: [23][  180/  341]    Overall Loss 2.629919    Objective Loss 2.629919                                        LR 0.001000    Time 0.071363    
2025-01-06 21:12:07,398 - Epoch: [23][  190/  341]    Overall Loss 2.630015    Objective Loss 2.630015                                        LR 0.001000    Time 0.068834    
2025-01-06 21:12:07,629 - Epoch: [23][  200/  341]    Overall Loss 2.629995    Objective Loss 2.629995                                        LR 0.001000    Time 0.066548    
2025-01-06 21:12:07,872 - Epoch: [23][  210/  341]    Overall Loss 2.630639    Objective Loss 2.630639                                        LR 0.001000    Time 0.064536    
2025-01-06 21:12:08,115 - Epoch: [23][  220/  341]    Overall Loss 2.631012    Objective Loss 2.631012                                        LR 0.001000    Time 0.062703    
2025-01-06 21:12:08,358 - Epoch: [23][  230/  341]    Overall Loss 2.631329    Objective Loss 2.631329                                        LR 0.001000    Time 0.060989    
2025-01-06 21:12:08,603 - Epoch: [23][  240/  341]    Overall Loss 2.631618    Objective Loss 2.631618                                        LR 0.001000    Time 0.059467    
2025-01-06 21:12:08,837 - Epoch: [23][  250/  341]    Overall Loss 2.630748    Objective Loss 2.630748                                        LR 0.001000    Time 0.058025    
2025-01-06 21:12:09,082 - Epoch: [23][  260/  341]    Overall Loss 2.630459    Objective Loss 2.630459                                        LR 0.001000    Time 0.056734    
2025-01-06 21:12:09,324 - Epoch: [23][  270/  341]    Overall Loss 2.629949    Objective Loss 2.629949                                        LR 0.001000    Time 0.055530    
2025-01-06 21:12:09,557 - Epoch: [23][  280/  341]    Overall Loss 2.630083    Objective Loss 2.630083                                        LR 0.001000    Time 0.054378    
2025-01-06 21:12:09,798 - Epoch: [23][  290/  341]    Overall Loss 2.629729    Objective Loss 2.629729                                        LR 0.001000    Time 0.053300    
2025-01-06 21:12:10,039 - Epoch: [23][  300/  341]    Overall Loss 2.629530    Objective Loss 2.629530                                        LR 0.001000    Time 0.052327    
2025-01-06 21:12:10,266 - Epoch: [23][  310/  341]    Overall Loss 2.629644    Objective Loss 2.629644                                        LR 0.001000    Time 0.051372    
2025-01-06 21:12:10,500 - Epoch: [23][  320/  341]    Overall Loss 2.628810    Objective Loss 2.628810                                        LR 0.001000    Time 0.050496    
2025-01-06 21:12:10,760 - Epoch: [23][  330/  341]    Overall Loss 2.628511    Objective Loss 2.628511                                        LR 0.001000    Time 0.049756    
2025-01-06 21:12:11,013 - Epoch: [23][  340/  341]    Overall Loss 2.628750    Objective Loss 2.628750    Top1 9.765625    Top5 35.546875    LR 0.001000    Time 0.049037    
2025-01-06 21:12:11,031 - Epoch: [23][  341/  341]    Overall Loss 2.628820    Objective Loss 2.628820    Top1 9.571788    Top5 35.516373    LR 0.001000    Time 0.048945    
2025-01-06 21:12:13,074 - --- validate (epoch=23)-----------
2025-01-06 21:12:13,074 - 15217 samples (256 per mini-batch)
2025-01-06 21:12:21,722 - Epoch: [23][   10/   60]    Loss 3.083040    Top1 0.117188    Top5 0.546875    
2025-01-06 21:12:21,933 - Epoch: [23][   20/   60]    Loss 3.081380    Top1 0.097656    Top5 0.527344    
2025-01-06 21:12:22,175 - Epoch: [23][   30/   60]    Loss 3.082795    Top1 0.065104    Top5 0.481771    
2025-01-06 21:12:22,378 - Epoch: [23][   40/   60]    Loss 3.083366    Top1 0.058594    Top5 0.410156    
2025-01-06 21:12:22,591 - Epoch: [23][   50/   60]    Loss 3.082985    Top1 0.070313    Top5 0.453125    
2025-01-06 21:12:22,769 - Epoch: [23][   60/   60]    Loss 3.082706    Top1 0.072288    Top5 0.460012    
2025-01-06 21:12:24,338 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.083

2025-01-06 21:12:24,340 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:12:25,150 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:12:25,150 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:12:25,154 - 

2025-01-06 21:12:25,154 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:12:33,659 - Epoch: [24][   10/  341]    Overall Loss 2.631109    Objective Loss 2.631109                                        LR 0.001000    Time 0.849477    
2025-01-06 21:12:33,899 - Epoch: [24][   20/  341]    Overall Loss 2.627147    Objective Loss 2.627147                                        LR 0.001000    Time 0.436713    
2025-01-06 21:12:34,140 - Epoch: [24][   30/  341]    Overall Loss 2.625430    Objective Loss 2.625430                                        LR 0.001000    Time 0.299178    
2025-01-06 21:12:34,382 - Epoch: [24][   40/  341]    Overall Loss 2.624189    Objective Loss 2.624189                                        LR 0.001000    Time 0.230186    
2025-01-06 21:12:34,614 - Epoch: [24][   50/  341]    Overall Loss 2.625329    Objective Loss 2.625329                                        LR 0.001000    Time 0.188794    
2025-01-06 21:12:34,852 - Epoch: [24][   60/  341]    Overall Loss 2.627068    Objective Loss 2.627068                                        LR 0.001000    Time 0.161287    
2025-01-06 21:12:35,095 - Epoch: [24][   70/  341]    Overall Loss 2.629921    Objective Loss 2.629921                                        LR 0.001000    Time 0.141720    
2025-01-06 21:12:35,329 - Epoch: [24][   80/  341]    Overall Loss 2.629245    Objective Loss 2.629245                                        LR 0.001000    Time 0.126934    
2025-01-06 21:12:35,562 - Epoch: [24][   90/  341]    Overall Loss 2.629821    Objective Loss 2.629821                                        LR 0.001000    Time 0.115298    
2025-01-06 21:12:35,788 - Epoch: [24][  100/  341]    Overall Loss 2.627116    Objective Loss 2.627116                                        LR 0.001000    Time 0.106025    
2025-01-06 21:12:36,022 - Epoch: [24][  110/  341]    Overall Loss 2.628210    Objective Loss 2.628210                                        LR 0.001000    Time 0.098521    
2025-01-06 21:12:36,263 - Epoch: [24][  120/  341]    Overall Loss 2.630186    Objective Loss 2.630186                                        LR 0.001000    Time 0.092320    
2025-01-06 21:12:36,496 - Epoch: [24][  130/  341]    Overall Loss 2.630457    Objective Loss 2.630457                                        LR 0.001000    Time 0.086928    
2025-01-06 21:12:36,727 - Epoch: [24][  140/  341]    Overall Loss 2.631711    Objective Loss 2.631711                                        LR 0.001000    Time 0.082371    
2025-01-06 21:12:36,962 - Epoch: [24][  150/  341]    Overall Loss 2.630751    Objective Loss 2.630751                                        LR 0.001000    Time 0.078374    
2025-01-06 21:12:37,222 - Epoch: [24][  160/  341]    Overall Loss 2.630624    Objective Loss 2.630624                                        LR 0.001000    Time 0.075088    
2025-01-06 21:12:37,461 - Epoch: [24][  170/  341]    Overall Loss 2.630208    Objective Loss 2.630208                                        LR 0.001000    Time 0.072077    
2025-01-06 21:12:37,694 - Epoch: [24][  180/  341]    Overall Loss 2.630489    Objective Loss 2.630489                                        LR 0.001000    Time 0.069367    
2025-01-06 21:12:37,930 - Epoch: [24][  190/  341]    Overall Loss 2.630896    Objective Loss 2.630896                                        LR 0.001000    Time 0.066958    
2025-01-06 21:12:38,183 - Epoch: [24][  200/  341]    Overall Loss 2.630482    Objective Loss 2.630482                                        LR 0.001000    Time 0.064875    
2025-01-06 21:12:38,419 - Epoch: [24][  210/  341]    Overall Loss 2.629084    Objective Loss 2.629084                                        LR 0.001000    Time 0.062911    
2025-01-06 21:12:38,662 - Epoch: [24][  220/  341]    Overall Loss 2.628359    Objective Loss 2.628359                                        LR 0.001000    Time 0.061157    
2025-01-06 21:12:38,897 - Epoch: [24][  230/  341]    Overall Loss 2.627883    Objective Loss 2.627883                                        LR 0.001000    Time 0.059520    
2025-01-06 21:12:39,146 - Epoch: [24][  240/  341]    Overall Loss 2.628070    Objective Loss 2.628070                                        LR 0.001000    Time 0.058076    
2025-01-06 21:12:39,392 - Epoch: [24][  250/  341]    Overall Loss 2.627826    Objective Loss 2.627826                                        LR 0.001000    Time 0.056737    
2025-01-06 21:12:39,622 - Epoch: [24][  260/  341]    Overall Loss 2.627598    Objective Loss 2.627598                                        LR 0.001000    Time 0.055440    
2025-01-06 21:12:39,858 - Epoch: [24][  270/  341]    Overall Loss 2.627739    Objective Loss 2.627739                                        LR 0.001000    Time 0.054262    
2025-01-06 21:12:40,094 - Epoch: [24][  280/  341]    Overall Loss 2.628699    Objective Loss 2.628699                                        LR 0.001000    Time 0.053167    
2025-01-06 21:12:40,326 - Epoch: [24][  290/  341]    Overall Loss 2.628984    Objective Loss 2.628984                                        LR 0.001000    Time 0.052130    
2025-01-06 21:12:40,563 - Epoch: [24][  300/  341]    Overall Loss 2.628957    Objective Loss 2.628957                                        LR 0.001000    Time 0.051184    
2025-01-06 21:12:40,807 - Epoch: [24][  310/  341]    Overall Loss 2.628528    Objective Loss 2.628528                                        LR 0.001000    Time 0.050319    
2025-01-06 21:12:41,037 - Epoch: [24][  320/  341]    Overall Loss 2.628612    Objective Loss 2.628612                                        LR 0.001000    Time 0.049467    
2025-01-06 21:12:41,282 - Epoch: [24][  330/  341]    Overall Loss 2.628710    Objective Loss 2.628710                                        LR 0.001000    Time 0.048710    
2025-01-06 21:12:41,536 - Epoch: [24][  340/  341]    Overall Loss 2.628542    Objective Loss 2.628542    Top1 10.546875    Top5 37.500000    LR 0.001000    Time 0.048025    
2025-01-06 21:12:41,560 - Epoch: [24][  341/  341]    Overall Loss 2.628601    Objective Loss 2.628601    Top1 9.823678    Top5 37.279597    LR 0.001000    Time 0.047954    
2025-01-06 21:12:43,347 - --- validate (epoch=24)-----------
2025-01-06 21:12:43,347 - 15217 samples (256 per mini-batch)
2025-01-06 21:12:52,069 - Epoch: [24][   10/   60]    Loss 3.165678    Top1 0.078125    Top5 0.312500    
2025-01-06 21:12:52,287 - Epoch: [24][   20/   60]    Loss 3.163737    Top1 0.078125    Top5 0.410156    
2025-01-06 21:12:52,489 - Epoch: [24][   30/   60]    Loss 3.161000    Top1 0.078125    Top5 0.468750    
2025-01-06 21:12:52,707 - Epoch: [24][   40/   60]    Loss 3.161939    Top1 0.078125    Top5 0.449219    
2025-01-06 21:12:52,902 - Epoch: [24][   50/   60]    Loss 3.160851    Top1 0.078125    Top5 0.453125    
2025-01-06 21:12:53,080 - Epoch: [24][   60/   60]    Loss 3.159972    Top1 0.072288    Top5 0.460012    
2025-01-06 21:12:54,663 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.160

2025-01-06 21:12:54,663 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:12:55,125 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:12:55,125 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:12:55,143 - 

2025-01-06 21:12:55,143 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:13:03,664 - Epoch: [25][   10/  341]    Overall Loss 2.632211    Objective Loss 2.632211                                        LR 0.001000    Time 0.852092    
2025-01-06 21:13:03,899 - Epoch: [25][   20/  341]    Overall Loss 2.625665    Objective Loss 2.625665                                        LR 0.001000    Time 0.437786    
2025-01-06 21:13:04,129 - Epoch: [25][   30/  341]    Overall Loss 2.623874    Objective Loss 2.623874                                        LR 0.001000    Time 0.299551    
2025-01-06 21:13:04,370 - Epoch: [25][   40/  341]    Overall Loss 2.624968    Objective Loss 2.624968                                        LR 0.001000    Time 0.230566    
2025-01-06 21:13:04,598 - Epoch: [25][   50/  341]    Overall Loss 2.624935    Objective Loss 2.624935                                        LR 0.001000    Time 0.189010    
2025-01-06 21:13:04,826 - Epoch: [25][   60/  341]    Overall Loss 2.626531    Objective Loss 2.626531                                        LR 0.001000    Time 0.161284    
2025-01-06 21:13:05,067 - Epoch: [25][   70/  341]    Overall Loss 2.628973    Objective Loss 2.628973                                        LR 0.001000    Time 0.141683    
2025-01-06 21:13:05,299 - Epoch: [25][   80/  341]    Overall Loss 2.627471    Objective Loss 2.627471                                        LR 0.001000    Time 0.126871    
2025-01-06 21:13:05,532 - Epoch: [25][   90/  341]    Overall Loss 2.627897    Objective Loss 2.627897                                        LR 0.001000    Time 0.115367    
2025-01-06 21:13:05,774 - Epoch: [25][  100/  341]    Overall Loss 2.627793    Objective Loss 2.627793                                        LR 0.001000    Time 0.106249    
2025-01-06 21:13:06,005 - Epoch: [25][  110/  341]    Overall Loss 2.627526    Objective Loss 2.627526                                        LR 0.001000    Time 0.098686    
2025-01-06 21:13:06,234 - Epoch: [25][  120/  341]    Overall Loss 2.627918    Objective Loss 2.627918                                        LR 0.001000    Time 0.092373    
2025-01-06 21:13:06,470 - Epoch: [25][  130/  341]    Overall Loss 2.626476    Objective Loss 2.626476                                        LR 0.001000    Time 0.087082    
2025-01-06 21:13:06,708 - Epoch: [25][  140/  341]    Overall Loss 2.626150    Objective Loss 2.626150                                        LR 0.001000    Time 0.082566    
2025-01-06 21:13:06,946 - Epoch: [25][  150/  341]    Overall Loss 2.626967    Objective Loss 2.626967                                        LR 0.001000    Time 0.078645    
2025-01-06 21:13:07,181 - Epoch: [25][  160/  341]    Overall Loss 2.627014    Objective Loss 2.627014                                        LR 0.001000    Time 0.075197    
2025-01-06 21:13:07,420 - Epoch: [25][  170/  341]    Overall Loss 2.626702    Objective Loss 2.626702                                        LR 0.001000    Time 0.072181    
2025-01-06 21:13:07,665 - Epoch: [25][  180/  341]    Overall Loss 2.626732    Objective Loss 2.626732                                        LR 0.001000    Time 0.069531    
2025-01-06 21:13:07,905 - Epoch: [25][  190/  341]    Overall Loss 2.627260    Objective Loss 2.627260                                        LR 0.001000    Time 0.067138    
2025-01-06 21:13:08,141 - Epoch: [25][  200/  341]    Overall Loss 2.627549    Objective Loss 2.627549                                        LR 0.001000    Time 0.064958    
2025-01-06 21:13:08,376 - Epoch: [25][  210/  341]    Overall Loss 2.627728    Objective Loss 2.627728                                        LR 0.001000    Time 0.062981    
2025-01-06 21:13:08,616 - Epoch: [25][  220/  341]    Overall Loss 2.627792    Objective Loss 2.627792                                        LR 0.001000    Time 0.061213    
2025-01-06 21:13:08,852 - Epoch: [25][  230/  341]    Overall Loss 2.627752    Objective Loss 2.627752                                        LR 0.001000    Time 0.059577    
2025-01-06 21:13:09,084 - Epoch: [25][  240/  341]    Overall Loss 2.627878    Objective Loss 2.627878                                        LR 0.001000    Time 0.058060    
2025-01-06 21:13:09,329 - Epoch: [25][  250/  341]    Overall Loss 2.628090    Objective Loss 2.628090                                        LR 0.001000    Time 0.056720    
2025-01-06 21:13:09,562 - Epoch: [25][  260/  341]    Overall Loss 2.628039    Objective Loss 2.628039                                        LR 0.001000    Time 0.055434    
2025-01-06 21:13:09,800 - Epoch: [25][  270/  341]    Overall Loss 2.627941    Objective Loss 2.627941                                        LR 0.001000    Time 0.054263    
2025-01-06 21:13:10,033 - Epoch: [25][  280/  341]    Overall Loss 2.628203    Objective Loss 2.628203                                        LR 0.001000    Time 0.053156    
2025-01-06 21:13:10,269 - Epoch: [25][  290/  341]    Overall Loss 2.628536    Objective Loss 2.628536                                        LR 0.001000    Time 0.052137    
2025-01-06 21:13:10,499 - Epoch: [25][  300/  341]    Overall Loss 2.628701    Objective Loss 2.628701                                        LR 0.001000    Time 0.051165    
2025-01-06 21:13:10,739 - Epoch: [25][  310/  341]    Overall Loss 2.628445    Objective Loss 2.628445                                        LR 0.001000    Time 0.050290    
2025-01-06 21:13:10,972 - Epoch: [25][  320/  341]    Overall Loss 2.628427    Objective Loss 2.628427                                        LR 0.001000    Time 0.049441    
2025-01-06 21:13:11,233 - Epoch: [25][  330/  341]    Overall Loss 2.628475    Objective Loss 2.628475                                        LR 0.001000    Time 0.048731    
2025-01-06 21:13:11,500 - Epoch: [25][  340/  341]    Overall Loss 2.628500    Objective Loss 2.628500    Top1 8.593750    Top5 33.984375    LR 0.001000    Time 0.048085    
2025-01-06 21:13:11,522 - Epoch: [25][  341/  341]    Overall Loss 2.628540    Objective Loss 2.628540    Top1 9.571788    Top5 34.005038    LR 0.001000    Time 0.047996    
2025-01-06 21:13:13,301 - --- validate (epoch=25)-----------
2025-01-06 21:13:13,301 - 15217 samples (256 per mini-batch)
2025-01-06 21:13:22,200 - Epoch: [25][   10/   60]    Loss 3.160815    Top1 0.117188    Top5 0.664062    
2025-01-06 21:13:22,407 - Epoch: [25][   20/   60]    Loss 3.159906    Top1 0.117188    Top5 0.546875    
2025-01-06 21:13:22,617 - Epoch: [25][   30/   60]    Loss 3.162482    Top1 0.078125    Top5 0.442708    
2025-01-06 21:13:22,815 - Epoch: [25][   40/   60]    Loss 3.162537    Top1 0.068359    Top5 0.488281    
2025-01-06 21:13:23,028 - Epoch: [25][   50/   60]    Loss 3.163290    Top1 0.062500    Top5 0.468750    
2025-01-06 21:13:23,209 - Epoch: [25][   60/   60]    Loss 3.162641    Top1 0.072288    Top5 0.460012    
2025-01-06 21:13:24,673 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.163

2025-01-06 21:13:24,673 - ==> Confusion:
[[   0    0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:13:25,142 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:13:25,142 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:13:25,160 - 

2025-01-06 21:13:25,160 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:13:33,915 - Epoch: [26][   10/  341]    Overall Loss 2.624007    Objective Loss 2.624007                                        LR 0.001000    Time 0.875199    
2025-01-06 21:13:34,152 - Epoch: [26][   20/  341]    Overall Loss 2.619232    Objective Loss 2.619232                                        LR 0.001000    Time 0.449413    
2025-01-06 21:13:34,393 - Epoch: [26][   30/  341]    Overall Loss 2.621692    Objective Loss 2.621692                                        LR 0.001000    Time 0.307583    
2025-01-06 21:13:34,621 - Epoch: [26][   40/  341]    Overall Loss 2.624359    Objective Loss 2.624359                                        LR 0.001000    Time 0.236385    
2025-01-06 21:13:34,842 - Epoch: [26][   50/  341]    Overall Loss 2.624671    Objective Loss 2.624671                                        LR 0.001000    Time 0.193535    
2025-01-06 21:13:35,079 - Epoch: [26][   60/  341]    Overall Loss 2.624489    Objective Loss 2.624489                                        LR 0.001000    Time 0.165227    
2025-01-06 21:13:35,308 - Epoch: [26][   70/  341]    Overall Loss 2.623071    Objective Loss 2.623071                                        LR 0.001000    Time 0.144897    
2025-01-06 21:13:35,541 - Epoch: [26][   80/  341]    Overall Loss 2.624541    Objective Loss 2.624541                                        LR 0.001000    Time 0.129698    
2025-01-06 21:13:35,771 - Epoch: [26][   90/  341]    Overall Loss 2.625082    Objective Loss 2.625082                                        LR 0.001000    Time 0.117844    
2025-01-06 21:13:35,993 - Epoch: [26][  100/  341]    Overall Loss 2.625125    Objective Loss 2.625125                                        LR 0.001000    Time 0.108282    
2025-01-06 21:13:36,229 - Epoch: [26][  110/  341]    Overall Loss 2.625545    Objective Loss 2.625545                                        LR 0.001000    Time 0.100579    
2025-01-06 21:13:36,467 - Epoch: [26][  120/  341]    Overall Loss 2.626573    Objective Loss 2.626573                                        LR 0.001000    Time 0.094178    
2025-01-06 21:13:36,716 - Epoch: [26][  130/  341]    Overall Loss 2.627658    Objective Loss 2.627658                                        LR 0.001000    Time 0.088849    
2025-01-06 21:13:36,943 - Epoch: [26][  140/  341]    Overall Loss 2.628682    Objective Loss 2.628682                                        LR 0.001000    Time 0.084128    
2025-01-06 21:13:37,184 - Epoch: [26][  150/  341]    Overall Loss 2.630021    Objective Loss 2.630021                                        LR 0.001000    Time 0.080126    
2025-01-06 21:13:37,419 - Epoch: [26][  160/  341]    Overall Loss 2.629104    Objective Loss 2.629104                                        LR 0.001000    Time 0.076584    
2025-01-06 21:13:37,655 - Epoch: [26][  170/  341]    Overall Loss 2.629280    Objective Loss 2.629280                                        LR 0.001000    Time 0.073471    
2025-01-06 21:13:37,888 - Epoch: [26][  180/  341]    Overall Loss 2.629305    Objective Loss 2.629305                                        LR 0.001000    Time 0.070681    
2025-01-06 21:13:38,120 - Epoch: [26][  190/  341]    Overall Loss 2.629301    Objective Loss 2.629301                                        LR 0.001000    Time 0.068182    
2025-01-06 21:13:38,359 - Epoch: [26][  200/  341]    Overall Loss 2.628557    Objective Loss 2.628557                                        LR 0.001000    Time 0.065969    
2025-01-06 21:13:38,592 - Epoch: [26][  210/  341]    Overall Loss 2.628883    Objective Loss 2.628883                                        LR 0.001000    Time 0.063936    
2025-01-06 21:13:38,833 - Epoch: [26][  220/  341]    Overall Loss 2.628765    Objective Loss 2.628765                                        LR 0.001000    Time 0.062127    
2025-01-06 21:13:39,066 - Epoch: [26][  230/  341]    Overall Loss 2.629390    Objective Loss 2.629390                                        LR 0.001000    Time 0.060440    
2025-01-06 21:13:39,295 - Epoch: [26][  240/  341]    Overall Loss 2.629102    Objective Loss 2.629102                                        LR 0.001000    Time 0.058874    
2025-01-06 21:13:39,542 - Epoch: [26][  250/  341]    Overall Loss 2.629526    Objective Loss 2.629526                                        LR 0.001000    Time 0.057465    
2025-01-06 21:13:39,782 - Epoch: [26][  260/  341]    Overall Loss 2.629862    Objective Loss 2.629862                                        LR 0.001000    Time 0.056181    
2025-01-06 21:13:40,015 - Epoch: [26][  270/  341]    Overall Loss 2.629865    Objective Loss 2.629865                                        LR 0.001000    Time 0.054939    
2025-01-06 21:13:40,267 - Epoch: [26][  280/  341]    Overall Loss 2.629337    Objective Loss 2.629337                                        LR 0.001000    Time 0.053878    
2025-01-06 21:13:40,514 - Epoch: [26][  290/  341]    Overall Loss 2.629107    Objective Loss 2.629107                                        LR 0.001000    Time 0.052870    
2025-01-06 21:13:40,751 - Epoch: [26][  300/  341]    Overall Loss 2.629116    Objective Loss 2.629116                                        LR 0.001000    Time 0.051863    
2025-01-06 21:13:40,986 - Epoch: [26][  310/  341]    Overall Loss 2.628986    Objective Loss 2.628986                                        LR 0.001000    Time 0.050916    
2025-01-06 21:13:41,217 - Epoch: [26][  320/  341]    Overall Loss 2.628576    Objective Loss 2.628576                                        LR 0.001000    Time 0.050046    
2025-01-06 21:13:41,458 - Epoch: [26][  330/  341]    Overall Loss 2.628862    Objective Loss 2.628862                                        LR 0.001000    Time 0.049259    
2025-01-06 21:13:41,711 - Epoch: [26][  340/  341]    Overall Loss 2.628669    Objective Loss 2.628669    Top1 9.765625    Top5 36.328125    LR 0.001000    Time 0.048556    
2025-01-06 21:13:41,740 - Epoch: [26][  341/  341]    Overall Loss 2.628321    Objective Loss 2.628321    Top1 11.083123    Top5 37.279597    LR 0.001000    Time 0.048499    
2025-01-06 21:13:43,427 - --- validate (epoch=26)-----------
2025-01-06 21:13:43,429 - 15217 samples (256 per mini-batch)
2025-01-06 21:13:52,152 - Epoch: [26][   10/   60]    Loss 3.209207    Top1 0.078125    Top5 0.546875    
2025-01-06 21:13:52,356 - Epoch: [26][   20/   60]    Loss 3.214269    Top1 0.039062    Top5 0.527344    
2025-01-06 21:13:52,593 - Epoch: [26][   30/   60]    Loss 3.216137    Top1 0.052083    Top5 0.494792    
2025-01-06 21:13:52,796 - Epoch: [26][   40/   60]    Loss 3.216915    Top1 0.048828    Top5 0.478516    
2025-01-06 21:13:53,001 - Epoch: [26][   50/   60]    Loss 3.216178    Top1 0.070313    Top5 0.468750    
2025-01-06 21:13:53,177 - Epoch: [26][   60/   60]    Loss 3.216007    Top1 0.072288    Top5 0.460012    
2025-01-06 21:13:54,722 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.216

2025-01-06 21:13:54,722 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:13:55,196 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:13:55,196 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:13:55,201 - 

2025-01-06 21:13:55,201 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:14:03,908 - Epoch: [27][   10/  341]    Overall Loss 2.632318    Objective Loss 2.632318                                        LR 0.001000    Time 0.869662    
2025-01-06 21:14:04,153 - Epoch: [27][   20/  341]    Overall Loss 2.634418    Objective Loss 2.634418                                        LR 0.001000    Time 0.447096    
2025-01-06 21:14:04,386 - Epoch: [27][   30/  341]    Overall Loss 2.636739    Objective Loss 2.636739                                        LR 0.001000    Time 0.305827    
2025-01-06 21:14:04,612 - Epoch: [27][   40/  341]    Overall Loss 2.635202    Objective Loss 2.635202                                        LR 0.001000    Time 0.235030    
2025-01-06 21:14:04,842 - Epoch: [27][   50/  341]    Overall Loss 2.633028    Objective Loss 2.633028                                        LR 0.001000    Time 0.192616    
2025-01-06 21:14:05,074 - Epoch: [27][   60/  341]    Overall Loss 2.634896    Objective Loss 2.634896                                        LR 0.001000    Time 0.164205    
2025-01-06 21:14:05,306 - Epoch: [27][   70/  341]    Overall Loss 2.633516    Objective Loss 2.633516                                        LR 0.001000    Time 0.144057    
2025-01-06 21:14:05,531 - Epoch: [27][   80/  341]    Overall Loss 2.633252    Objective Loss 2.633252                                        LR 0.001000    Time 0.128873    
2025-01-06 21:14:05,770 - Epoch: [27][   90/  341]    Overall Loss 2.633691    Objective Loss 2.633691                                        LR 0.001000    Time 0.117200    
2025-01-06 21:14:05,997 - Epoch: [27][  100/  341]    Overall Loss 2.634086    Objective Loss 2.634086                                        LR 0.001000    Time 0.107752    
2025-01-06 21:14:06,229 - Epoch: [27][  110/  341]    Overall Loss 2.632191    Objective Loss 2.632191                                        LR 0.001000    Time 0.100063    
2025-01-06 21:14:06,463 - Epoch: [27][  120/  341]    Overall Loss 2.633001    Objective Loss 2.633001                                        LR 0.001000    Time 0.093677    
2025-01-06 21:14:06,685 - Epoch: [27][  130/  341]    Overall Loss 2.632405    Objective Loss 2.632405                                        LR 0.001000    Time 0.088177    
2025-01-06 21:14:06,926 - Epoch: [27][  140/  341]    Overall Loss 2.632441    Objective Loss 2.632441                                        LR 0.001000    Time 0.083601    
2025-01-06 21:14:07,149 - Epoch: [27][  150/  341]    Overall Loss 2.631160    Objective Loss 2.631160                                        LR 0.001000    Time 0.079516    
2025-01-06 21:14:07,372 - Epoch: [27][  160/  341]    Overall Loss 2.631226    Objective Loss 2.631226                                        LR 0.001000    Time 0.075935    
2025-01-06 21:14:07,605 - Epoch: [27][  170/  341]    Overall Loss 2.631166    Objective Loss 2.631166                                        LR 0.001000    Time 0.072835    
2025-01-06 21:14:07,838 - Epoch: [27][  180/  341]    Overall Loss 2.631921    Objective Loss 2.631921                                        LR 0.001000    Time 0.070088    
2025-01-06 21:14:08,068 - Epoch: [27][  190/  341]    Overall Loss 2.631640    Objective Loss 2.631640                                        LR 0.001000    Time 0.067608    
2025-01-06 21:14:08,298 - Epoch: [27][  200/  341]    Overall Loss 2.631210    Objective Loss 2.631210                                        LR 0.001000    Time 0.065376    
2025-01-06 21:14:08,534 - Epoch: [27][  210/  341]    Overall Loss 2.631456    Objective Loss 2.631456                                        LR 0.001000    Time 0.063389    
2025-01-06 21:14:08,762 - Epoch: [27][  220/  341]    Overall Loss 2.630393    Objective Loss 2.630393                                        LR 0.001000    Time 0.061540    
2025-01-06 21:14:09,004 - Epoch: [27][  230/  341]    Overall Loss 2.630581    Objective Loss 2.630581                                        LR 0.001000    Time 0.059917    
2025-01-06 21:14:09,236 - Epoch: [27][  240/  341]    Overall Loss 2.630106    Objective Loss 2.630106                                        LR 0.001000    Time 0.058390    
2025-01-06 21:14:09,470 - Epoch: [27][  250/  341]    Overall Loss 2.630403    Objective Loss 2.630403                                        LR 0.001000    Time 0.056989    
2025-01-06 21:14:09,714 - Epoch: [27][  260/  341]    Overall Loss 2.630876    Objective Loss 2.630876                                        LR 0.001000    Time 0.055737    
2025-01-06 21:14:09,963 - Epoch: [27][  270/  341]    Overall Loss 2.630786    Objective Loss 2.630786                                        LR 0.001000    Time 0.054595    
2025-01-06 21:14:10,202 - Epoch: [27][  280/  341]    Overall Loss 2.630740    Objective Loss 2.630740                                        LR 0.001000    Time 0.053498    
2025-01-06 21:14:10,435 - Epoch: [27][  290/  341]    Overall Loss 2.629851    Objective Loss 2.629851                                        LR 0.001000    Time 0.052455    
2025-01-06 21:14:10,666 - Epoch: [27][  300/  341]    Overall Loss 2.629245    Objective Loss 2.629245                                        LR 0.001000    Time 0.051477    
2025-01-06 21:14:10,906 - Epoch: [27][  310/  341]    Overall Loss 2.629255    Objective Loss 2.629255                                        LR 0.001000    Time 0.050591    
2025-01-06 21:14:11,132 - Epoch: [27][  320/  341]    Overall Loss 2.629151    Objective Loss 2.629151                                        LR 0.001000    Time 0.049716    
2025-01-06 21:14:11,385 - Epoch: [27][  330/  341]    Overall Loss 2.629272    Objective Loss 2.629272                                        LR 0.001000    Time 0.048952    
2025-01-06 21:14:11,625 - Epoch: [27][  340/  341]    Overall Loss 2.629324    Objective Loss 2.629324    Top1 7.812500    Top5 32.812500    LR 0.001000    Time 0.048219    
2025-01-06 21:14:11,652 - Epoch: [27][  341/  341]    Overall Loss 2.629348    Objective Loss 2.629348    Top1 8.312343    Top5 32.745592    LR 0.001000    Time 0.048159    
2025-01-06 21:14:13,385 - --- validate (epoch=27)-----------
2025-01-06 21:14:13,385 - 15217 samples (256 per mini-batch)
2025-01-06 21:14:22,006 - Epoch: [27][   10/   60]    Loss 3.113197    Top1 0.078125    Top5 0.625000    
2025-01-06 21:14:22,223 - Epoch: [27][   20/   60]    Loss 3.113329    Top1 0.097656    Top5 0.644531    
2025-01-06 21:14:22,443 - Epoch: [27][   30/   60]    Loss 3.113337    Top1 0.078125    Top5 0.598958    
2025-01-06 21:14:22,645 - Epoch: [27][   40/   60]    Loss 3.115309    Top1 0.078125    Top5 0.517578    
2025-01-06 21:14:22,847 - Epoch: [27][   50/   60]    Loss 3.116231    Top1 0.078125    Top5 0.476562    
2025-01-06 21:14:23,024 - Epoch: [27][   60/   60]    Loss 3.116099    Top1 0.072288    Top5 0.460012    
2025-01-06 21:14:24,631 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.116

2025-01-06 21:14:24,631 - ==> Confusion:
[[   0    0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:14:25,097 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:14:25,097 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:14:25,112 - 

2025-01-06 21:14:25,112 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:14:33,899 - Epoch: [28][   10/  341]    Overall Loss 2.653099    Objective Loss 2.653099                                        LR 0.001000    Time 0.878587    
2025-01-06 21:14:34,131 - Epoch: [28][   20/  341]    Overall Loss 2.637754    Objective Loss 2.637754                                        LR 0.001000    Time 0.450936    
2025-01-06 21:14:34,371 - Epoch: [28][   30/  341]    Overall Loss 2.634279    Objective Loss 2.634279                                        LR 0.001000    Time 0.308557    
2025-01-06 21:14:34,602 - Epoch: [28][   40/  341]    Overall Loss 2.630557    Objective Loss 2.630557                                        LR 0.001000    Time 0.237174    
2025-01-06 21:14:34,836 - Epoch: [28][   50/  341]    Overall Loss 2.629748    Objective Loss 2.629748                                        LR 0.001000    Time 0.194434    
2025-01-06 21:14:35,072 - Epoch: [28][   60/  341]    Overall Loss 2.629075    Objective Loss 2.629075                                        LR 0.001000    Time 0.165961    
2025-01-06 21:14:35,308 - Epoch: [28][   70/  341]    Overall Loss 2.628021    Objective Loss 2.628021                                        LR 0.001000    Time 0.145612    
2025-01-06 21:14:35,544 - Epoch: [28][   80/  341]    Overall Loss 2.630748    Objective Loss 2.630748                                        LR 0.001000    Time 0.130347    
2025-01-06 21:14:35,779 - Epoch: [28][   90/  341]    Overall Loss 2.631469    Objective Loss 2.631469                                        LR 0.001000    Time 0.118465    
2025-01-06 21:14:36,014 - Epoch: [28][  100/  341]    Overall Loss 2.631756    Objective Loss 2.631756                                        LR 0.001000    Time 0.108955    
2025-01-06 21:14:36,235 - Epoch: [28][  110/  341]    Overall Loss 2.631481    Objective Loss 2.631481                                        LR 0.001000    Time 0.101059    
2025-01-06 21:14:36,480 - Epoch: [28][  120/  341]    Overall Loss 2.631248    Objective Loss 2.631248                                        LR 0.001000    Time 0.094685    
2025-01-06 21:14:36,724 - Epoch: [28][  130/  341]    Overall Loss 2.629487    Objective Loss 2.629487                                        LR 0.001000    Time 0.089278    
2025-01-06 21:14:36,943 - Epoch: [28][  140/  341]    Overall Loss 2.629033    Objective Loss 2.629033                                        LR 0.001000    Time 0.084465    
2025-01-06 21:14:37,183 - Epoch: [28][  150/  341]    Overall Loss 2.628330    Objective Loss 2.628330                                        LR 0.001000    Time 0.080434    
2025-01-06 21:14:37,417 - Epoch: [28][  160/  341]    Overall Loss 2.628940    Objective Loss 2.628940                                        LR 0.001000    Time 0.076869    
2025-01-06 21:14:37,657 - Epoch: [28][  170/  341]    Overall Loss 2.629393    Objective Loss 2.629393                                        LR 0.001000    Time 0.073743    
2025-01-06 21:14:37,886 - Epoch: [28][  180/  341]    Overall Loss 2.628634    Objective Loss 2.628634                                        LR 0.001000    Time 0.070912    
2025-01-06 21:14:38,119 - Epoch: [28][  190/  341]    Overall Loss 2.628618    Objective Loss 2.628618                                        LR 0.001000    Time 0.068406    
2025-01-06 21:14:38,369 - Epoch: [28][  200/  341]    Overall Loss 2.628844    Objective Loss 2.628844                                        LR 0.001000    Time 0.066234    
2025-01-06 21:14:38,614 - Epoch: [28][  210/  341]    Overall Loss 2.628224    Objective Loss 2.628224                                        LR 0.001000    Time 0.064245    
2025-01-06 21:14:38,846 - Epoch: [28][  220/  341]    Overall Loss 2.627504    Objective Loss 2.627504                                        LR 0.001000    Time 0.062382    
2025-01-06 21:14:39,082 - Epoch: [28][  230/  341]    Overall Loss 2.628198    Objective Loss 2.628198                                        LR 0.001000    Time 0.060695    
2025-01-06 21:14:39,323 - Epoch: [28][  240/  341]    Overall Loss 2.628708    Objective Loss 2.628708                                        LR 0.001000    Time 0.059164    
2025-01-06 21:14:39,564 - Epoch: [28][  250/  341]    Overall Loss 2.628222    Objective Loss 2.628222                                        LR 0.001000    Time 0.057762    
2025-01-06 21:14:39,799 - Epoch: [28][  260/  341]    Overall Loss 2.627322    Objective Loss 2.627322                                        LR 0.001000    Time 0.056445    
2025-01-06 21:14:40,037 - Epoch: [28][  270/  341]    Overall Loss 2.627560    Objective Loss 2.627560                                        LR 0.001000    Time 0.055235    
2025-01-06 21:14:40,277 - Epoch: [28][  280/  341]    Overall Loss 2.627631    Objective Loss 2.627631                                        LR 0.001000    Time 0.054120    
2025-01-06 21:14:40,532 - Epoch: [28][  290/  341]    Overall Loss 2.627538    Objective Loss 2.627538                                        LR 0.001000    Time 0.053132    
2025-01-06 21:14:40,766 - Epoch: [28][  300/  341]    Overall Loss 2.627581    Objective Loss 2.627581                                        LR 0.001000    Time 0.052142    
2025-01-06 21:14:41,000 - Epoch: [28][  310/  341]    Overall Loss 2.627605    Objective Loss 2.627605                                        LR 0.001000    Time 0.051216    
2025-01-06 21:14:41,226 - Epoch: [28][  320/  341]    Overall Loss 2.628177    Objective Loss 2.628177                                        LR 0.001000    Time 0.050322    
2025-01-06 21:14:41,446 - Epoch: [28][  330/  341]    Overall Loss 2.628487    Objective Loss 2.628487                                        LR 0.001000    Time 0.049464    
2025-01-06 21:14:41,701 - Epoch: [28][  340/  341]    Overall Loss 2.628194    Objective Loss 2.628194    Top1 6.250000    Top5 31.640625    LR 0.001000    Time 0.048759    
2025-01-06 21:14:41,728 - Epoch: [28][  341/  341]    Overall Loss 2.628302    Objective Loss 2.628302    Top1 8.816121    Top5 33.753149    LR 0.001000    Time 0.048696    
2025-01-06 21:14:43,405 - --- validate (epoch=28)-----------
2025-01-06 21:14:43,405 - 15217 samples (256 per mini-batch)
2025-01-06 21:14:52,056 - Epoch: [28][   10/   60]    Loss 3.159395    Top1 0.078125    Top5 0.507813    
2025-01-06 21:14:52,263 - Epoch: [28][   20/   60]    Loss 3.159630    Top1 0.078125    Top5 0.585938    
2025-01-06 21:14:52,484 - Epoch: [28][   30/   60]    Loss 3.162964    Top1 0.065104    Top5 0.455729    
2025-01-06 21:14:52,687 - Epoch: [28][   40/   60]    Loss 3.162671    Top1 0.058594    Top5 0.439453    
2025-01-06 21:14:52,892 - Epoch: [28][   50/   60]    Loss 3.162741    Top1 0.062500    Top5 0.445312    
2025-01-06 21:14:53,082 - Epoch: [28][   60/   60]    Loss 3.162617    Top1 0.072288    Top5 0.460012    
2025-01-06 21:14:54,662 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.163

2025-01-06 21:14:54,662 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:14:55,117 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:14:55,117 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:14:55,133 - 

2025-01-06 21:14:55,133 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:15:03,707 - Epoch: [29][   10/  341]    Overall Loss 2.624890    Objective Loss 2.624890                                        LR 0.001000    Time 0.857311    
2025-01-06 21:15:03,952 - Epoch: [29][   20/  341]    Overall Loss 2.626230    Objective Loss 2.626230                                        LR 0.001000    Time 0.440092    
2025-01-06 21:15:04,187 - Epoch: [29][   30/  341]    Overall Loss 2.631511    Objective Loss 2.631511                                        LR 0.001000    Time 0.301226    
2025-01-06 21:15:04,424 - Epoch: [29][   40/  341]    Overall Loss 2.631114    Objective Loss 2.631114                                        LR 0.001000    Time 0.231843    
2025-01-06 21:15:04,655 - Epoch: [29][   50/  341]    Overall Loss 2.634001    Objective Loss 2.634001                                        LR 0.001000    Time 0.190102    
2025-01-06 21:15:04,886 - Epoch: [29][   60/  341]    Overall Loss 2.629462    Objective Loss 2.629462                                        LR 0.001000    Time 0.162263    
2025-01-06 21:15:05,122 - Epoch: [29][   70/  341]    Overall Loss 2.634094    Objective Loss 2.634094                                        LR 0.001000    Time 0.142450    
2025-01-06 21:15:05,349 - Epoch: [29][   80/  341]    Overall Loss 2.633928    Objective Loss 2.633928                                        LR 0.001000    Time 0.127487    
2025-01-06 21:15:05,588 - Epoch: [29][   90/  341]    Overall Loss 2.629482    Objective Loss 2.629482                                        LR 0.001000    Time 0.115976    
2025-01-06 21:15:05,818 - Epoch: [29][  100/  341]    Overall Loss 2.629384    Objective Loss 2.629384                                        LR 0.001000    Time 0.106673    
2025-01-06 21:15:06,052 - Epoch: [29][  110/  341]    Overall Loss 2.629674    Objective Loss 2.629674                                        LR 0.001000    Time 0.099105    
2025-01-06 21:15:06,282 - Epoch: [29][  120/  341]    Overall Loss 2.630776    Objective Loss 2.630776                                        LR 0.001000    Time 0.092765    
2025-01-06 21:15:06,522 - Epoch: [29][  130/  341]    Overall Loss 2.630363    Objective Loss 2.630363                                        LR 0.001000    Time 0.087474    
2025-01-06 21:15:06,755 - Epoch: [29][  140/  341]    Overall Loss 2.628783    Objective Loss 2.628783                                        LR 0.001000    Time 0.082884    
2025-01-06 21:15:06,982 - Epoch: [29][  150/  341]    Overall Loss 2.628283    Objective Loss 2.628283                                        LR 0.001000    Time 0.078869    
2025-01-06 21:15:07,209 - Epoch: [29][  160/  341]    Overall Loss 2.628815    Objective Loss 2.628815                                        LR 0.001000    Time 0.075360    
2025-01-06 21:15:07,448 - Epoch: [29][  170/  341]    Overall Loss 2.629030    Objective Loss 2.629030                                        LR 0.001000    Time 0.072333    
2025-01-06 21:15:07,680 - Epoch: [29][  180/  341]    Overall Loss 2.629452    Objective Loss 2.629452                                        LR 0.001000    Time 0.069602    
2025-01-06 21:15:07,918 - Epoch: [29][  190/  341]    Overall Loss 2.629295    Objective Loss 2.629295                                        LR 0.001000    Time 0.067193    
2025-01-06 21:15:08,151 - Epoch: [29][  200/  341]    Overall Loss 2.629985    Objective Loss 2.629985                                        LR 0.001000    Time 0.065000    
2025-01-06 21:15:08,389 - Epoch: [29][  210/  341]    Overall Loss 2.629873    Objective Loss 2.629873                                        LR 0.001000    Time 0.063034    
2025-01-06 21:15:08,622 - Epoch: [29][  220/  341]    Overall Loss 2.630445    Objective Loss 2.630445                                        LR 0.001000    Time 0.061233    
2025-01-06 21:15:08,856 - Epoch: [29][  230/  341]    Overall Loss 2.630841    Objective Loss 2.630841                                        LR 0.001000    Time 0.059587    
2025-01-06 21:15:09,092 - Epoch: [29][  240/  341]    Overall Loss 2.631049    Objective Loss 2.631049                                        LR 0.001000    Time 0.058086    
2025-01-06 21:15:09,336 - Epoch: [29][  250/  341]    Overall Loss 2.630968    Objective Loss 2.630968                                        LR 0.001000    Time 0.056738    
2025-01-06 21:15:09,567 - Epoch: [29][  260/  341]    Overall Loss 2.629399    Objective Loss 2.629399                                        LR 0.001000    Time 0.055446    
2025-01-06 21:15:09,793 - Epoch: [29][  270/  341]    Overall Loss 2.629109    Objective Loss 2.629109                                        LR 0.001000    Time 0.054229    
2025-01-06 21:15:10,040 - Epoch: [29][  280/  341]    Overall Loss 2.629337    Objective Loss 2.629337                                        LR 0.001000    Time 0.053173    
2025-01-06 21:15:10,272 - Epoch: [29][  290/  341]    Overall Loss 2.629661    Objective Loss 2.629661                                        LR 0.001000    Time 0.052141    
2025-01-06 21:15:10,508 - Epoch: [29][  300/  341]    Overall Loss 2.629451    Objective Loss 2.629451                                        LR 0.001000    Time 0.051190    
2025-01-06 21:15:10,741 - Epoch: [29][  310/  341]    Overall Loss 2.629352    Objective Loss 2.629352                                        LR 0.001000    Time 0.050291    
2025-01-06 21:15:10,975 - Epoch: [29][  320/  341]    Overall Loss 2.629280    Objective Loss 2.629280                                        LR 0.001000    Time 0.049450    
2025-01-06 21:15:11,205 - Epoch: [29][  330/  341]    Overall Loss 2.629181    Objective Loss 2.629181                                        LR 0.001000    Time 0.048617    
2025-01-06 21:15:11,461 - Epoch: [29][  340/  341]    Overall Loss 2.629185    Objective Loss 2.629185    Top1 11.328125    Top5 33.203125    LR 0.001000    Time 0.047940    
2025-01-06 21:15:11,485 - Epoch: [29][  341/  341]    Overall Loss 2.629140    Objective Loss 2.629140    Top1 11.586902    Top5 35.264484    LR 0.001000    Time 0.047870    
2025-01-06 21:15:13,451 - --- validate (epoch=29)-----------
2025-01-06 21:15:13,451 - 15217 samples (256 per mini-batch)
2025-01-06 21:15:22,247 - Epoch: [29][   10/   60]    Loss 3.121343    Top1 0.039062    Top5 0.273437    
2025-01-06 21:15:22,464 - Epoch: [29][   20/   60]    Loss 3.120104    Top1 0.039062    Top5 0.390625    
2025-01-06 21:15:22,688 - Epoch: [29][   30/   60]    Loss 3.117979    Top1 0.065104    Top5 0.468750    
2025-01-06 21:15:22,893 - Epoch: [29][   40/   60]    Loss 3.117485    Top1 0.058594    Top5 0.478516    
2025-01-06 21:15:23,103 - Epoch: [29][   50/   60]    Loss 3.117887    Top1 0.078125    Top5 0.468750    
2025-01-06 21:15:23,295 - Epoch: [29][   60/   60]    Loss 3.117928    Top1 0.072288    Top5 0.460012    
2025-01-06 21:15:24,837 - ==> Top1: 0.072    Top5: 0.460    Loss: 3.118

2025-01-06 21:15:24,837 - ==> Confusion:
[[   0    0    0    0    0    0    0   30    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   23    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   16    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   11    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1410    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   18    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1403    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1404    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 1453    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0   14    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0 9401    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:15:25,291 - ==> Best [Top1: 0.072   Top5: 0.473   Params: 126490 on epoch: 3]
2025-01-06 21:15:25,291 - Saving checkpoint to: logs\2025.01.06-205828\checkpoint.pth.tar
2025-01-06 21:15:25,301 - Initiating quantization aware training (QAT)...
2025-01-06 21:15:25,301 - Collecting statistics for quantization aware training (QAT)...
2025-01-06 21:15:46,906 - torch.compile() successful, mode=default, cache limit=8
2025-01-06 21:15:46,906 - 

2025-01-06 21:15:46,906 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:16:00,639 - Epoch: [30][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 1.373233    
2025-01-06 21:16:00,960 - Epoch: [30][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.702689    
2025-01-06 21:16:01,277 - Epoch: [30][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.479003    
2025-01-06 21:16:01,626 - Epoch: [30][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.367991    
2025-01-06 21:16:01,935 - Epoch: [30][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.300569    
2025-01-06 21:16:02,249 - Epoch: [30][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.255706    
2025-01-06 21:16:02,552 - Epoch: [30][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.223511    
2025-01-06 21:16:02,867 - Epoch: [30][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.199502    
2025-01-06 21:16:03,168 - Epoch: [30][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.180684    
2025-01-06 21:16:03,482 - Epoch: [30][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.165753    
2025-01-06 21:16:03,813 - Epoch: [30][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.153696    
2025-01-06 21:16:04,124 - Epoch: [30][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.143444    
2025-01-06 21:16:04,437 - Epoch: [30][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.134815    
2025-01-06 21:16:04,762 - Epoch: [30][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.127509    
2025-01-06 21:16:05,064 - Epoch: [30][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.121012    
2025-01-06 21:16:05,374 - Epoch: [30][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.115385    
2025-01-06 21:16:05,720 - Epoch: [30][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.110629    
2025-01-06 21:16:06,027 - Epoch: [30][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.106178    
2025-01-06 21:16:06,338 - Epoch: [30][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.102230    
2025-01-06 21:16:06,668 - Epoch: [30][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098746    
2025-01-06 21:16:06,978 - Epoch: [30][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095503    
2025-01-06 21:16:07,286 - Epoch: [30][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092559    
2025-01-06 21:16:07,613 - Epoch: [30][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089959    
2025-01-06 21:16:07,933 - Epoch: [30][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087536    
2025-01-06 21:16:08,241 - Epoch: [30][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085267    
2025-01-06 21:16:08,563 - Epoch: [30][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083225    
2025-01-06 21:16:08,977 - Epoch: [30][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081675    
2025-01-06 21:16:09,299 - Epoch: [30][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079910    
2025-01-06 21:16:09,632 - Epoch: [30][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078294    
2025-01-06 21:16:09,961 - Epoch: [30][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076781    
2025-01-06 21:16:10,296 - Epoch: [30][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075383    
2025-01-06 21:16:10,710 - Epoch: [30][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074321    
2025-01-06 21:16:11,112 - Epoch: [30][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073287    
2025-01-06 21:16:11,506 - Epoch: [30][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.296875    Top5 12.109375    LR 0.001000    Time 0.072290    
2025-01-06 21:16:11,544 - Epoch: [30][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.793451    Top5 13.853904    LR 0.001000    Time 0.072188    
2025-01-06 21:16:13,391 - --- validate (epoch=30)-----------
2025-01-06 21:16:13,391 - 15217 samples (256 per mini-batch)
2025-01-06 21:16:22,700 - Epoch: [30][   10/   60]    Loss 3.044524    Top1 0.156250    Top5 0.234375    
2025-01-06 21:16:22,942 - Epoch: [30][   20/   60]    Loss 3.044524    Top1 0.214844    Top5 0.371094    
2025-01-06 21:16:23,238 - Epoch: [30][   30/   60]    Loss 3.044524    Top1 0.247396    Top5 0.377604    
2025-01-06 21:16:23,493 - Epoch: [30][   40/   60]    Loss 3.044524    Top1 0.205078    Top5 0.341797    
2025-01-06 21:16:23,755 - Epoch: [30][   50/   60]    Loss 3.044523    Top1 0.179688    Top5 0.296875    
2025-01-06 21:16:24,001 - Epoch: [30][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:16:25,504 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:16:25,504 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:16:26,327 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 30]
2025-01-06 21:16:26,327 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:16:26,396 - 

2025-01-06 21:16:26,396 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:16:34,842 - Epoch: [31][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.844599    
2025-01-06 21:16:35,162 - Epoch: [31][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.438326    
2025-01-06 21:16:35,464 - Epoch: [31][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.302282    
2025-01-06 21:16:35,774 - Epoch: [31][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.234454    
2025-01-06 21:16:36,085 - Epoch: [31][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.193783    
2025-01-06 21:16:36,388 - Epoch: [31][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.166534    
2025-01-06 21:16:36,686 - Epoch: [31][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.146916    
2025-01-06 21:16:37,007 - Epoch: [31][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.132355    
2025-01-06 21:16:37,303 - Epoch: [31][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.120943    
2025-01-06 21:16:37,608 - Epoch: [31][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.111900    
2025-01-06 21:16:37,918 - Epoch: [31][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.104540    
2025-01-06 21:16:38,220 - Epoch: [31][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098351    
2025-01-06 21:16:38,570 - Epoch: [31][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093476    
2025-01-06 21:16:38,888 - Epoch: [31][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089067    
2025-01-06 21:16:39,201 - Epoch: [31][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085217    
2025-01-06 21:16:39,510 - Epoch: [31][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081807    
2025-01-06 21:16:39,817 - Epoch: [31][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078800    
2025-01-06 21:16:40,127 - Epoch: [31][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076143    
2025-01-06 21:16:40,438 - Epoch: [31][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073775    
2025-01-06 21:16:40,764 - Epoch: [31][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071713    
2025-01-06 21:16:41,064 - Epoch: [31][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069729    
2025-01-06 21:16:41,378 - Epoch: [31][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067986    
2025-01-06 21:16:41,697 - Epoch: [31][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066391    
2025-01-06 21:16:42,009 - Epoch: [31][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064922    
2025-01-06 21:16:42,315 - Epoch: [31][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063551    
2025-01-06 21:16:42,630 - Epoch: [31][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062319    
2025-01-06 21:16:42,964 - Epoch: [31][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061248    
2025-01-06 21:16:43,276 - Epoch: [31][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060174    
2025-01-06 21:16:43,591 - Epoch: [31][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059185    
2025-01-06 21:16:43,938 - Epoch: [31][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058369    
2025-01-06 21:16:44,290 - Epoch: [31][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057608    
2025-01-06 21:16:44,658 - Epoch: [31][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056956    
2025-01-06 21:16:45,009 - Epoch: [31][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056294    
2025-01-06 21:16:45,385 - Epoch: [31][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 6.640625    Top5 12.890625    LR 0.001000    Time 0.055744    
2025-01-06 21:16:45,413 - Epoch: [31][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 6.549118    Top5 14.357683    LR 0.001000    Time 0.055661    
2025-01-06 21:16:47,214 - --- validate (epoch=31)-----------
2025-01-06 21:16:47,214 - 15217 samples (256 per mini-batch)
2025-01-06 21:16:56,061 - Epoch: [31][   10/   60]    Loss 3.044524    Top1 0.039062    Top5 0.117188    
2025-01-06 21:16:56,323 - Epoch: [31][   20/   60]    Loss 3.044524    Top1 0.117188    Top5 0.253906    
2025-01-06 21:16:56,585 - Epoch: [31][   30/   60]    Loss 3.044524    Top1 0.130208    Top5 0.234375    
2025-01-06 21:16:56,873 - Epoch: [31][   40/   60]    Loss 3.044524    Top1 0.156250    Top5 0.263672    
2025-01-06 21:16:57,115 - Epoch: [31][   50/   60]    Loss 3.044524    Top1 0.179688    Top5 0.312500    
2025-01-06 21:16:57,366 - Epoch: [31][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:16:58,880 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:16:58,890 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:16:59,355 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 31]
2025-01-06 21:16:59,355 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:16:59,391 - 

2025-01-06 21:16:59,391 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:17:08,174 - Epoch: [32][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.877184    
2025-01-06 21:17:08,527 - Epoch: [32][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.456259    
2025-01-06 21:17:08,856 - Epoch: [32][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.315115    
2025-01-06 21:17:09,178 - Epoch: [32][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.244399    
2025-01-06 21:17:09,524 - Epoch: [32][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.202443    
2025-01-06 21:17:09,834 - Epoch: [32][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.173835    
2025-01-06 21:17:10,149 - Epoch: [32][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.153465    
2025-01-06 21:17:10,462 - Epoch: [32][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.138204    
2025-01-06 21:17:10,777 - Epoch: [32][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.126338    
2025-01-06 21:17:11,077 - Epoch: [32][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.116708    
2025-01-06 21:17:11,384 - Epoch: [32][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.108887    
2025-01-06 21:17:11,700 - Epoch: [32][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.102453    
2025-01-06 21:17:12,032 - Epoch: [32][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.097126    
2025-01-06 21:17:12,334 - Epoch: [32][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092343    
2025-01-06 21:17:12,647 - Epoch: [32][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.088257    
2025-01-06 21:17:12,964 - Epoch: [32][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084727    
2025-01-06 21:17:13,275 - Epoch: [32][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081572    
2025-01-06 21:17:13,581 - Epoch: [32][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078740    
2025-01-06 21:17:13,894 - Epoch: [32][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076242    
2025-01-06 21:17:14,211 - Epoch: [32][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074014    
2025-01-06 21:17:14,512 - Epoch: [32][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071924    
2025-01-06 21:17:14,822 - Epoch: [32][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070062    
2025-01-06 21:17:15,126 - Epoch: [32][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068330    
2025-01-06 21:17:15,440 - Epoch: [32][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066792    
2025-01-06 21:17:15,772 - Epoch: [32][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065444    
2025-01-06 21:17:16,103 - Epoch: [32][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064200    
2025-01-06 21:17:16,407 - Epoch: [32][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062948    
2025-01-06 21:17:16,722 - Epoch: [32][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061823    
2025-01-06 21:17:17,038 - Epoch: [32][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060783    
2025-01-06 21:17:17,340 - Epoch: [32][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059763    
2025-01-06 21:17:17,652 - Epoch: [32][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058842    
2025-01-06 21:17:17,959 - Epoch: [32][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057961    
2025-01-06 21:17:18,278 - Epoch: [32][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057172    
2025-01-06 21:17:18,602 - Epoch: [32][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 2.734375    Top5 11.718750    LR 0.001000    Time 0.056442    
2025-01-06 21:17:18,632 - Epoch: [32][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 2.518892    Top5 13.602015    LR 0.001000    Time 0.056362    
2025-01-06 21:17:20,280 - --- validate (epoch=32)-----------
2025-01-06 21:17:20,280 - 15217 samples (256 per mini-batch)
2025-01-06 21:17:29,080 - Epoch: [32][   10/   60]    Loss 3.044523    Top1 0.078125    Top5 0.156250    
2025-01-06 21:17:29,331 - Epoch: [32][   20/   60]    Loss 3.044523    Top1 0.156250    Top5 0.273437    
2025-01-06 21:17:29,584 - Epoch: [32][   30/   60]    Loss 3.044523    Top1 0.195312    Top5 0.299479    
2025-01-06 21:17:29,849 - Epoch: [32][   40/   60]    Loss 3.044524    Top1 0.195312    Top5 0.332031    
2025-01-06 21:17:30,109 - Epoch: [32][   50/   60]    Loss 3.044523    Top1 0.210937    Top5 0.335938    
2025-01-06 21:17:30,353 - Epoch: [32][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:17:31,853 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:17:31,853 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:17:32,306 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 32]
2025-01-06 21:17:32,306 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:17:32,341 - 

2025-01-06 21:17:32,341 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:17:41,155 - Epoch: [33][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.881289    
2025-01-06 21:17:41,479 - Epoch: [33][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.456855    
2025-01-06 21:17:41,809 - Epoch: [33][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.315557    
2025-01-06 21:17:42,132 - Epoch: [33][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.244750    
2025-01-06 21:17:42,465 - Epoch: [33][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.202454    
2025-01-06 21:17:42,784 - Epoch: [33][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.174036    
2025-01-06 21:17:43,106 - Epoch: [33][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.153771    
2025-01-06 21:17:43,419 - Epoch: [33][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.138455    
2025-01-06 21:17:43,740 - Epoch: [33][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.126639    
2025-01-06 21:17:44,052 - Epoch: [33][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.117099    
2025-01-06 21:17:44,364 - Epoch: [33][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.109287    
2025-01-06 21:17:44,674 - Epoch: [33][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.102762    
2025-01-06 21:17:44,980 - Epoch: [33][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.097211    
2025-01-06 21:17:45,303 - Epoch: [33][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092577    
2025-01-06 21:17:45,609 - Epoch: [33][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.088445    
2025-01-06 21:17:45,922 - Epoch: [33][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084875    
2025-01-06 21:17:46,223 - Epoch: [33][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081648    
2025-01-06 21:17:46,525 - Epoch: [33][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078791    
2025-01-06 21:17:46,838 - Epoch: [33][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076293    
2025-01-06 21:17:47,141 - Epoch: [33][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073993    
2025-01-06 21:17:47,460 - Epoch: [33][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071989    
2025-01-06 21:17:47,786 - Epoch: [33][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070198    
2025-01-06 21:17:48,094 - Epoch: [33][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068484    
2025-01-06 21:17:48,408 - Epoch: [33][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066940    
2025-01-06 21:17:48,726 - Epoch: [33][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065534    
2025-01-06 21:17:49,023 - Epoch: [33][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064158    
2025-01-06 21:17:49,325 - Epoch: [33][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062899    
2025-01-06 21:17:49,639 - Epoch: [33][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061773    
2025-01-06 21:17:49,951 - Epoch: [33][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060714    
2025-01-06 21:17:50,273 - Epoch: [33][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059763    
2025-01-06 21:17:50,579 - Epoch: [33][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058822    
2025-01-06 21:17:50,907 - Epoch: [33][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058008    
2025-01-06 21:17:51,255 - Epoch: [33][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057305    
2025-01-06 21:17:51,614 - Epoch: [33][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.296875    Top5 9.765625    LR 0.001000    Time 0.056675    
2025-01-06 21:17:51,650 - Epoch: [33][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.030227    Top5 10.327456    LR 0.001000    Time 0.056615    
2025-01-06 21:17:53,556 - --- validate (epoch=33)-----------
2025-01-06 21:17:53,556 - 15217 samples (256 per mini-batch)
2025-01-06 21:18:02,130 - Epoch: [33][   10/   60]    Loss 3.044524    Top1 0.156250    Top5 0.312500    
2025-01-06 21:18:02,414 - Epoch: [33][   20/   60]    Loss 3.044524    Top1 0.156250    Top5 0.253906    
2025-01-06 21:18:02,668 - Epoch: [33][   30/   60]    Loss 3.044524    Top1 0.195312    Top5 0.299479    
2025-01-06 21:18:02,949 - Epoch: [33][   40/   60]    Loss 3.044524    Top1 0.224609    Top5 0.351563    
2025-01-06 21:18:03,207 - Epoch: [33][   50/   60]    Loss 3.044523    Top1 0.210937    Top5 0.328125    
2025-01-06 21:18:03,452 - Epoch: [33][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:18:04,990 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:18:04,990 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:18:05,458 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 33]
2025-01-06 21:18:05,465 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:18:05,501 - 

2025-01-06 21:18:05,501 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:18:14,017 - Epoch: [34][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.851602    
2025-01-06 21:18:14,355 - Epoch: [34][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.442702    
2025-01-06 21:18:14,667 - Epoch: [34][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.305530    
2025-01-06 21:18:14,987 - Epoch: [34][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.237163    
2025-01-06 21:18:15,303 - Epoch: [34][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.196045    
2025-01-06 21:18:15,608 - Epoch: [34][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.168463    
2025-01-06 21:18:15,919 - Epoch: [34][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.148802    
2025-01-06 21:18:16,231 - Epoch: [34][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.134104    
2025-01-06 21:18:16,538 - Epoch: [34][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.122618    
2025-01-06 21:18:16,849 - Epoch: [34][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.113463    
2025-01-06 21:18:17,154 - Epoch: [34][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.105918    
2025-01-06 21:18:17,449 - Epoch: [34][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.099550    
2025-01-06 21:18:17,751 - Epoch: [34][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094220    
2025-01-06 21:18:18,056 - Epoch: [34][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089668    
2025-01-06 21:18:18,365 - Epoch: [34][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085746    
2025-01-06 21:18:18,675 - Epoch: [34][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082330    
2025-01-06 21:18:19,001 - Epoch: [34][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079403    
2025-01-06 21:18:19,308 - Epoch: [34][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076696    
2025-01-06 21:18:19,624 - Epoch: [34][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074320    
2025-01-06 21:18:19,935 - Epoch: [34][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072161    
2025-01-06 21:18:20,240 - Epoch: [34][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070179    
2025-01-06 21:18:20,552 - Epoch: [34][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068396    
2025-01-06 21:18:20,863 - Epoch: [34][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066769    
2025-01-06 21:18:21,164 - Epoch: [34][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065237    
2025-01-06 21:18:21,477 - Epoch: [34][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063880    
2025-01-06 21:18:21,782 - Epoch: [34][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062598    
2025-01-06 21:18:22,099 - Epoch: [34][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061455    
2025-01-06 21:18:22,412 - Epoch: [34][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060375    
2025-01-06 21:18:22,712 - Epoch: [34][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059329    
2025-01-06 21:18:23,037 - Epoch: [34][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058433    
2025-01-06 21:18:23,352 - Epoch: [34][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057567    
2025-01-06 21:18:23,663 - Epoch: [34][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056738    
2025-01-06 21:18:23,970 - Epoch: [34][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.055943    
2025-01-06 21:18:24,305 - Epoch: [34][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.687500    Top5 14.062500    LR 0.001000    Time 0.055277    
2025-01-06 21:18:24,346 - Epoch: [34][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.526448    Top5 12.846348    LR 0.001000    Time 0.055210    
2025-01-06 21:18:26,137 - --- validate (epoch=34)-----------
2025-01-06 21:18:26,137 - 15217 samples (256 per mini-batch)
2025-01-06 21:18:34,704 - Epoch: [34][   10/   60]    Loss 3.044524    Top1 0.195312    Top5 0.390625    
2025-01-06 21:18:34,961 - Epoch: [34][   20/   60]    Loss 3.044524    Top1 0.214844    Top5 0.390625    
2025-01-06 21:18:35,209 - Epoch: [34][   30/   60]    Loss 3.044524    Top1 0.195312    Top5 0.338542    
2025-01-06 21:18:35,467 - Epoch: [34][   40/   60]    Loss 3.044524    Top1 0.205078    Top5 0.351563    
2025-01-06 21:18:35,735 - Epoch: [34][   50/   60]    Loss 3.044524    Top1 0.203125    Top5 0.335938    
2025-01-06 21:18:35,973 - Epoch: [34][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:18:37,457 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:18:37,457 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:18:37,929 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 34]
2025-01-06 21:18:37,929 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:18:37,965 - 

2025-01-06 21:18:37,966 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:18:46,707 - Epoch: [35][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.873847    
2025-01-06 21:18:47,023 - Epoch: [35][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.452716    
2025-01-06 21:18:47,347 - Epoch: [35][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.312609    
2025-01-06 21:18:47,666 - Epoch: [35][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.242370    
2025-01-06 21:18:47,986 - Epoch: [35][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.200282    
2025-01-06 21:18:48,297 - Epoch: [35][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.172047    
2025-01-06 21:18:48,618 - Epoch: [35][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.152062    
2025-01-06 21:18:48,931 - Epoch: [35][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.136970    
2025-01-06 21:18:49,238 - Epoch: [35][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.125155    
2025-01-06 21:18:49,546 - Epoch: [35][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.115722    
2025-01-06 21:18:49,848 - Epoch: [35][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.107945    
2025-01-06 21:18:50,148 - Epoch: [35][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.101451    
2025-01-06 21:18:50,476 - Epoch: [35][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.096175    
2025-01-06 21:18:50,793 - Epoch: [35][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091566    
2025-01-06 21:18:51,093 - Epoch: [35][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087461    
2025-01-06 21:18:51,404 - Epoch: [35][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083943    
2025-01-06 21:18:51,717 - Epoch: [35][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080846    
2025-01-06 21:18:52,038 - Epoch: [35][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078122    
2025-01-06 21:18:52,338 - Epoch: [35][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075591    
2025-01-06 21:18:52,638 - Epoch: [35][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073310    
2025-01-06 21:18:52,956 - Epoch: [35][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071337    
2025-01-06 21:18:53,260 - Epoch: [35][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069471    
2025-01-06 21:18:53,563 - Epoch: [35][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067765    
2025-01-06 21:18:53,879 - Epoch: [35][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066259    
2025-01-06 21:18:54,201 - Epoch: [35][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064899    
2025-01-06 21:18:54,520 - Epoch: [35][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063627    
2025-01-06 21:18:54,821 - Epoch: [35][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062380    
2025-01-06 21:18:55,138 - Epoch: [35][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061284    
2025-01-06 21:18:55,443 - Epoch: [35][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060209    
2025-01-06 21:18:55,756 - Epoch: [35][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059244    
2025-01-06 21:18:56,064 - Epoch: [35][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058326    
2025-01-06 21:18:56,366 - Epoch: [35][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057447    
2025-01-06 21:18:56,671 - Epoch: [35][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056629    
2025-01-06 21:18:57,029 - Epoch: [35][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.906250    Top5 15.625000    LR 0.001000    Time 0.056014    
2025-01-06 21:18:57,060 - Epoch: [35][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.778338    Top5 14.357683    LR 0.001000    Time 0.055935    
2025-01-06 21:18:58,819 - --- validate (epoch=35)-----------
2025-01-06 21:18:58,819 - 15217 samples (256 per mini-batch)
2025-01-06 21:19:07,459 - Epoch: [35][   10/   60]    Loss 3.044523    Top1 0.234375    Top5 0.312500    
2025-01-06 21:19:07,727 - Epoch: [35][   20/   60]    Loss 3.044524    Top1 0.175781    Top5 0.292969    
2025-01-06 21:19:07,999 - Epoch: [35][   30/   60]    Loss 3.044524    Top1 0.169271    Top5 0.299479    
2025-01-06 21:19:08,243 - Epoch: [35][   40/   60]    Loss 3.044524    Top1 0.175781    Top5 0.283203    
2025-01-06 21:19:08,499 - Epoch: [35][   50/   60]    Loss 3.044524    Top1 0.203125    Top5 0.312500    
2025-01-06 21:19:08,763 - Epoch: [35][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:19:10,335 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:19:10,337 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:19:11,048 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 35]
2025-01-06 21:19:11,048 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:19:11,088 - 

2025-01-06 21:19:11,088 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:19:19,635 - Epoch: [36][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.854765    
2025-01-06 21:19:19,963 - Epoch: [36][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.443743    
2025-01-06 21:19:20,272 - Epoch: [36][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.306147    
2025-01-06 21:19:20,594 - Epoch: [36][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.237659    
2025-01-06 21:19:20,896 - Epoch: [36][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.196166    
2025-01-06 21:19:21,220 - Epoch: [36][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.168877    
2025-01-06 21:19:21,523 - Epoch: [36][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.149070    
2025-01-06 21:19:21,863 - Epoch: [36][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.134564    
2025-01-06 21:19:22,177 - Epoch: [36][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.123091    
2025-01-06 21:19:22,481 - Epoch: [36][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.113813    
2025-01-06 21:19:22,790 - Epoch: [36][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.106278    
2025-01-06 21:19:23,112 - Epoch: [36][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100106    
2025-01-06 21:19:23,423 - Epoch: [36][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094800    
2025-01-06 21:19:23,757 - Epoch: [36][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090414    
2025-01-06 21:19:24,080 - Epoch: [36][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086537    
2025-01-06 21:19:24,383 - Epoch: [36][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083020    
2025-01-06 21:19:24,688 - Epoch: [36][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079936    
2025-01-06 21:19:24,993 - Epoch: [36][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077140    
2025-01-06 21:19:25,295 - Epoch: [36][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074673    
2025-01-06 21:19:25,601 - Epoch: [36][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072465    
2025-01-06 21:19:25,905 - Epoch: [36][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070466    
2025-01-06 21:19:26,212 - Epoch: [36][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068655    
2025-01-06 21:19:26,515 - Epoch: [36][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066990    
2025-01-06 21:19:26,817 - Epoch: [36][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065457    
2025-01-06 21:19:27,129 - Epoch: [36][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064086    
2025-01-06 21:19:27,442 - Epoch: [36][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062783    
2025-01-06 21:19:27,746 - Epoch: [36][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061546    
2025-01-06 21:19:28,060 - Epoch: [36][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060472    
2025-01-06 21:19:28,355 - Epoch: [36][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059401    
2025-01-06 21:19:28,669 - Epoch: [36][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058470    
2025-01-06 21:19:28,983 - Epoch: [36][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057591    
2025-01-06 21:19:29,292 - Epoch: [36][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056758    
2025-01-06 21:19:29,600 - Epoch: [36][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.055973    
2025-01-06 21:19:29,942 - Epoch: [36][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.296875    Top5 12.500000    LR 0.001000    Time 0.055331    
2025-01-06 21:19:29,969 - Epoch: [36][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.289673    Top5 15.113350    LR 0.001000    Time 0.055249    
2025-01-06 21:19:31,667 - --- validate (epoch=36)-----------
2025-01-06 21:19:31,667 - 15217 samples (256 per mini-batch)
2025-01-06 21:19:40,637 - Epoch: [36][   10/   60]    Loss 3.044523    Top1 0.039062    Top5 0.078125    
2025-01-06 21:19:40,921 - Epoch: [36][   20/   60]    Loss 3.044524    Top1 0.078125    Top5 0.234375    
2025-01-06 21:19:41,173 - Epoch: [36][   30/   60]    Loss 3.044523    Top1 0.143229    Top5 0.260417    
2025-01-06 21:19:41,438 - Epoch: [36][   40/   60]    Loss 3.044524    Top1 0.156250    Top5 0.283203    
2025-01-06 21:19:41,684 - Epoch: [36][   50/   60]    Loss 3.044524    Top1 0.179688    Top5 0.304688    
2025-01-06 21:19:41,938 - Epoch: [36][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:19:43,432 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:19:43,432 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:19:44,123 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 36]
2025-01-06 21:19:44,123 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:19:44,155 - 

2025-01-06 21:19:44,158 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:19:52,687 - Epoch: [37][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.852908    
2025-01-06 21:19:53,001 - Epoch: [37][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.442154    
2025-01-06 21:19:53,335 - Epoch: [37][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.305874    
2025-01-06 21:19:53,640 - Epoch: [37][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.237033    
2025-01-06 21:19:53,957 - Epoch: [37][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.195968    
2025-01-06 21:19:54,280 - Epoch: [37][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.168519    
2025-01-06 21:19:54,595 - Epoch: [37][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.148947    
2025-01-06 21:19:54,902 - Epoch: [37][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.134161    
2025-01-06 21:19:55,213 - Epoch: [37][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.122693    
2025-01-06 21:19:55,515 - Epoch: [37][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.113445    
2025-01-06 21:19:55,842 - Epoch: [37][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.106106    
2025-01-06 21:19:56,152 - Epoch: [37][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.099842    
2025-01-06 21:19:56,488 - Epoch: [37][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094673    
2025-01-06 21:19:56,804 - Epoch: [37][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090162    
2025-01-06 21:19:57,145 - Epoch: [37][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086427    
2025-01-06 21:19:57,470 - Epoch: [37][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083058    
2025-01-06 21:19:57,795 - Epoch: [37][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080081    
2025-01-06 21:19:58,113 - Epoch: [37][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077400    
2025-01-06 21:19:58,417 - Epoch: [37][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074926    
2025-01-06 21:19:58,734 - Epoch: [37][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072766    
2025-01-06 21:19:59,039 - Epoch: [37][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070753    
2025-01-06 21:19:59,371 - Epoch: [37][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069049    
2025-01-06 21:19:59,668 - Epoch: [37][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067335    
2025-01-06 21:19:59,977 - Epoch: [37][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065816    
2025-01-06 21:20:00,293 - Epoch: [37][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064436    
2025-01-06 21:20:00,651 - Epoch: [37][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063333    
2025-01-06 21:20:00,964 - Epoch: [37][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062147    
2025-01-06 21:20:01,274 - Epoch: [37][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061033    
2025-01-06 21:20:01,591 - Epoch: [37][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060022    
2025-01-06 21:20:01,894 - Epoch: [37][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059033    
2025-01-06 21:20:02,215 - Epoch: [37][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058162    
2025-01-06 21:20:02,524 - Epoch: [37][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057311    
2025-01-06 21:20:02,824 - Epoch: [37][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056485    
2025-01-06 21:20:03,151 - Epoch: [37][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.125000    Top5 10.546875    LR 0.001000    Time 0.055785    
2025-01-06 21:20:03,177 - Epoch: [37][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.282116    Top5 11.586902    LR 0.001000    Time 0.055696    
2025-01-06 21:20:04,885 - --- validate (epoch=37)-----------
2025-01-06 21:20:04,885 - 15217 samples (256 per mini-batch)
2025-01-06 21:20:13,815 - Epoch: [37][   10/   60]    Loss 3.044523    Top1 0.195312    Top5 0.312500    
2025-01-06 21:20:14,081 - Epoch: [37][   20/   60]    Loss 3.044523    Top1 0.175781    Top5 0.273437    
2025-01-06 21:20:14,339 - Epoch: [37][   30/   60]    Loss 3.044524    Top1 0.208333    Top5 0.312500    
2025-01-06 21:20:14,600 - Epoch: [37][   40/   60]    Loss 3.044524    Top1 0.214844    Top5 0.332031    
2025-01-06 21:20:14,856 - Epoch: [37][   50/   60]    Loss 3.044524    Top1 0.195312    Top5 0.320312    
2025-01-06 21:20:15,105 - Epoch: [37][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:20:16,598 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:20:16,598 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:20:17,055 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 37]
2025-01-06 21:20:17,055 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:20:17,088 - 

2025-01-06 21:20:17,089 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:20:25,703 - Epoch: [38][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.861339    
2025-01-06 21:20:26,009 - Epoch: [38][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.445963    
2025-01-06 21:20:26,334 - Epoch: [38][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.308134    
2025-01-06 21:20:26,637 - Epoch: [38][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.238680    
2025-01-06 21:20:26,959 - Epoch: [38][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.197380    
2025-01-06 21:20:27,263 - Epoch: [38][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.169553    
2025-01-06 21:20:27,588 - Epoch: [38][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.149977    
2025-01-06 21:20:27,909 - Epoch: [38][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.135218    
2025-01-06 21:20:28,240 - Epoch: [38][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.123867    
2025-01-06 21:20:28,533 - Epoch: [38][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.114409    
2025-01-06 21:20:28,864 - Epoch: [38][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.106931    
2025-01-06 21:20:29,168 - Epoch: [38][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100465    
2025-01-06 21:20:29,469 - Epoch: [38][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095053    
2025-01-06 21:20:29,813 - Epoch: [38][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090718    
2025-01-06 21:20:30,111 - Epoch: [38][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086589    
2025-01-06 21:20:30,414 - Epoch: [38][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083070    
2025-01-06 21:20:30,739 - Epoch: [38][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080096    
2025-01-06 21:20:31,073 - Epoch: [38][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077500    
2025-01-06 21:20:31,376 - Epoch: [38][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075021    
2025-01-06 21:20:31,725 - Epoch: [38][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073010    
2025-01-06 21:20:32,064 - Epoch: [38][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071150    
2025-01-06 21:20:32,368 - Epoch: [38][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069292    
2025-01-06 21:20:32,691 - Epoch: [38][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067685    
2025-01-06 21:20:32,999 - Epoch: [38][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066148    
2025-01-06 21:20:33,321 - Epoch: [38][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064788    
2025-01-06 21:20:33,628 - Epoch: [38][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063480    
2025-01-06 21:20:33,934 - Epoch: [38][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062262    
2025-01-06 21:20:34,246 - Epoch: [38][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061150    
2025-01-06 21:20:34,559 - Epoch: [38][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060086    
2025-01-06 21:20:34,873 - Epoch: [38][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059127    
2025-01-06 21:20:35,192 - Epoch: [38][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058249    
2025-01-06 21:20:35,554 - Epoch: [38][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057554    
2025-01-06 21:20:35,864 - Epoch: [38][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056748    
2025-01-06 21:20:36,207 - Epoch: [38][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.687500    Top5 14.062500    LR 0.001000    Time 0.056089    
2025-01-06 21:20:36,235 - Epoch: [38][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.282116    Top5 14.357683    LR 0.001000    Time 0.056001    
2025-01-06 21:20:38,011 - --- validate (epoch=38)-----------
2025-01-06 21:20:38,011 - 15217 samples (256 per mini-batch)
2025-01-06 21:20:46,573 - Epoch: [38][   10/   60]    Loss 3.044524    Top1 0.234375    Top5 0.390625    
2025-01-06 21:20:46,830 - Epoch: [38][   20/   60]    Loss 3.044523    Top1 0.195312    Top5 0.371094    
2025-01-06 21:20:47,088 - Epoch: [38][   30/   60]    Loss 3.044523    Top1 0.156250    Top5 0.299479    
2025-01-06 21:20:47,354 - Epoch: [38][   40/   60]    Loss 3.044523    Top1 0.166016    Top5 0.312500    
2025-01-06 21:20:47,614 - Epoch: [38][   50/   60]    Loss 3.044523    Top1 0.203125    Top5 0.320312    
2025-01-06 21:20:47,844 - Epoch: [38][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:20:49,347 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:20:49,347 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:20:49,801 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 38]
2025-01-06 21:20:49,801 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:20:49,842 - 

2025-01-06 21:20:49,842 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:20:58,893 - Epoch: [39][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.904932    
2025-01-06 21:20:59,208 - Epoch: [39][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.468209    
2025-01-06 21:20:59,538 - Epoch: [39][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.323120    
2025-01-06 21:20:59,846 - Epoch: [39][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.250057    
2025-01-06 21:21:00,169 - Epoch: [39][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.206498    
2025-01-06 21:21:00,500 - Epoch: [39][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.177602    
2025-01-06 21:21:00,859 - Epoch: [39][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.157350    
2025-01-06 21:21:01,167 - Epoch: [39][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.141521    
2025-01-06 21:21:01,477 - Epoch: [39][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.129247    
2025-01-06 21:21:01,794 - Epoch: [39][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.119488    
2025-01-06 21:21:02,116 - Epoch: [39][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.111555    
2025-01-06 21:21:02,469 - Epoch: [39][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.105199    
2025-01-06 21:21:02,785 - Epoch: [39][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.099536    
2025-01-06 21:21:03,088 - Epoch: [39][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094577    
2025-01-06 21:21:03,407 - Epoch: [39][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090400    
2025-01-06 21:21:03,711 - Epoch: [39][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086647    
2025-01-06 21:21:04,021 - Epoch: [39][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083373    
2025-01-06 21:21:04,340 - Epoch: [39][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080515    
2025-01-06 21:21:04,645 - Epoch: [39][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077883    
2025-01-06 21:21:04,958 - Epoch: [39][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075552    
2025-01-06 21:21:05,277 - Epoch: [39][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073477    
2025-01-06 21:21:05,611 - Epoch: [39][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071655    
2025-01-06 21:21:05,946 - Epoch: [39][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069993    
2025-01-06 21:21:06,265 - Epoch: [39][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068410    
2025-01-06 21:21:06,575 - Epoch: [39][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066913    
2025-01-06 21:21:06,938 - Epoch: [39][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065734    
2025-01-06 21:21:07,260 - Epoch: [39][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064493    
2025-01-06 21:21:07,581 - Epoch: [39][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063331    
2025-01-06 21:21:07,903 - Epoch: [39][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062257    
2025-01-06 21:21:08,222 - Epoch: [39][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061246    
2025-01-06 21:21:08,548 - Epoch: [39][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060323    
2025-01-06 21:21:08,861 - Epoch: [39][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059417    
2025-01-06 21:21:09,161 - Epoch: [39][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058524    
2025-01-06 21:21:09,492 - Epoch: [39][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.468750    Top5 12.109375    LR 0.001000    Time 0.057758    
2025-01-06 21:21:09,522 - Epoch: [39][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.541562    Top5 12.090680    LR 0.001000    Time 0.057677    
2025-01-06 21:21:11,218 - --- validate (epoch=39)-----------
2025-01-06 21:21:11,218 - 15217 samples (256 per mini-batch)
2025-01-06 21:21:19,779 - Epoch: [39][   10/   60]    Loss 3.044524    Top1 0.117188    Top5 0.234375    
2025-01-06 21:21:20,044 - Epoch: [39][   20/   60]    Loss 3.044524    Top1 0.234375    Top5 0.292969    
2025-01-06 21:21:20,304 - Epoch: [39][   30/   60]    Loss 3.044524    Top1 0.182292    Top5 0.260417    
2025-01-06 21:21:20,559 - Epoch: [39][   40/   60]    Loss 3.044524    Top1 0.166016    Top5 0.234375    
2025-01-06 21:21:20,829 - Epoch: [39][   50/   60]    Loss 3.044524    Top1 0.171875    Top5 0.257812    
2025-01-06 21:21:21,052 - Epoch: [39][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:21:22,615 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:21:22,615 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:21:23,079 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 39]
2025-01-06 21:21:23,082 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:21:23,113 - 

2025-01-06 21:21:23,113 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:21:31,598 - Epoch: [40][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.848375    
2025-01-06 21:21:31,925 - Epoch: [40][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.440562    
2025-01-06 21:21:32,238 - Epoch: [40][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.304128    
2025-01-06 21:21:32,560 - Epoch: [40][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.236145    
2025-01-06 21:21:32,887 - Epoch: [40][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.195245    
2025-01-06 21:21:33,191 - Epoch: [40][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.167770    
2025-01-06 21:21:33,518 - Epoch: [40][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.148481    
2025-01-06 21:21:33,821 - Epoch: [40][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.133699    
2025-01-06 21:21:34,130 - Epoch: [40][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.122280    
2025-01-06 21:21:34,433 - Epoch: [40][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.113082    
2025-01-06 21:21:34,736 - Epoch: [40][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.105562    
2025-01-06 21:21:35,057 - Epoch: [40][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.099436    
2025-01-06 21:21:35,378 - Epoch: [40][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094257    
2025-01-06 21:21:35,686 - Epoch: [40][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089724    
2025-01-06 21:21:35,991 - Epoch: [40][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085776    
2025-01-06 21:21:36,336 - Epoch: [40][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082570    
2025-01-06 21:21:36,637 - Epoch: [40][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079484    
2025-01-06 21:21:36,954 - Epoch: [40][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076832    
2025-01-06 21:21:37,269 - Epoch: [40][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074444    
2025-01-06 21:21:37,589 - Epoch: [40][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072322    
2025-01-06 21:21:37,909 - Epoch: [40][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070402    
2025-01-06 21:21:38,229 - Epoch: [40][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068658    
2025-01-06 21:21:38,535 - Epoch: [40][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067000    
2025-01-06 21:21:38,849 - Epoch: [40][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065518    
2025-01-06 21:21:39,150 - Epoch: [40][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064099    
2025-01-06 21:21:39,455 - Epoch: [40][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062805    
2025-01-06 21:21:39,768 - Epoch: [40][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061638    
2025-01-06 21:21:40,079 - Epoch: [40][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060549    
2025-01-06 21:21:40,409 - Epoch: [40][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059599    
2025-01-06 21:21:40,747 - Epoch: [40][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058740    
2025-01-06 21:21:41,069 - Epoch: [40][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057884    
2025-01-06 21:21:41,383 - Epoch: [40][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057054    
2025-01-06 21:21:41,695 - Epoch: [40][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056271    
2025-01-06 21:21:42,050 - Epoch: [40][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.859375    Top5 12.109375    LR 0.001000    Time 0.055660    
2025-01-06 21:21:42,083 - Epoch: [40][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.289673    Top5 12.090680    LR 0.001000    Time 0.055593    
2025-01-06 21:21:43,849 - --- validate (epoch=40)-----------
2025-01-06 21:21:43,849 - 15217 samples (256 per mini-batch)
2025-01-06 21:21:52,586 - Epoch: [40][   10/   60]    Loss 3.044524    Top1 0.156250    Top5 0.273437    
2025-01-06 21:21:52,863 - Epoch: [40][   20/   60]    Loss 3.044524    Top1 0.156250    Top5 0.253906    
2025-01-06 21:21:53,124 - Epoch: [40][   30/   60]    Loss 3.044524    Top1 0.234375    Top5 0.338542    
2025-01-06 21:21:53,373 - Epoch: [40][   40/   60]    Loss 3.044524    Top1 0.214844    Top5 0.361328    
2025-01-06 21:21:53,640 - Epoch: [40][   50/   60]    Loss 3.044524    Top1 0.210937    Top5 0.343750    
2025-01-06 21:21:53,886 - Epoch: [40][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:21:55,444 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:21:55,444 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:21:55,924 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 40]
2025-01-06 21:21:55,928 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:21:55,959 - 

2025-01-06 21:21:55,959 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:22:04,883 - Epoch: [41][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.892071    
2025-01-06 21:22:05,176 - Epoch: [41][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.460726    
2025-01-06 21:22:05,489 - Epoch: [41][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.317561    
2025-01-06 21:22:05,795 - Epoch: [41][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.245840    
2025-01-06 21:22:06,106 - Epoch: [41][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.202890    
2025-01-06 21:22:06,420 - Epoch: [41][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.174297    
2025-01-06 21:22:06,734 - Epoch: [41][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.153884    
2025-01-06 21:22:07,077 - Epoch: [41][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.138946    
2025-01-06 21:22:07,381 - Epoch: [41][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.126881    
2025-01-06 21:22:07,692 - Epoch: [41][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.117306    
2025-01-06 21:22:07,992 - Epoch: [41][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.109369    
2025-01-06 21:22:08,309 - Epoch: [41][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.102896    
2025-01-06 21:22:08,624 - Epoch: [41][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.097401    
2025-01-06 21:22:08,958 - Epoch: [41][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092832    
2025-01-06 21:22:09,268 - Epoch: [41][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.088711    
2025-01-06 21:22:09,572 - Epoch: [41][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085064    
2025-01-06 21:22:09,874 - Epoch: [41][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081836    
2025-01-06 21:22:10,185 - Epoch: [41][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079011    
2025-01-06 21:22:10,515 - Epoch: [41][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076588    
2025-01-06 21:22:10,828 - Epoch: [41][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074328    
2025-01-06 21:22:11,150 - Epoch: [41][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072321    
2025-01-06 21:22:11,469 - Epoch: [41][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070482    
2025-01-06 21:22:11,770 - Epoch: [41][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068729    
2025-01-06 21:22:12,099 - Epoch: [41][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067231    
2025-01-06 21:22:12,420 - Epoch: [41][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065826    
2025-01-06 21:22:12,726 - Epoch: [41][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064472    
2025-01-06 21:22:13,032 - Epoch: [41][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063208    
2025-01-06 21:22:13,343 - Epoch: [41][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062063    
2025-01-06 21:22:13,656 - Epoch: [41][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061001    
2025-01-06 21:22:13,966 - Epoch: [41][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060000    
2025-01-06 21:22:14,293 - Epoch: [41][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059119    
2025-01-06 21:22:14,599 - Epoch: [41][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058229    
2025-01-06 21:22:14,924 - Epoch: [41][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057449    
2025-01-06 21:22:15,258 - Epoch: [41][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.078125    Top5 15.625000    LR 0.001000    Time 0.056743    
2025-01-06 21:22:15,289 - Epoch: [41][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.282116    Top5 14.861461    LR 0.001000    Time 0.056667    
2025-01-06 21:22:17,011 - --- validate (epoch=41)-----------
2025-01-06 21:22:17,011 - 15217 samples (256 per mini-batch)
2025-01-06 21:22:25,756 - Epoch: [41][   10/   60]    Loss 3.044523    Top1 0.234375    Top5 0.390625    
2025-01-06 21:22:26,017 - Epoch: [41][   20/   60]    Loss 3.044523    Top1 0.214844    Top5 0.351563    
2025-01-06 21:22:26,281 - Epoch: [41][   30/   60]    Loss 3.044523    Top1 0.208333    Top5 0.325521    
2025-01-06 21:22:26,530 - Epoch: [41][   40/   60]    Loss 3.044523    Top1 0.205078    Top5 0.292969    
2025-01-06 21:22:26,799 - Epoch: [41][   50/   60]    Loss 3.044523    Top1 0.195312    Top5 0.289063    
2025-01-06 21:22:27,052 - Epoch: [41][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:22:28,594 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:22:28,594 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:22:29,053 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 41]
2025-01-06 21:22:29,057 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:22:29,089 - 

2025-01-06 21:22:29,089 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:22:37,688 - Epoch: [42][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.859890    
2025-01-06 21:22:38,015 - Epoch: [42][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.446290    
2025-01-06 21:22:38,345 - Epoch: [42][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.308525    
2025-01-06 21:22:38,647 - Epoch: [42][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.238949    
2025-01-06 21:22:38,989 - Epoch: [42][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.197991    
2025-01-06 21:22:39,309 - Epoch: [42][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.170331    
2025-01-06 21:22:39,614 - Epoch: [42][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.150317    
2025-01-06 21:22:39,930 - Epoch: [42][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.135478    
2025-01-06 21:22:40,227 - Epoch: [42][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.123664    
2025-01-06 21:22:40,546 - Epoch: [42][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.114486    
2025-01-06 21:22:40,853 - Epoch: [42][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.106871    
2025-01-06 21:22:41,163 - Epoch: [42][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100539    
2025-01-06 21:22:41,466 - Epoch: [42][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095130    
2025-01-06 21:22:41,771 - Epoch: [42][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090515    
2025-01-06 21:22:42,079 - Epoch: [42][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086534    
2025-01-06 21:22:42,380 - Epoch: [42][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083011    
2025-01-06 21:22:42,695 - Epoch: [42][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079980    
2025-01-06 21:22:42,996 - Epoch: [42][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077205    
2025-01-06 21:22:43,306 - Epoch: [42][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074773    
2025-01-06 21:22:43,610 - Epoch: [42][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072559    
2025-01-06 21:22:43,920 - Epoch: [42][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070579    
2025-01-06 21:22:44,236 - Epoch: [42][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068807    
2025-01-06 21:22:44,551 - Epoch: [42][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067176    
2025-01-06 21:22:44,860 - Epoch: [42][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065665    
2025-01-06 21:22:45,173 - Epoch: [42][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064289    
2025-01-06 21:22:45,485 - Epoch: [42][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063018    
2025-01-06 21:22:45,785 - Epoch: [42][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061793    
2025-01-06 21:22:46,091 - Epoch: [42][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060680    
2025-01-06 21:22:46,398 - Epoch: [42][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059646    
2025-01-06 21:22:46,696 - Epoch: [42][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058646    
2025-01-06 21:22:47,004 - Epoch: [42][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057748    
2025-01-06 21:22:47,312 - Epoch: [42][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056897    
2025-01-06 21:22:47,620 - Epoch: [42][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056107    
2025-01-06 21:22:47,962 - Epoch: [42][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.687500    Top5 13.281250    LR 0.001000    Time 0.055463    
2025-01-06 21:22:48,000 - Epoch: [42][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.534005    Top5 14.357683    LR 0.001000    Time 0.055410    
2025-01-06 21:22:49,833 - --- validate (epoch=42)-----------
2025-01-06 21:22:49,833 - 15217 samples (256 per mini-batch)
2025-01-06 21:22:58,524 - Epoch: [42][   10/   60]    Loss 3.044524    Top1 0.156250    Top5 0.273437    
2025-01-06 21:22:58,804 - Epoch: [42][   20/   60]    Loss 3.044524    Top1 0.195312    Top5 0.253906    
2025-01-06 21:22:59,069 - Epoch: [42][   30/   60]    Loss 3.044524    Top1 0.182292    Top5 0.247396    
2025-01-06 21:22:59,313 - Epoch: [42][   40/   60]    Loss 3.044524    Top1 0.195312    Top5 0.283203    
2025-01-06 21:22:59,573 - Epoch: [42][   50/   60]    Loss 3.044524    Top1 0.179688    Top5 0.312500    
2025-01-06 21:22:59,807 - Epoch: [42][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:23:01,338 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:23:01,338 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:23:01,795 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 42]
2025-01-06 21:23:01,805 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:23:01,832 - 

2025-01-06 21:23:01,832 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:23:10,632 - Epoch: [43][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.879456    
2025-01-06 21:23:10,946 - Epoch: [43][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.455410    
2025-01-06 21:23:11,269 - Epoch: [43][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.314382    
2025-01-06 21:23:11,609 - Epoch: [43][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.244296    
2025-01-06 21:23:11,938 - Epoch: [43][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.202002    
2025-01-06 21:23:12,250 - Epoch: [43][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.173542    
2025-01-06 21:23:12,563 - Epoch: [43][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.153217    
2025-01-06 21:23:12,866 - Epoch: [43][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.137858    
2025-01-06 21:23:13,175 - Epoch: [43][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.125968    
2025-01-06 21:23:13,489 - Epoch: [43][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.116490    
2025-01-06 21:23:13,794 - Epoch: [43][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.108676    
2025-01-06 21:23:14,101 - Epoch: [43][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.102178    
2025-01-06 21:23:14,413 - Epoch: [43][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.096717    
2025-01-06 21:23:14,717 - Epoch: [43][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091984    
2025-01-06 21:23:15,031 - Epoch: [43][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087869    
2025-01-06 21:23:15,337 - Epoch: [43][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084290    
2025-01-06 21:23:15,651 - Epoch: [43][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081178    
2025-01-06 21:23:15,985 - Epoch: [43][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078522    
2025-01-06 21:23:16,315 - Epoch: [43][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076106    
2025-01-06 21:23:16,653 - Epoch: [43][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073989    
2025-01-06 21:23:16,985 - Epoch: [43][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072050    
2025-01-06 21:23:17,350 - Epoch: [43][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070432    
2025-01-06 21:23:17,743 - Epoch: [43][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069081    
2025-01-06 21:23:18,091 - Epoch: [43][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067651    
2025-01-06 21:23:18,441 - Epoch: [43][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066342    
2025-01-06 21:23:18,825 - Epoch: [43][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065239    
2025-01-06 21:23:19,214 - Epoch: [43][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064264    
2025-01-06 21:23:19,604 - Epoch: [43][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063360    
2025-01-06 21:23:20,013 - Epoch: [43][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062585    
2025-01-06 21:23:20,375 - Epoch: [43][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061709    
2025-01-06 21:23:20,770 - Epoch: [43][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060992    
2025-01-06 21:23:21,192 - Epoch: [43][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060400    
2025-01-06 21:23:21,682 - Epoch: [43][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060056    
2025-01-06 21:23:22,225 - Epoch: [43][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.125000    Top5 12.109375    LR 0.001000    Time 0.059880    
2025-01-06 21:23:22,276 - Epoch: [43][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.022670    Top5 11.586902    LR 0.001000    Time 0.059854    
2025-01-06 21:23:24,792 - --- validate (epoch=43)-----------
2025-01-06 21:23:24,792 - 15217 samples (256 per mini-batch)
2025-01-06 21:23:35,167 - Epoch: [43][   10/   60]    Loss 3.044524    Top1 0.234375    Top5 0.312500    
2025-01-06 21:23:35,421 - Epoch: [43][   20/   60]    Loss 3.044524    Top1 0.214844    Top5 0.312500    
2025-01-06 21:23:35,701 - Epoch: [43][   30/   60]    Loss 3.044524    Top1 0.208333    Top5 0.312500    
2025-01-06 21:23:35,954 - Epoch: [43][   40/   60]    Loss 3.044524    Top1 0.214844    Top5 0.312500    
2025-01-06 21:23:36,208 - Epoch: [43][   50/   60]    Loss 3.044524    Top1 0.210937    Top5 0.320312    
2025-01-06 21:23:36,444 - Epoch: [43][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:23:37,964 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:23:37,964 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:23:38,638 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 43]
2025-01-06 21:23:38,638 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:23:38,671 - 

2025-01-06 21:23:38,671 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:23:47,666 - Epoch: [44][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.899398    
2025-01-06 21:23:47,991 - Epoch: [44][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.465945    
2025-01-06 21:23:48,309 - Epoch: [44][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.321205    
2025-01-06 21:23:48,645 - Epoch: [44][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.249313    
2025-01-06 21:23:48,967 - Epoch: [44][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.205897    
2025-01-06 21:23:49,270 - Epoch: [44][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.176628    
2025-01-06 21:23:49,602 - Epoch: [44][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.156131    
2025-01-06 21:23:49,922 - Epoch: [44][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.140490    
2025-01-06 21:23:50,236 - Epoch: [44][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.128367    
2025-01-06 21:23:50,551 - Epoch: [44][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.118683    
2025-01-06 21:23:50,863 - Epoch: [44][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.110736    
2025-01-06 21:23:51,163 - Epoch: [44][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.104008    
2025-01-06 21:23:51,493 - Epoch: [44][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098446    
2025-01-06 21:23:51,809 - Epoch: [44][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093671    
2025-01-06 21:23:52,121 - Epoch: [44][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089492    
2025-01-06 21:23:52,428 - Epoch: [44][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085784    
2025-01-06 21:23:52,750 - Epoch: [44][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082632    
2025-01-06 21:23:53,055 - Epoch: [44][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079732    
2025-01-06 21:23:53,374 - Epoch: [44][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077215    
2025-01-06 21:23:53,711 - Epoch: [44][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075040    
2025-01-06 21:23:54,047 - Epoch: [44][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073066    
2025-01-06 21:23:54,357 - Epoch: [44][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071145    
2025-01-06 21:23:54,667 - Epoch: [44][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069399    
2025-01-06 21:23:54,998 - Epoch: [44][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067880    
2025-01-06 21:23:55,318 - Epoch: [44][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066445    
2025-01-06 21:23:55,633 - Epoch: [44][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065101    
2025-01-06 21:23:55,944 - Epoch: [44][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063833    
2025-01-06 21:23:56,251 - Epoch: [44][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062651    
2025-01-06 21:23:56,563 - Epoch: [44][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061564    
2025-01-06 21:23:56,944 - Epoch: [44][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060783    
2025-01-06 21:23:57,366 - Epoch: [44][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060153    
2025-01-06 21:23:57,772 - Epoch: [44][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059539    
2025-01-06 21:23:58,181 - Epoch: [44][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058974    
2025-01-06 21:23:58,673 - Epoch: [44][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.687500    Top5 11.718750    LR 0.001000    Time 0.058683    
2025-01-06 21:23:58,709 - Epoch: [44][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.282116    Top5 10.327456    LR 0.001000    Time 0.058617    
2025-01-06 21:24:00,614 - --- validate (epoch=44)-----------
2025-01-06 21:24:00,616 - 15217 samples (256 per mini-batch)
2025-01-06 21:24:09,407 - Epoch: [44][   10/   60]    Loss 3.044524    Top1 0.156250    Top5 0.234375    
2025-01-06 21:24:09,668 - Epoch: [44][   20/   60]    Loss 3.044524    Top1 0.156250    Top5 0.253906    
2025-01-06 21:24:09,944 - Epoch: [44][   30/   60]    Loss 3.044524    Top1 0.195312    Top5 0.299479    
2025-01-06 21:24:10,208 - Epoch: [44][   40/   60]    Loss 3.044524    Top1 0.214844    Top5 0.322266    
2025-01-06 21:24:10,478 - Epoch: [44][   50/   60]    Loss 3.044524    Top1 0.210937    Top5 0.328125    
2025-01-06 21:24:10,711 - Epoch: [44][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:24:12,247 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:24:12,250 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:24:12,775 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 44]
2025-01-06 21:24:12,775 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:24:12,823 - 

2025-01-06 21:24:12,823 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:24:21,822 - Epoch: [45][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.899764    
2025-01-06 21:24:22,141 - Epoch: [45][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.465853    
2025-01-06 21:24:22,456 - Epoch: [45][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.321051    
2025-01-06 21:24:22,760 - Epoch: [45][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.248393    
2025-01-06 21:24:23,078 - Epoch: [45][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.205044    
2025-01-06 21:24:23,396 - Epoch: [45][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.176171    
2025-01-06 21:24:23,710 - Epoch: [45][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.155478    
2025-01-06 21:24:24,032 - Epoch: [45][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.140074    
2025-01-06 21:24:24,346 - Epoch: [45][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.128002    
2025-01-06 21:24:24,666 - Epoch: [45][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.118396    
2025-01-06 21:24:24,997 - Epoch: [45][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.110645    
2025-01-06 21:24:25,317 - Epoch: [45][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.104088    
2025-01-06 21:24:25,632 - Epoch: [45][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098509    
2025-01-06 21:24:25,937 - Epoch: [45][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093645    
2025-01-06 21:24:26,242 - Epoch: [45][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089440    
2025-01-06 21:24:26,556 - Epoch: [45][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085811    
2025-01-06 21:24:26,870 - Epoch: [45][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082611    
2025-01-06 21:24:27,164 - Epoch: [45][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079657    
2025-01-06 21:24:27,479 - Epoch: [45][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077120    
2025-01-06 21:24:27,800 - Epoch: [45][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074860    
2025-01-06 21:24:28,110 - Epoch: [45][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072771    
2025-01-06 21:24:28,433 - Epoch: [45][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070884    
2025-01-06 21:24:28,752 - Epoch: [45][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069188    
2025-01-06 21:24:29,076 - Epoch: [45][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067658    
2025-01-06 21:24:29,389 - Epoch: [45][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066204    
2025-01-06 21:24:29,705 - Epoch: [45][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064872    
2025-01-06 21:24:30,015 - Epoch: [45][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063617    
2025-01-06 21:24:30,330 - Epoch: [45][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062470    
2025-01-06 21:24:30,638 - Epoch: [45][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061379    
2025-01-06 21:24:30,942 - Epoch: [45][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060344    
2025-01-06 21:24:31,255 - Epoch: [45][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059407    
2025-01-06 21:24:31,556 - Epoch: [45][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058492    
2025-01-06 21:24:31,900 - Epoch: [45][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057763    
2025-01-06 21:24:32,266 - Epoch: [45][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.515625    Top5 11.718750    LR 0.001000    Time 0.057139    
2025-01-06 21:24:32,300 - Epoch: [45][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.778338    Top5 11.586902    LR 0.001000    Time 0.057069    
2025-01-06 21:24:34,294 - --- validate (epoch=45)-----------
2025-01-06 21:24:34,294 - 15217 samples (256 per mini-batch)
2025-01-06 21:24:43,334 - Epoch: [45][   10/   60]    Loss 3.044524    Top1 0.117188    Top5 0.312500    
2025-01-06 21:24:43,613 - Epoch: [45][   20/   60]    Loss 3.044524    Top1 0.136719    Top5 0.273437    
2025-01-06 21:24:43,860 - Epoch: [45][   30/   60]    Loss 3.044524    Top1 0.208333    Top5 0.338542    
2025-01-06 21:24:44,124 - Epoch: [45][   40/   60]    Loss 3.044524    Top1 0.185547    Top5 0.322266    
2025-01-06 21:24:44,392 - Epoch: [45][   50/   60]    Loss 3.044524    Top1 0.187500    Top5 0.304688    
2025-01-06 21:24:44,645 - Epoch: [45][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:24:46,106 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:24:46,106 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:24:46,584 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 45]
2025-01-06 21:24:46,584 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:24:46,616 - 

2025-01-06 21:24:46,617 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:24:55,417 - Epoch: [46][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.879939    
2025-01-06 21:24:55,735 - Epoch: [46][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.455886    
2025-01-06 21:24:56,086 - Epoch: [46][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.315603    
2025-01-06 21:24:56,401 - Epoch: [46][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.244499    
2025-01-06 21:24:56,754 - Epoch: [46][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.202653    
2025-01-06 21:24:57,059 - Epoch: [46][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.173960    
2025-01-06 21:24:57,387 - Epoch: [46][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.153796    
2025-01-06 21:24:57,714 - Epoch: [46][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.138655    
2025-01-06 21:24:58,026 - Epoch: [46][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.126651    
2025-01-06 21:24:58,343 - Epoch: [46][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.117160    
2025-01-06 21:24:58,654 - Epoch: [46][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.109312    
2025-01-06 21:24:58,958 - Epoch: [46][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.102737    
2025-01-06 21:24:59,272 - Epoch: [46][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.097228    
2025-01-06 21:24:59,585 - Epoch: [46][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092518    
2025-01-06 21:24:59,888 - Epoch: [46][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.088365    
2025-01-06 21:25:00,205 - Epoch: [46][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084825    
2025-01-06 21:25:00,506 - Epoch: [46][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081606    
2025-01-06 21:25:00,831 - Epoch: [46][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078877    
2025-01-06 21:25:01,145 - Epoch: [46][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076381    
2025-01-06 21:25:01,461 - Epoch: [46][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074128    
2025-01-06 21:25:01,772 - Epoch: [46][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072082    
2025-01-06 21:25:02,085 - Epoch: [46][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070228    
2025-01-06 21:25:02,389 - Epoch: [46][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068496    
2025-01-06 21:25:02,718 - Epoch: [46][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067011    
2025-01-06 21:25:03,031 - Epoch: [46][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065586    
2025-01-06 21:25:03,348 - Epoch: [46][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064279    
2025-01-06 21:25:03,673 - Epoch: [46][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063102    
2025-01-06 21:25:03,988 - Epoch: [46][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061976    
2025-01-06 21:25:04,317 - Epoch: [46][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060973    
2025-01-06 21:25:04,643 - Epoch: [46][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060028    
2025-01-06 21:25:04,947 - Epoch: [46][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059070    
2025-01-06 21:25:05,253 - Epoch: [46][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058180    
2025-01-06 21:25:05,573 - Epoch: [46][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057387    
2025-01-06 21:25:05,944 - Epoch: [46][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.078125    Top5 14.453125    LR 0.001000    Time 0.056786    
2025-01-06 21:25:05,971 - Epoch: [46][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.534005    Top5 13.350126    LR 0.001000    Time 0.056699    
2025-01-06 21:25:07,815 - --- validate (epoch=46)-----------
2025-01-06 21:25:07,815 - 15217 samples (256 per mini-batch)
2025-01-06 21:25:16,613 - Epoch: [46][   10/   60]    Loss 3.044524    Top1 0.156250    Top5 0.273437    
2025-01-06 21:25:16,892 - Epoch: [46][   20/   60]    Loss 3.044524    Top1 0.195312    Top5 0.273437    
2025-01-06 21:25:17,142 - Epoch: [46][   30/   60]    Loss 3.044524    Top1 0.182292    Top5 0.273437    
2025-01-06 21:25:17,388 - Epoch: [46][   40/   60]    Loss 3.044524    Top1 0.175781    Top5 0.263672    
2025-01-06 21:25:17,654 - Epoch: [46][   50/   60]    Loss 3.044524    Top1 0.171875    Top5 0.296875    
2025-01-06 21:25:17,915 - Epoch: [46][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:25:19,412 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:25:19,412 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:25:19,900 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 46]
2025-01-06 21:25:19,906 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:25:19,939 - 

2025-01-06 21:25:19,939 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:25:28,655 - Epoch: [47][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.871490    
2025-01-06 21:25:28,957 - Epoch: [47][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.450852    
2025-01-06 21:25:29,276 - Epoch: [47][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.311191    
2025-01-06 21:25:29,589 - Epoch: [47][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.241234    
2025-01-06 21:25:29,935 - Epoch: [47][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.199903    
2025-01-06 21:25:30,249 - Epoch: [47][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.171813    
2025-01-06 21:25:30,564 - Epoch: [47][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.151780    
2025-01-06 21:25:30,877 - Epoch: [47][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.136709    
2025-01-06 21:25:31,188 - Epoch: [47][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.124980    
2025-01-06 21:25:31,485 - Epoch: [47][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.115444    
2025-01-06 21:25:31,809 - Epoch: [47][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.107802    
2025-01-06 21:25:32,128 - Epoch: [47][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.101474    
2025-01-06 21:25:32,447 - Epoch: [47][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.096124    
2025-01-06 21:25:32,755 - Epoch: [47][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091440    
2025-01-06 21:25:33,083 - Epoch: [47][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087530    
2025-01-06 21:25:33,403 - Epoch: [47][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084061    
2025-01-06 21:25:33,714 - Epoch: [47][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080946    
2025-01-06 21:25:34,029 - Epoch: [47][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078190    
2025-01-06 21:25:34,377 - Epoch: [47][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075887    
2025-01-06 21:25:34,714 - Epoch: [47][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073774    
2025-01-06 21:25:35,032 - Epoch: [47][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071767    
2025-01-06 21:25:35,345 - Epoch: [47][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069921    
2025-01-06 21:25:35,653 - Epoch: [47][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068217    
2025-01-06 21:25:35,993 - Epoch: [47][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066794    
2025-01-06 21:25:36,301 - Epoch: [47][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065353    
2025-01-06 21:25:36,598 - Epoch: [47][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063981    
2025-01-06 21:25:36,952 - Epoch: [47][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062885    
2025-01-06 21:25:37,268 - Epoch: [47][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061769    
2025-01-06 21:25:37,580 - Epoch: [47][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060715    
2025-01-06 21:25:37,885 - Epoch: [47][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059708    
2025-01-06 21:25:38,185 - Epoch: [47][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058750    
2025-01-06 21:25:38,499 - Epoch: [47][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057895    
2025-01-06 21:25:38,832 - Epoch: [47][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057149    
2025-01-06 21:25:39,198 - Epoch: [47][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.078125    Top5 12.890625    LR 0.001000    Time 0.056528    
2025-01-06 21:25:39,228 - Epoch: [47][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.037783    Top5 13.350126    LR 0.001000    Time 0.056452    
2025-01-06 21:25:41,262 - --- validate (epoch=47)-----------
2025-01-06 21:25:41,262 - 15217 samples (256 per mini-batch)
2025-01-06 21:25:50,114 - Epoch: [47][   10/   60]    Loss 3.044524    Top1 0.117188    Top5 0.195312    
2025-01-06 21:25:50,376 - Epoch: [47][   20/   60]    Loss 3.044524    Top1 0.214844    Top5 0.292969    
2025-01-06 21:25:50,639 - Epoch: [47][   30/   60]    Loss 3.044524    Top1 0.208333    Top5 0.299479    
2025-01-06 21:25:50,904 - Epoch: [47][   40/   60]    Loss 3.044524    Top1 0.205078    Top5 0.322266    
2025-01-06 21:25:51,156 - Epoch: [47][   50/   60]    Loss 3.044524    Top1 0.195312    Top5 0.320312    
2025-01-06 21:25:51,407 - Epoch: [47][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:25:52,999 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:25:52,999 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:25:53,475 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 47]
2025-01-06 21:25:53,481 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:25:53,516 - 

2025-01-06 21:25:53,516 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:26:02,285 - Epoch: [48][   10/  341]    Overall Loss 3.044523    Objective Loss 3.044523                                        LR 0.001000    Time 0.876882    
2025-01-06 21:26:02,601 - Epoch: [48][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.454241    
2025-01-06 21:26:02,926 - Epoch: [48][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.313680    
2025-01-06 21:26:03,237 - Epoch: [48][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.242984    
2025-01-06 21:26:03,545 - Epoch: [48][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.200554    
2025-01-06 21:26:03,862 - Epoch: [48][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.172408    
2025-01-06 21:26:04,167 - Epoch: [48][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.152127    
2025-01-06 21:26:04,480 - Epoch: [48][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.137030    
2025-01-06 21:26:04,803 - Epoch: [48][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.125393    
2025-01-06 21:26:05,108 - Epoch: [48][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.115899    
2025-01-06 21:26:05,415 - Epoch: [48][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.108141    
2025-01-06 21:26:05,758 - Epoch: [48][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.101986    
2025-01-06 21:26:06,069 - Epoch: [48][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.096536    
2025-01-06 21:26:06,383 - Epoch: [48][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091883    
2025-01-06 21:26:06,680 - Epoch: [48][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087724    
2025-01-06 21:26:07,011 - Epoch: [48][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084310    
2025-01-06 21:26:07,319 - Epoch: [48][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081161    
2025-01-06 21:26:07,625 - Epoch: [48][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078339    
2025-01-06 21:26:07,941 - Epoch: [48][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075881    
2025-01-06 21:26:08,248 - Epoch: [48][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073582    
2025-01-06 21:26:08,568 - Epoch: [48][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071599    
2025-01-06 21:26:08,891 - Epoch: [48][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069804    
2025-01-06 21:26:09,221 - Epoch: [48][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068204    
2025-01-06 21:26:09,527 - Epoch: [48][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066639    
2025-01-06 21:26:09,841 - Epoch: [48][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065230    
2025-01-06 21:26:10,160 - Epoch: [48][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063930    
2025-01-06 21:26:10,461 - Epoch: [48][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062677    
2025-01-06 21:26:10,767 - Epoch: [48][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061533    
2025-01-06 21:26:11,100 - Epoch: [48][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060560    
2025-01-06 21:26:11,410 - Epoch: [48][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059567    
2025-01-06 21:26:11,704 - Epoch: [48][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058595    
2025-01-06 21:26:12,015 - Epoch: [48][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057709    
2025-01-06 21:26:12,320 - Epoch: [48][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056885    
2025-01-06 21:26:12,663 - Epoch: [48][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 1.562500    Top5 11.718750    LR 0.001000    Time 0.056216    
2025-01-06 21:26:12,692 - Epoch: [48][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.022670    Top5 13.853904    LR 0.001000    Time 0.056138    
2025-01-06 21:26:14,336 - --- validate (epoch=48)-----------
2025-01-06 21:26:14,336 - 15217 samples (256 per mini-batch)
2025-01-06 21:26:23,323 - Epoch: [48][   10/   60]    Loss 3.044524    Top1 0.273437    Top5 0.351563    
2025-01-06 21:26:23,582 - Epoch: [48][   20/   60]    Loss 3.044524    Top1 0.234375    Top5 0.371094    
2025-01-06 21:26:23,857 - Epoch: [48][   30/   60]    Loss 3.044523    Top1 0.221354    Top5 0.325521    
2025-01-06 21:26:24,131 - Epoch: [48][   40/   60]    Loss 3.044523    Top1 0.214844    Top5 0.322266    
2025-01-06 21:26:24,407 - Epoch: [48][   50/   60]    Loss 3.044523    Top1 0.195312    Top5 0.304688    
2025-01-06 21:26:24,674 - Epoch: [48][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:26:26,188 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:26:26,188 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:26:26,650 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 48]
2025-01-06 21:26:26,650 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:26:26,684 - 

2025-01-06 21:26:26,684 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:26:35,557 - Epoch: [49][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.887304    
2025-01-06 21:26:35,908 - Epoch: [49][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.460742    
2025-01-06 21:26:36,241 - Epoch: [49][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.318251    
2025-01-06 21:26:36,583 - Epoch: [49][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.247238    
2025-01-06 21:26:36,918 - Epoch: [49][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.204489    
2025-01-06 21:26:37,244 - Epoch: [49][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.175834    
2025-01-06 21:26:37,575 - Epoch: [49][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.155315    
2025-01-06 21:26:37,875 - Epoch: [49][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.139656    
2025-01-06 21:26:38,184 - Epoch: [49][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.127566    
2025-01-06 21:26:38,489 - Epoch: [49][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.117864    
2025-01-06 21:26:38,803 - Epoch: [49][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.110003    
2025-01-06 21:26:39,106 - Epoch: [49][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.103359    
2025-01-06 21:26:39,415 - Epoch: [49][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.097706    
2025-01-06 21:26:39,724 - Epoch: [49][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092935    
2025-01-06 21:26:40,036 - Epoch: [49][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.088815    
2025-01-06 21:26:40,342 - Epoch: [49][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085142    
2025-01-06 21:26:40,655 - Epoch: [49][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081973    
2025-01-06 21:26:40,961 - Epoch: [49][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079109    
2025-01-06 21:26:41,273 - Epoch: [49][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076589    
2025-01-06 21:26:41,586 - Epoch: [49][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074324    
2025-01-06 21:26:41,897 - Epoch: [49][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072263    
2025-01-06 21:26:42,206 - Epoch: [49][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070384    
2025-01-06 21:26:42,517 - Epoch: [49][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068675    
2025-01-06 21:26:42,879 - Epoch: [49][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067318    
2025-01-06 21:26:43,180 - Epoch: [49][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065818    
2025-01-06 21:26:43,495 - Epoch: [49][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064499    
2025-01-06 21:26:43,808 - Epoch: [49][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063269    
2025-01-06 21:26:44,129 - Epoch: [49][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062156    
2025-01-06 21:26:44,460 - Epoch: [49][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061149    
2025-01-06 21:26:44,780 - Epoch: [49][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060180    
2025-01-06 21:26:45,116 - Epoch: [49][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059288    
2025-01-06 21:26:45,428 - Epoch: [49][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058406    
2025-01-06 21:26:45,822 - Epoch: [49][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057802    
2025-01-06 21:26:46,237 - Epoch: [49][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.078125    Top5 16.015625    LR 0.001000    Time 0.057322    
2025-01-06 21:26:46,263 - Epoch: [49][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.534005    Top5 15.617128    LR 0.001000    Time 0.057228    
2025-01-06 21:26:48,145 - --- validate (epoch=49)-----------
2025-01-06 21:26:48,147 - 15217 samples (256 per mini-batch)
2025-01-06 21:26:57,286 - Epoch: [49][   10/   60]    Loss 3.044524    Top1 0.195312    Top5 0.390625    
2025-01-06 21:26:57,556 - Epoch: [49][   20/   60]    Loss 3.044524    Top1 0.175781    Top5 0.292969    
2025-01-06 21:26:57,825 - Epoch: [49][   30/   60]    Loss 3.044523    Top1 0.208333    Top5 0.299479    
2025-01-06 21:26:58,080 - Epoch: [49][   40/   60]    Loss 3.044523    Top1 0.195312    Top5 0.302734    
2025-01-06 21:26:58,322 - Epoch: [49][   50/   60]    Loss 3.044523    Top1 0.210937    Top5 0.312500    
2025-01-06 21:26:58,568 - Epoch: [49][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:27:00,059 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:27:00,063 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:27:00,525 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 49]
2025-01-06 21:27:00,531 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:27:00,561 - 

2025-01-06 21:27:00,567 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:27:08,981 - Epoch: [50][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.841388    
2025-01-06 21:27:09,308 - Epoch: [50][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.437014    
2025-01-06 21:27:09,637 - Epoch: [50][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.302313    
2025-01-06 21:27:09,961 - Epoch: [50][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.234776    
2025-01-06 21:27:10,263 - Epoch: [50][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.193869    
2025-01-06 21:27:10,577 - Epoch: [50][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.166796    
2025-01-06 21:27:10,891 - Epoch: [50][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.147454    
2025-01-06 21:27:11,201 - Epoch: [50][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.132896    
2025-01-06 21:27:11,504 - Epoch: [50][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.121499    
2025-01-06 21:27:11,807 - Epoch: [50][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.112377    
2025-01-06 21:27:12,121 - Epoch: [50][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.105017    
2025-01-06 21:27:12,435 - Epoch: [50][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098878    
2025-01-06 21:27:12,742 - Epoch: [50][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093636    
2025-01-06 21:27:13,044 - Epoch: [50][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089105    
2025-01-06 21:27:13,358 - Epoch: [50][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085258    
2025-01-06 21:27:13,673 - Epoch: [50][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081896    
2025-01-06 21:27:14,019 - Epoch: [50][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079114    
2025-01-06 21:27:14,335 - Epoch: [50][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076476    
2025-01-06 21:27:14,646 - Epoch: [50][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074087    
2025-01-06 21:27:14,976 - Epoch: [50][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072024    
2025-01-06 21:27:15,280 - Epoch: [50][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070040    
2025-01-06 21:27:15,588 - Epoch: [50][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068258    
2025-01-06 21:27:15,901 - Epoch: [50][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066652    
2025-01-06 21:27:16,214 - Epoch: [50][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065177    
2025-01-06 21:27:16,521 - Epoch: [50][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063797    
2025-01-06 21:27:16,839 - Epoch: [50][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062565    
2025-01-06 21:27:17,157 - Epoch: [50][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061429    
2025-01-06 21:27:17,466 - Epoch: [50][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060337    
2025-01-06 21:27:17,773 - Epoch: [50][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059314    
2025-01-06 21:27:18,108 - Epoch: [50][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058456    
2025-01-06 21:27:18,414 - Epoch: [50][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057556    
2025-01-06 21:27:18,720 - Epoch: [50][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056714    
2025-01-06 21:27:19,061 - Epoch: [50][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056030    
2025-01-06 21:27:19,418 - Epoch: [50][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.468750    Top5 12.500000    LR 0.001000    Time 0.055429    
2025-01-06 21:27:19,458 - Epoch: [50][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.037783    Top5 11.838791    LR 0.001000    Time 0.055386    
2025-01-06 21:27:21,508 - --- validate (epoch=50)-----------
2025-01-06 21:27:21,509 - 15217 samples (256 per mini-batch)
2025-01-06 21:27:30,424 - Epoch: [50][   10/   60]    Loss 3.044523    Top1 0.273437    Top5 0.429687    
2025-01-06 21:27:30,681 - Epoch: [50][   20/   60]    Loss 3.044523    Top1 0.253906    Top5 0.449219    
2025-01-06 21:27:30,961 - Epoch: [50][   30/   60]    Loss 3.044523    Top1 0.221354    Top5 0.364583    
2025-01-06 21:27:31,206 - Epoch: [50][   40/   60]    Loss 3.044524    Top1 0.175781    Top5 0.312500    
2025-01-06 21:27:31,461 - Epoch: [50][   50/   60]    Loss 3.044524    Top1 0.179688    Top5 0.296875    
2025-01-06 21:27:31,708 - Epoch: [50][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:27:33,251 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:27:33,251 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:27:34,072 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 50]
2025-01-06 21:27:34,072 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:27:34,115 - 

2025-01-06 21:27:34,115 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:27:43,175 - Epoch: [51][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.906047    
2025-01-06 21:27:43,489 - Epoch: [51][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.468713    
2025-01-06 21:27:43,803 - Epoch: [51][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.322879    
2025-01-06 21:27:44,139 - Epoch: [51][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.250522    
2025-01-06 21:27:44,463 - Epoch: [51][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.206885    
2025-01-06 21:27:44,766 - Epoch: [51][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.177453    
2025-01-06 21:27:45,076 - Epoch: [51][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.156525    
2025-01-06 21:27:45,382 - Epoch: [51][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.140780    
2025-01-06 21:27:45,690 - Epoch: [51][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.128565    
2025-01-06 21:27:46,002 - Epoch: [51][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.118825    
2025-01-06 21:27:46,312 - Epoch: [51][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.110844    
2025-01-06 21:27:46,609 - Epoch: [51][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.104062    
2025-01-06 21:27:46,922 - Epoch: [51][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098466    
2025-01-06 21:27:47,233 - Epoch: [51][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093654    
2025-01-06 21:27:47,537 - Epoch: [51][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089425    
2025-01-06 21:27:47,837 - Epoch: [51][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085708    
2025-01-06 21:27:48,170 - Epoch: [51][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082629    
2025-01-06 21:27:48,475 - Epoch: [51][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079730    
2025-01-06 21:27:48,798 - Epoch: [51][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077235    
2025-01-06 21:27:49,113 - Epoch: [51][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074947    
2025-01-06 21:27:49,424 - Epoch: [51][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072849    
2025-01-06 21:27:49,743 - Epoch: [51][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070945    
2025-01-06 21:27:50,044 - Epoch: [51][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069169    
2025-01-06 21:27:50,369 - Epoch: [51][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067597    
2025-01-06 21:27:50,670 - Epoch: [51][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066088    
2025-01-06 21:27:50,990 - Epoch: [51][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064774    
2025-01-06 21:27:51,298 - Epoch: [51][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063517    
2025-01-06 21:27:51,626 - Epoch: [51][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062420    
2025-01-06 21:27:51,946 - Epoch: [51][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061371    
2025-01-06 21:27:52,284 - Epoch: [51][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060451    
2025-01-06 21:27:52,601 - Epoch: [51][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059499    
2025-01-06 21:27:52,920 - Epoch: [51][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058629    
2025-01-06 21:27:53,221 - Epoch: [51][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057764    
2025-01-06 21:27:53,596 - Epoch: [51][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 7.031250    Top5 15.234375    LR 0.001000    Time 0.057139    
2025-01-06 21:27:53,623 - Epoch: [51][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 6.045340    Top5 14.609572    LR 0.001000    Time 0.057047    
2025-01-06 21:27:55,457 - --- validate (epoch=51)-----------
2025-01-06 21:27:55,457 - 15217 samples (256 per mini-batch)
2025-01-06 21:28:04,244 - Epoch: [51][   10/   60]    Loss 3.044524    Top1 0.273437    Top5 0.468750    
2025-01-06 21:28:04,536 - Epoch: [51][   20/   60]    Loss 3.044524    Top1 0.253906    Top5 0.390625    
2025-01-06 21:28:04,804 - Epoch: [51][   30/   60]    Loss 3.044524    Top1 0.208333    Top5 0.312500    
2025-01-06 21:28:05,072 - Epoch: [51][   40/   60]    Loss 3.044523    Top1 0.205078    Top5 0.341797    
2025-01-06 21:28:05,328 - Epoch: [51][   50/   60]    Loss 3.044523    Top1 0.210937    Top5 0.328125    
2025-01-06 21:28:05,566 - Epoch: [51][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:28:07,138 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:28:07,139 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:28:07,587 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 51]
2025-01-06 21:28:07,587 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:28:07,620 - 

2025-01-06 21:28:07,621 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:28:16,583 - Epoch: [52][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.896110    
2025-01-06 21:28:16,896 - Epoch: [52][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.463664    
2025-01-06 21:28:17,221 - Epoch: [52][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.319948    
2025-01-06 21:28:17,533 - Epoch: [52][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.247715    
2025-01-06 21:28:17,844 - Epoch: [52][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.204389    
2025-01-06 21:28:18,162 - Epoch: [52][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.175618    
2025-01-06 21:28:18,472 - Epoch: [52][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.154929    
2025-01-06 21:28:18,774 - Epoch: [52][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.139341    
2025-01-06 21:28:19,087 - Epoch: [52][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.127340    
2025-01-06 21:28:19,395 - Epoch: [52][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.117582    
2025-01-06 21:28:19,698 - Epoch: [52][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.109649    
2025-01-06 21:28:20,029 - Epoch: [52][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.103268    
2025-01-06 21:28:20,334 - Epoch: [52][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.097671    
2025-01-06 21:28:20,643 - Epoch: [52][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092902    
2025-01-06 21:28:20,973 - Epoch: [52][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.088908    
2025-01-06 21:28:21,293 - Epoch: [52][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085353    
2025-01-06 21:28:21,597 - Epoch: [52][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082122    
2025-01-06 21:28:21,918 - Epoch: [52][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079327    
2025-01-06 21:28:22,250 - Epoch: [52][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076902    
2025-01-06 21:28:22,568 - Epoch: [52][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074648    
2025-01-06 21:28:22,881 - Epoch: [52][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072582    
2025-01-06 21:28:23,194 - Epoch: [52][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070703    
2025-01-06 21:28:23,518 - Epoch: [52][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069034    
2025-01-06 21:28:23,827 - Epoch: [52][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067439    
2025-01-06 21:28:24,133 - Epoch: [52][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065965    
2025-01-06 21:28:24,439 - Epoch: [52][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064606    
2025-01-06 21:28:24,747 - Epoch: [52][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063352    
2025-01-06 21:28:25,049 - Epoch: [52][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062169    
2025-01-06 21:28:25,383 - Epoch: [52][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061177    
2025-01-06 21:28:25,719 - Epoch: [52][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060257    
2025-01-06 21:28:26,060 - Epoch: [52][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059413    
2025-01-06 21:28:26,385 - Epoch: [52][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058568    
2025-01-06 21:28:26,715 - Epoch: [52][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057793    
2025-01-06 21:28:27,073 - Epoch: [52][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.687500    Top5 14.453125    LR 0.001000    Time 0.057128    
2025-01-06 21:28:27,100 - Epoch: [52][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.037783    Top5 13.602015    LR 0.001000    Time 0.057037    
2025-01-06 21:28:28,826 - --- validate (epoch=52)-----------
2025-01-06 21:28:28,826 - 15217 samples (256 per mini-batch)
2025-01-06 21:28:37,662 - Epoch: [52][   10/   60]    Loss 3.044524    Top1 0.156250    Top5 0.234375    
2025-01-06 21:28:37,912 - Epoch: [52][   20/   60]    Loss 3.044524    Top1 0.234375    Top5 0.312500    
2025-01-06 21:28:38,190 - Epoch: [52][   30/   60]    Loss 3.044524    Top1 0.234375    Top5 0.338542    
2025-01-06 21:28:38,451 - Epoch: [52][   40/   60]    Loss 3.044524    Top1 0.205078    Top5 0.302734    
2025-01-06 21:28:38,704 - Epoch: [52][   50/   60]    Loss 3.044524    Top1 0.210937    Top5 0.328125    
2025-01-06 21:28:38,940 - Epoch: [52][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:28:40,492 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:28:40,494 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:28:40,967 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 52]
2025-01-06 21:28:40,970 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:28:41,003 - 

2025-01-06 21:28:41,003 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:28:49,761 - Epoch: [53][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.875475    
2025-01-06 21:28:50,101 - Epoch: [53][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.454721    
2025-01-06 21:28:50,434 - Epoch: [53][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.314245    
2025-01-06 21:28:50,749 - Epoch: [53][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.243573    
2025-01-06 21:28:51,105 - Epoch: [53][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.201973    
2025-01-06 21:28:51,448 - Epoch: [53][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.174017    
2025-01-06 21:28:51,766 - Epoch: [53][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.153708    
2025-01-06 21:28:52,086 - Epoch: [53][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.138482    
2025-01-06 21:28:52,400 - Epoch: [53][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.126578    
2025-01-06 21:28:52,739 - Epoch: [53][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.117313    
2025-01-06 21:28:53,066 - Epoch: [53][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.109605    
2025-01-06 21:28:53,387 - Epoch: [53][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.103141    
2025-01-06 21:28:53,694 - Epoch: [53][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.097568    
2025-01-06 21:28:54,002 - Epoch: [53][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092801    
2025-01-06 21:28:54,323 - Epoch: [53][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.088752    
2025-01-06 21:28:54,626 - Epoch: [53][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085104    
2025-01-06 21:28:54,939 - Epoch: [53][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081937    
2025-01-06 21:28:55,253 - Epoch: [53][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079129    
2025-01-06 21:28:55,569 - Epoch: [53][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076629    
2025-01-06 21:28:55,878 - Epoch: [53][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074334    
2025-01-06 21:28:56,190 - Epoch: [53][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072283    
2025-01-06 21:28:56,502 - Epoch: [53][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070375    
2025-01-06 21:28:56,826 - Epoch: [53][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068725    
2025-01-06 21:28:57,152 - Epoch: [53][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067220    
2025-01-06 21:28:57,480 - Epoch: [53][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065839    
2025-01-06 21:28:57,789 - Epoch: [53][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064495    
2025-01-06 21:28:58,102 - Epoch: [53][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063266    
2025-01-06 21:28:58,414 - Epoch: [53][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062121    
2025-01-06 21:28:58,730 - Epoch: [53][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061067    
2025-01-06 21:28:59,032 - Epoch: [53][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060039    
2025-01-06 21:28:59,337 - Epoch: [53][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059087    
2025-01-06 21:28:59,659 - Epoch: [53][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058247    
2025-01-06 21:28:59,964 - Epoch: [53][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057407    
2025-01-06 21:29:00,341 - Epoch: [53][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.125000    Top5 12.500000    LR 0.001000    Time 0.056825    
2025-01-06 21:29:00,372 - Epoch: [53][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.022670    Top5 12.846348    LR 0.001000    Time 0.056749    
2025-01-06 21:29:02,406 - --- validate (epoch=53)-----------
2025-01-06 21:29:02,406 - 15217 samples (256 per mini-batch)
2025-01-06 21:29:11,281 - Epoch: [53][   10/   60]    Loss 3.044523    Top1 0.195312    Top5 0.312500    
2025-01-06 21:29:11,532 - Epoch: [53][   20/   60]    Loss 3.044523    Top1 0.234375    Top5 0.410156    
2025-01-06 21:29:11,802 - Epoch: [53][   30/   60]    Loss 3.044523    Top1 0.195312    Top5 0.364583    
2025-01-06 21:29:12,067 - Epoch: [53][   40/   60]    Loss 3.044523    Top1 0.175781    Top5 0.312500    
2025-01-06 21:29:12,331 - Epoch: [53][   50/   60]    Loss 3.044523    Top1 0.171875    Top5 0.296875    
2025-01-06 21:29:12,573 - Epoch: [53][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:29:14,110 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:29:14,110 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:29:14,603 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 53]
2025-01-06 21:29:14,603 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:29:14,637 - 

2025-01-06 21:29:14,637 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:29:23,549 - Epoch: [54][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.890661    
2025-01-06 21:29:23,872 - Epoch: [54][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.461462    
2025-01-06 21:29:24,190 - Epoch: [54][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.318225    
2025-01-06 21:29:24,495 - Epoch: [54][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.246299    
2025-01-06 21:29:24,816 - Epoch: [54][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.203443    
2025-01-06 21:29:25,120 - Epoch: [54][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.174595    
2025-01-06 21:29:25,440 - Epoch: [54][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.154230    
2025-01-06 21:29:25,758 - Epoch: [54][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.138928    
2025-01-06 21:29:26,056 - Epoch: [54][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.126783    
2025-01-06 21:29:26,386 - Epoch: [54][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.117404    
2025-01-06 21:29:26,698 - Epoch: [54][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.109565    
2025-01-06 21:29:27,018 - Epoch: [54][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.103099    
2025-01-06 21:29:27,334 - Epoch: [54][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.097601    
2025-01-06 21:29:27,646 - Epoch: [54][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092861    
2025-01-06 21:29:27,961 - Epoch: [54][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.088765    
2025-01-06 21:29:28,285 - Epoch: [54][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085245    
2025-01-06 21:29:28,618 - Epoch: [54][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082190    
2025-01-06 21:29:28,961 - Epoch: [54][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079530    
2025-01-06 21:29:29,282 - Epoch: [54][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077031    
2025-01-06 21:29:29,619 - Epoch: [54][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074866    
2025-01-06 21:29:29,919 - Epoch: [54][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072720    
2025-01-06 21:29:30,238 - Epoch: [54][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070866    
2025-01-06 21:29:30,551 - Epoch: [54][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069143    
2025-01-06 21:29:30,864 - Epoch: [54][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067565    
2025-01-06 21:29:31,185 - Epoch: [54][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066146    
2025-01-06 21:29:31,513 - Epoch: [54][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064854    
2025-01-06 21:29:31,828 - Epoch: [54][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063618    
2025-01-06 21:29:32,140 - Epoch: [54][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062459    
2025-01-06 21:29:32,439 - Epoch: [54][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061334    
2025-01-06 21:29:32,751 - Epoch: [54][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060330    
2025-01-06 21:29:33,055 - Epoch: [54][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059360    
2025-01-06 21:29:33,362 - Epoch: [54][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058465    
2025-01-06 21:29:33,672 - Epoch: [54][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057633    
2025-01-06 21:29:34,014 - Epoch: [54][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.906250    Top5 14.843750    LR 0.001000    Time 0.056942    
2025-01-06 21:29:34,040 - Epoch: [54][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.274559    Top5 13.853904    LR 0.001000    Time 0.056850    
2025-01-06 21:29:35,751 - --- validate (epoch=54)-----------
2025-01-06 21:29:35,754 - 15217 samples (256 per mini-batch)
2025-01-06 21:29:44,275 - Epoch: [54][   10/   60]    Loss 3.044523    Top1 0.156250    Top5 0.312500    
2025-01-06 21:29:44,528 - Epoch: [54][   20/   60]    Loss 3.044524    Top1 0.253906    Top5 0.390625    
2025-01-06 21:29:44,793 - Epoch: [54][   30/   60]    Loss 3.044524    Top1 0.182292    Top5 0.312500    
2025-01-06 21:29:45,050 - Epoch: [54][   40/   60]    Loss 3.044524    Top1 0.185547    Top5 0.302734    
2025-01-06 21:29:45,303 - Epoch: [54][   50/   60]    Loss 3.044524    Top1 0.195312    Top5 0.312500    
2025-01-06 21:29:45,556 - Epoch: [54][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:29:47,030 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:29:47,041 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:29:47,510 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 54]
2025-01-06 21:29:47,514 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:29:47,543 - 

2025-01-06 21:29:47,543 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:29:56,239 - Epoch: [55][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.869628    
2025-01-06 21:29:56,559 - Epoch: [55][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.449970    
2025-01-06 21:29:56,901 - Epoch: [55][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.311401    
2025-01-06 21:29:57,228 - Epoch: [55][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.241690    
2025-01-06 21:29:57,543 - Epoch: [55][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.199649    
2025-01-06 21:29:57,882 - Epoch: [55][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.172034    
2025-01-06 21:29:58,188 - Epoch: [55][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.151820    
2025-01-06 21:29:58,521 - Epoch: [55][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.137011    
2025-01-06 21:29:58,845 - Epoch: [55][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.125391    
2025-01-06 21:29:59,182 - Epoch: [55][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.116215    
2025-01-06 21:29:59,484 - Epoch: [55][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.108395    
2025-01-06 21:29:59,792 - Epoch: [55][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.101929    
2025-01-06 21:30:00,102 - Epoch: [55][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.096479    
2025-01-06 21:30:00,413 - Epoch: [55][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091804    
2025-01-06 21:30:00,717 - Epoch: [55][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087696    
2025-01-06 21:30:01,036 - Epoch: [55][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084149    
2025-01-06 21:30:01,340 - Epoch: [55][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080984    
2025-01-06 21:30:01,644 - Epoch: [55][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078119    
2025-01-06 21:30:01,960 - Epoch: [55][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075669    
2025-01-06 21:30:02,264 - Epoch: [55][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073404    
2025-01-06 21:30:02,566 - Epoch: [55][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071348    
2025-01-06 21:30:02,880 - Epoch: [55][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069486    
2025-01-06 21:30:03,202 - Epoch: [55][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067864    
2025-01-06 21:30:03,510 - Epoch: [55][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066322    
2025-01-06 21:30:03,822 - Epoch: [55][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064917    
2025-01-06 21:30:04,129 - Epoch: [55][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063599    
2025-01-06 21:30:04,430 - Epoch: [55][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062360    
2025-01-06 21:30:04,762 - Epoch: [55][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061318    
2025-01-06 21:30:05,079 - Epoch: [55][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060296    
2025-01-06 21:30:05,392 - Epoch: [55][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059296    
2025-01-06 21:30:05,733 - Epoch: [55][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058482    
2025-01-06 21:30:06,042 - Epoch: [55][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057619    
2025-01-06 21:30:06,351 - Epoch: [55][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056811    
2025-01-06 21:30:06,686 - Epoch: [55][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.296875    Top5 14.062500    LR 0.001000    Time 0.056125    
2025-01-06 21:30:06,720 - Epoch: [55][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.030227    Top5 12.846348    LR 0.001000    Time 0.056060    
2025-01-06 21:30:08,507 - --- validate (epoch=55)-----------
2025-01-06 21:30:08,507 - 15217 samples (256 per mini-batch)
2025-01-06 21:30:17,206 - Epoch: [55][   10/   60]    Loss 3.044524    Top1 0.117188    Top5 0.195312    
2025-01-06 21:30:17,474 - Epoch: [55][   20/   60]    Loss 3.044523    Top1 0.195312    Top5 0.292969    
2025-01-06 21:30:17,749 - Epoch: [55][   30/   60]    Loss 3.044523    Top1 0.195312    Top5 0.312500    
2025-01-06 21:30:18,000 - Epoch: [55][   40/   60]    Loss 3.044523    Top1 0.195312    Top5 0.322266    
2025-01-06 21:30:18,253 - Epoch: [55][   50/   60]    Loss 3.044524    Top1 0.187500    Top5 0.304688    
2025-01-06 21:30:18,483 - Epoch: [55][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:30:19,987 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:30:19,987 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:30:20,463 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 55]
2025-01-06 21:30:20,473 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:30:20,505 - 

2025-01-06 21:30:20,505 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:30:29,298 - Epoch: [56][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.879356    
2025-01-06 21:30:29,620 - Epoch: [56][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.455771    
2025-01-06 21:30:29,951 - Epoch: [56][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.314869    
2025-01-06 21:30:30,274 - Epoch: [56][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.244226    
2025-01-06 21:30:30,598 - Epoch: [56][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.201868    
2025-01-06 21:30:30,919 - Epoch: [56][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.173567    
2025-01-06 21:30:31,213 - Epoch: [56][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.152980    
2025-01-06 21:30:31,530 - Epoch: [56][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.137818    
2025-01-06 21:30:31,866 - Epoch: [56][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.126222    
2025-01-06 21:30:32,167 - Epoch: [56][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.116616    
2025-01-06 21:30:32,471 - Epoch: [56][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.108777    
2025-01-06 21:30:32,777 - Epoch: [56][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.102258    
2025-01-06 21:30:33,091 - Epoch: [56][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.096807    
2025-01-06 21:30:33,416 - Epoch: [56][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092215    
2025-01-06 21:30:33,720 - Epoch: [56][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.088097    
2025-01-06 21:30:34,033 - Epoch: [56][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084546    
2025-01-06 21:30:34,337 - Epoch: [56][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081359    
2025-01-06 21:30:34,675 - Epoch: [56][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078718    
2025-01-06 21:30:34,971 - Epoch: [56][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076125    
2025-01-06 21:30:35,321 - Epoch: [56][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074069    
2025-01-06 21:30:35,627 - Epoch: [56][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072000    
2025-01-06 21:30:35,949 - Epoch: [56][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070192    
2025-01-06 21:30:36,254 - Epoch: [56][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068464    
2025-01-06 21:30:36,558 - Epoch: [56][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066882    
2025-01-06 21:30:36,887 - Epoch: [56][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065521    
2025-01-06 21:30:37,190 - Epoch: [56][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064166    
2025-01-06 21:30:37,520 - Epoch: [56][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063011    
2025-01-06 21:30:37,838 - Epoch: [56][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061899    
2025-01-06 21:30:38,137 - Epoch: [56][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060794    
2025-01-06 21:30:38,449 - Epoch: [56][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059773    
2025-01-06 21:30:38,773 - Epoch: [56][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058889    
2025-01-06 21:30:39,095 - Epoch: [56][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058058    
2025-01-06 21:30:39,451 - Epoch: [56][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057376    
2025-01-06 21:30:39,802 - Epoch: [56][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.078125    Top5 15.625000    LR 0.001000    Time 0.056720    
2025-01-06 21:30:39,845 - Epoch: [56][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.037783    Top5 16.372796    LR 0.001000    Time 0.056682    
2025-01-06 21:30:41,604 - --- validate (epoch=56)-----------
2025-01-06 21:30:41,606 - 15217 samples (256 per mini-batch)
2025-01-06 21:30:50,597 - Epoch: [56][   10/   60]    Loss 3.044523    Top1 0.234375    Top5 0.390625    
2025-01-06 21:30:50,873 - Epoch: [56][   20/   60]    Loss 3.044523    Top1 0.214844    Top5 0.351563    
2025-01-06 21:30:51,136 - Epoch: [56][   30/   60]    Loss 3.044523    Top1 0.156250    Top5 0.286458    
2025-01-06 21:30:51,399 - Epoch: [56][   40/   60]    Loss 3.044523    Top1 0.214844    Top5 0.332031    
2025-01-06 21:30:51,654 - Epoch: [56][   50/   60]    Loss 3.044523    Top1 0.203125    Top5 0.320312    
2025-01-06 21:30:51,897 - Epoch: [56][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:30:53,419 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:30:53,419 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:30:53,885 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 56]
2025-01-06 21:30:53,885 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:30:53,918 - 

2025-01-06 21:30:53,919 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:31:02,892 - Epoch: [57][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.897252    
2025-01-06 21:31:03,209 - Epoch: [57][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.463685    
2025-01-06 21:31:03,519 - Epoch: [57][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.319459    
2025-01-06 21:31:03,846 - Epoch: [57][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.247767    
2025-01-06 21:31:04,147 - Epoch: [57][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.204237    
2025-01-06 21:31:04,475 - Epoch: [57][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.175493    
2025-01-06 21:31:04,780 - Epoch: [57][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.154784    
2025-01-06 21:31:05,106 - Epoch: [57][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.139511    
2025-01-06 21:31:05,433 - Epoch: [57][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.127644    
2025-01-06 21:31:05,735 - Epoch: [57][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.117900    
2025-01-06 21:31:06,058 - Epoch: [57][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.110025    
2025-01-06 21:31:06,390 - Epoch: [57][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.103622    
2025-01-06 21:31:06,716 - Epoch: [57][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098156    
2025-01-06 21:31:07,046 - Epoch: [57][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093503    
2025-01-06 21:31:07,343 - Epoch: [57][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089251    
2025-01-06 21:31:07,649 - Epoch: [57][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085571    
2025-01-06 21:31:07,985 - Epoch: [57][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082513    
2025-01-06 21:31:08,309 - Epoch: [57][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079731    
2025-01-06 21:31:08,627 - Epoch: [57][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077145    
2025-01-06 21:31:08,929 - Epoch: [57][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074798    
2025-01-06 21:31:09,246 - Epoch: [57][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072747    
2025-01-06 21:31:09,561 - Epoch: [57][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070824    
2025-01-06 21:31:09,880 - Epoch: [57][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069134    
2025-01-06 21:31:10,189 - Epoch: [57][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067542    
2025-01-06 21:31:10,506 - Epoch: [57][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066101    
2025-01-06 21:31:10,819 - Epoch: [57][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064762    
2025-01-06 21:31:11,123 - Epoch: [57][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063491    
2025-01-06 21:31:11,449 - Epoch: [57][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062383    
2025-01-06 21:31:11,762 - Epoch: [57][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061312    
2025-01-06 21:31:12,078 - Epoch: [57][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060321    
2025-01-06 21:31:12,396 - Epoch: [57][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059401    
2025-01-06 21:31:12,718 - Epoch: [57][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058552    
2025-01-06 21:31:13,012 - Epoch: [57][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057670    
2025-01-06 21:31:13,389 - Epoch: [57][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.078125    Top5 12.109375    LR 0.001000    Time 0.057082    
2025-01-06 21:31:13,425 - Epoch: [57][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.534005    Top5 11.586902    LR 0.001000    Time 0.057021    
2025-01-06 21:31:15,020 - --- validate (epoch=57)-----------
2025-01-06 21:31:15,020 - 15217 samples (256 per mini-batch)
2025-01-06 21:31:23,972 - Epoch: [57][   10/   60]    Loss 3.044524    Top1 0.156250    Top5 0.234375    
2025-01-06 21:31:24,220 - Epoch: [57][   20/   60]    Loss 3.044524    Top1 0.175781    Top5 0.273437    
2025-01-06 21:31:24,483 - Epoch: [57][   30/   60]    Loss 3.044524    Top1 0.208333    Top5 0.325521    
2025-01-06 21:31:24,736 - Epoch: [57][   40/   60]    Loss 3.044524    Top1 0.214844    Top5 0.371094    
2025-01-06 21:31:24,992 - Epoch: [57][   50/   60]    Loss 3.044524    Top1 0.195312    Top5 0.328125    
2025-01-06 21:31:25,232 - Epoch: [57][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:31:26,785 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:31:26,789 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:31:27,237 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 57]
2025-01-06 21:31:27,237 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:31:27,278 - 

2025-01-06 21:31:27,278 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:31:36,090 - Epoch: [58][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.881016    
2025-01-06 21:31:36,412 - Epoch: [58][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.456622    
2025-01-06 21:31:36,736 - Epoch: [58][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.315212    
2025-01-06 21:31:37,059 - Epoch: [58][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.244475    
2025-01-06 21:31:37,374 - Epoch: [58][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.201881    
2025-01-06 21:31:37,690 - Epoch: [58][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.173502    
2025-01-06 21:31:38,008 - Epoch: [58][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.153264    
2025-01-06 21:31:38,312 - Epoch: [58][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.137910    
2025-01-06 21:31:38,626 - Epoch: [58][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.125954    
2025-01-06 21:31:38,932 - Epoch: [58][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.116421    
2025-01-06 21:31:39,242 - Epoch: [58][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.108657    
2025-01-06 21:31:39,559 - Epoch: [58][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.102243    
2025-01-06 21:31:39,867 - Epoch: [58][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.096746    
2025-01-06 21:31:40,174 - Epoch: [58][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092021    
2025-01-06 21:31:40,492 - Epoch: [58][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.088005    
2025-01-06 21:31:40,796 - Epoch: [58][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084406    
2025-01-06 21:31:41,111 - Epoch: [58][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081293    
2025-01-06 21:31:41,413 - Epoch: [58][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078455    
2025-01-06 21:31:41,725 - Epoch: [58][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075916    
2025-01-06 21:31:42,028 - Epoch: [58][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073633    
2025-01-06 21:31:42,360 - Epoch: [58][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071712    
2025-01-06 21:31:42,668 - Epoch: [58][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069827    
2025-01-06 21:31:42,991 - Epoch: [58][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068196    
2025-01-06 21:31:43,327 - Epoch: [58][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066755    
2025-01-06 21:31:43,651 - Epoch: [58][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065342    
2025-01-06 21:31:43,975 - Epoch: [58][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064072    
2025-01-06 21:31:44,288 - Epoch: [58][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062859    
2025-01-06 21:31:44,609 - Epoch: [58][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061761    
2025-01-06 21:31:44,913 - Epoch: [58][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060679    
2025-01-06 21:31:45,227 - Epoch: [58][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059705    
2025-01-06 21:31:45,550 - Epoch: [58][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058821    
2025-01-06 21:31:45,859 - Epoch: [58][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057949    
2025-01-06 21:31:46,172 - Epoch: [58][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057139    
2025-01-06 21:31:46,526 - Epoch: [58][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 7.421875    Top5 14.843750    LR 0.001000    Time 0.056500    
2025-01-06 21:31:46,573 - Epoch: [58][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.541562    Top5 13.350126    LR 0.001000    Time 0.056451    
2025-01-06 21:31:48,385 - --- validate (epoch=58)-----------
2025-01-06 21:31:48,395 - 15217 samples (256 per mini-batch)
2025-01-06 21:31:56,986 - Epoch: [58][   10/   60]    Loss 3.044524    Top1 0.078125    Top5 0.117188    
2025-01-06 21:31:57,249 - Epoch: [58][   20/   60]    Loss 3.044523    Top1 0.097656    Top5 0.234375    
2025-01-06 21:31:57,508 - Epoch: [58][   30/   60]    Loss 3.044523    Top1 0.143229    Top5 0.273437    
2025-01-06 21:31:57,773 - Epoch: [58][   40/   60]    Loss 3.044523    Top1 0.175781    Top5 0.302734    
2025-01-06 21:31:58,022 - Epoch: [58][   50/   60]    Loss 3.044523    Top1 0.179688    Top5 0.296875    
2025-01-06 21:31:58,263 - Epoch: [58][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:31:59,777 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:31:59,787 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:32:00,461 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 58]
2025-01-06 21:32:00,461 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:32:00,494 - 

2025-01-06 21:32:00,495 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:32:09,486 - Epoch: [59][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.899013    
2025-01-06 21:32:09,828 - Epoch: [59][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.466617    
2025-01-06 21:32:10,146 - Epoch: [59][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.321690    
2025-01-06 21:32:10,460 - Epoch: [59][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.249118    
2025-01-06 21:32:10,795 - Epoch: [59][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.205989    
2025-01-06 21:32:11,101 - Epoch: [59][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.176757    
2025-01-06 21:32:11,415 - Epoch: [59][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.155992    
2025-01-06 21:32:11,734 - Epoch: [59][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.140477    
2025-01-06 21:32:12,052 - Epoch: [59][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.128409    
2025-01-06 21:32:12,358 - Epoch: [59][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.118621    
2025-01-06 21:32:12,663 - Epoch: [59][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.110610    
2025-01-06 21:32:12,991 - Epoch: [59][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.104129    
2025-01-06 21:32:13,314 - Epoch: [59][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098602    
2025-01-06 21:32:13,626 - Epoch: [59][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093790    
2025-01-06 21:32:13,937 - Epoch: [59][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089608    
2025-01-06 21:32:14,250 - Epoch: [59][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085962    
2025-01-06 21:32:14,564 - Epoch: [59][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082754    
2025-01-06 21:32:14,878 - Epoch: [59][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079903    
2025-01-06 21:32:15,184 - Epoch: [59][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077309    
2025-01-06 21:32:15,492 - Epoch: [59][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074981    
2025-01-06 21:32:15,807 - Epoch: [59][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072910    
2025-01-06 21:32:16,135 - Epoch: [59][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071086    
2025-01-06 21:32:16,442 - Epoch: [59][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069331    
2025-01-06 21:32:16,769 - Epoch: [59][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067800    
2025-01-06 21:32:17,075 - Epoch: [59][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066313    
2025-01-06 21:32:17,397 - Epoch: [59][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064994    
2025-01-06 21:32:17,744 - Epoch: [59][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063873    
2025-01-06 21:32:18,056 - Epoch: [59][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062704    
2025-01-06 21:32:18,359 - Epoch: [59][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061587    
2025-01-06 21:32:18,675 - Epoch: [59][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060588    
2025-01-06 21:32:18,981 - Epoch: [59][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059621    
2025-01-06 21:32:19,298 - Epoch: [59][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058747    
2025-01-06 21:32:19,619 - Epoch: [59][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057937    
2025-01-06 21:32:19,967 - Epoch: [59][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.687500    Top5 13.671875    LR 0.001000    Time 0.057258    
2025-01-06 21:32:19,992 - Epoch: [59][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.030227    Top5 13.602015    LR 0.001000    Time 0.057163    
2025-01-06 21:32:21,695 - --- validate (epoch=59)-----------
2025-01-06 21:32:21,695 - 15217 samples (256 per mini-batch)
2025-01-06 21:32:30,288 - Epoch: [59][   10/   60]    Loss 3.044524    Top1 0.117188    Top5 0.117188    
2025-01-06 21:32:30,554 - Epoch: [59][   20/   60]    Loss 3.044524    Top1 0.136719    Top5 0.175781    
2025-01-06 21:32:30,826 - Epoch: [59][   30/   60]    Loss 3.044523    Top1 0.195312    Top5 0.273437    
2025-01-06 21:32:31,089 - Epoch: [59][   40/   60]    Loss 3.044524    Top1 0.195312    Top5 0.292969    
2025-01-06 21:32:31,352 - Epoch: [59][   50/   60]    Loss 3.044524    Top1 0.195312    Top5 0.304688    
2025-01-06 21:32:31,595 - Epoch: [59][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:32:33,092 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:32:33,092 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:32:33,552 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 59]
2025-01-06 21:32:33,552 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:32:33,587 - 

2025-01-06 21:32:33,588 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:32:42,265 - Epoch: [60][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.867594    
2025-01-06 21:32:42,578 - Epoch: [60][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.449443    
2025-01-06 21:32:42,907 - Epoch: [60][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.310582    
2025-01-06 21:32:43,221 - Epoch: [60][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.240792    
2025-01-06 21:32:43,532 - Epoch: [60][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.198860    
2025-01-06 21:32:43,838 - Epoch: [60][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.170814    
2025-01-06 21:32:44,145 - Epoch: [60][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.150805    
2025-01-06 21:32:44,457 - Epoch: [60][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.135847    
2025-01-06 21:32:44,766 - Epoch: [60][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.124189    
2025-01-06 21:32:45,099 - Epoch: [60][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.114992    
2025-01-06 21:32:45,422 - Epoch: [60][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.107476    
2025-01-06 21:32:45,757 - Epoch: [60][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.101312    
2025-01-06 21:32:46,057 - Epoch: [60][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095825    
2025-01-06 21:32:46,372 - Epoch: [60][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091230    
2025-01-06 21:32:46,689 - Epoch: [60][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087263    
2025-01-06 21:32:46,995 - Epoch: [60][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083721    
2025-01-06 21:32:47,295 - Epoch: [60][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080501    
2025-01-06 21:32:47,611 - Epoch: [60][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077785    
2025-01-06 21:32:47,904 - Epoch: [60][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075234    
2025-01-06 21:32:48,210 - Epoch: [60][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072997    
2025-01-06 21:32:48,522 - Epoch: [60][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071006    
2025-01-06 21:32:48,834 - Epoch: [60][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069198    
2025-01-06 21:32:49,141 - Epoch: [60][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067524    
2025-01-06 21:32:49,445 - Epoch: [60][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065976    
2025-01-06 21:32:49,768 - Epoch: [60][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064632    
2025-01-06 21:32:50,078 - Epoch: [60][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063335    
2025-01-06 21:32:50,402 - Epoch: [60][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062192    
2025-01-06 21:32:50,708 - Epoch: [60][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061064    
2025-01-06 21:32:51,019 - Epoch: [60][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060029    
2025-01-06 21:32:51,329 - Epoch: [60][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059061    
2025-01-06 21:32:51,648 - Epoch: [60][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058185    
2025-01-06 21:32:51,953 - Epoch: [60][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057319    
2025-01-06 21:32:52,281 - Epoch: [60][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056577    
2025-01-06 21:32:52,634 - Epoch: [60][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.515625    Top5 12.109375    LR 0.001000    Time 0.055951    
2025-01-06 21:32:52,665 - Epoch: [60][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.274559    Top5 11.335013    LR 0.001000    Time 0.055877    
2025-01-06 21:32:54,446 - --- validate (epoch=60)-----------
2025-01-06 21:32:54,446 - 15217 samples (256 per mini-batch)
2025-01-06 21:33:02,988 - Epoch: [60][   10/   60]    Loss 3.044524    Top1 0.195312    Top5 0.273437    
2025-01-06 21:33:03,240 - Epoch: [60][   20/   60]    Loss 3.044524    Top1 0.195312    Top5 0.312500    
2025-01-06 21:33:03,516 - Epoch: [60][   30/   60]    Loss 3.044524    Top1 0.182292    Top5 0.286458    
2025-01-06 21:33:03,799 - Epoch: [60][   40/   60]    Loss 3.044524    Top1 0.224609    Top5 0.371094    
2025-01-06 21:33:04,049 - Epoch: [60][   50/   60]    Loss 3.044524    Top1 0.195312    Top5 0.328125    
2025-01-06 21:33:04,301 - Epoch: [60][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:33:05,805 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:33:05,805 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:33:06,270 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 60]
2025-01-06 21:33:06,273 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:33:06,303 - 

2025-01-06 21:33:06,304 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:33:15,047 - Epoch: [61][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.874347    
2025-01-06 21:33:15,359 - Epoch: [61][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.452782    
2025-01-06 21:33:15,687 - Epoch: [61][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.312793    
2025-01-06 21:33:16,004 - Epoch: [61][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.242502    
2025-01-06 21:33:16,340 - Epoch: [61][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.200729    
2025-01-06 21:33:16,673 - Epoch: [61][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.172780    
2025-01-06 21:33:16,991 - Epoch: [61][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.152639    
2025-01-06 21:33:17,308 - Epoch: [61][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.137522    
2025-01-06 21:33:17,621 - Epoch: [61][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.125718    
2025-01-06 21:33:17,935 - Epoch: [61][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.116287    
2025-01-06 21:33:18,244 - Epoch: [61][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.108532    
2025-01-06 21:33:18,543 - Epoch: [61][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.101973    
2025-01-06 21:33:18,871 - Epoch: [61][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.096577    
2025-01-06 21:33:19,192 - Epoch: [61][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091974    
2025-01-06 21:33:19,499 - Epoch: [61][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087887    
2025-01-06 21:33:19,814 - Epoch: [61][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084357    
2025-01-06 21:33:20,129 - Epoch: [61][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081248    
2025-01-06 21:33:20,433 - Epoch: [61][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078423    
2025-01-06 21:33:20,756 - Epoch: [61][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075994    
2025-01-06 21:33:21,060 - Epoch: [61][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073715    
2025-01-06 21:33:21,392 - Epoch: [61][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071783    
2025-01-06 21:33:21,717 - Epoch: [61][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070000    
2025-01-06 21:33:22,039 - Epoch: [61][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068355    
2025-01-06 21:33:22,376 - Epoch: [61][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066914    
2025-01-06 21:33:22,691 - Epoch: [61][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065496    
2025-01-06 21:33:23,006 - Epoch: [61][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064187    
2025-01-06 21:33:23,311 - Epoch: [61][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062939    
2025-01-06 21:33:23,614 - Epoch: [61][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061773    
2025-01-06 21:33:23,949 - Epoch: [61][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060764    
2025-01-06 21:33:24,267 - Epoch: [61][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059799    
2025-01-06 21:33:24,584 - Epoch: [61][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058891    
2025-01-06 21:33:24,890 - Epoch: [61][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058008    
2025-01-06 21:33:25,202 - Epoch: [61][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057196    
2025-01-06 21:33:25,528 - Epoch: [61][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.687500    Top5 13.671875    LR 0.001000    Time 0.056473    
2025-01-06 21:33:25,565 - Epoch: [61][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.534005    Top5 14.609572    LR 0.001000    Time 0.056385    
2025-01-06 21:33:27,281 - --- validate (epoch=61)-----------
2025-01-06 21:33:27,281 - 15217 samples (256 per mini-batch)
2025-01-06 21:33:35,842 - Epoch: [61][   10/   60]    Loss 3.044524    Top1 0.156250    Top5 0.195312    
2025-01-06 21:33:36,103 - Epoch: [61][   20/   60]    Loss 3.044524    Top1 0.175781    Top5 0.312500    
2025-01-06 21:33:36,357 - Epoch: [61][   30/   60]    Loss 3.044524    Top1 0.169271    Top5 0.312500    
2025-01-06 21:33:36,613 - Epoch: [61][   40/   60]    Loss 3.044524    Top1 0.185547    Top5 0.302734    
2025-01-06 21:33:36,859 - Epoch: [61][   50/   60]    Loss 3.044524    Top1 0.195312    Top5 0.304688    
2025-01-06 21:33:37,099 - Epoch: [61][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:33:38,579 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:33:38,580 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:33:39,059 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 61]
2025-01-06 21:33:39,059 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:33:39,091 - 

2025-01-06 21:33:39,092 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:33:48,045 - Epoch: [62][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.895322    
2025-01-06 21:33:48,375 - Epoch: [62][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.464170    
2025-01-06 21:33:48,703 - Epoch: [62][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.320297    
2025-01-06 21:33:49,005 - Epoch: [62][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.247740    
2025-01-06 21:33:49,318 - Epoch: [62][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.204455    
2025-01-06 21:33:49,622 - Epoch: [62][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.175401    
2025-01-06 21:33:49,949 - Epoch: [62][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.155021    
2025-01-06 21:33:50,252 - Epoch: [62][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.139424    
2025-01-06 21:33:50,557 - Epoch: [62][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.127310    
2025-01-06 21:33:50,867 - Epoch: [62][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.117683    
2025-01-06 21:33:51,175 - Epoch: [62][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.109786    
2025-01-06 21:33:51,479 - Epoch: [62][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.103170    
2025-01-06 21:33:51,780 - Epoch: [62][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.097533    
2025-01-06 21:33:52,074 - Epoch: [62][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092670    
2025-01-06 21:33:52,385 - Epoch: [62][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.088495    
2025-01-06 21:33:52,695 - Epoch: [62][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084902    
2025-01-06 21:33:52,991 - Epoch: [62][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081654    
2025-01-06 21:33:53,304 - Epoch: [62][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078855    
2025-01-06 21:33:53,611 - Epoch: [62][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076319    
2025-01-06 21:33:53,935 - Epoch: [62][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074099    
2025-01-06 21:33:54,244 - Epoch: [62][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071997    
2025-01-06 21:33:54,562 - Epoch: [62][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070170    
2025-01-06 21:33:54,862 - Epoch: [62][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068421    
2025-01-06 21:33:55,179 - Epoch: [62][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066892    
2025-01-06 21:33:55,487 - Epoch: [62][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065447    
2025-01-06 21:33:55,797 - Epoch: [62][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064125    
2025-01-06 21:33:56,112 - Epoch: [62][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062917    
2025-01-06 21:33:56,412 - Epoch: [62][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061740    
2025-01-06 21:33:56,751 - Epoch: [62][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060778    
2025-01-06 21:33:57,052 - Epoch: [62][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059758    
2025-01-06 21:33:57,360 - Epoch: [62][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058817    
2025-01-06 21:33:57,688 - Epoch: [62][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058004    
2025-01-06 21:33:58,006 - Epoch: [62][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057210    
2025-01-06 21:33:58,340 - Epoch: [62][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.078125    Top5 11.718750    LR 0.001000    Time 0.056508    
2025-01-06 21:33:58,387 - Epoch: [62][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.534005    Top5 11.335013    LR 0.001000    Time 0.056481    
2025-01-06 21:34:00,262 - --- validate (epoch=62)-----------
2025-01-06 21:34:00,262 - 15217 samples (256 per mini-batch)
2025-01-06 21:34:09,369 - Epoch: [62][   10/   60]    Loss 3.044523    Top1 0.156250    Top5 0.273437    
2025-01-06 21:34:09,621 - Epoch: [62][   20/   60]    Loss 3.044523    Top1 0.156250    Top5 0.234375    
2025-01-06 21:34:09,877 - Epoch: [62][   30/   60]    Loss 3.044523    Top1 0.182292    Top5 0.260417    
2025-01-06 21:34:10,138 - Epoch: [62][   40/   60]    Loss 3.044523    Top1 0.175781    Top5 0.263672    
2025-01-06 21:34:10,402 - Epoch: [62][   50/   60]    Loss 3.044523    Top1 0.164062    Top5 0.265625    
2025-01-06 21:34:10,656 - Epoch: [62][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:34:12,185 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:34:12,185 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:34:12,635 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 62]
2025-01-06 21:34:12,635 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:34:12,670 - 

2025-01-06 21:34:12,670 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:34:21,387 - Epoch: [63][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.871339    
2025-01-06 21:34:21,717 - Epoch: [63][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.452168    
2025-01-06 21:34:22,044 - Epoch: [63][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.312371    
2025-01-06 21:34:22,368 - Epoch: [63][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.242370    
2025-01-06 21:34:22,677 - Epoch: [63][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.200082    
2025-01-06 21:34:22,986 - Epoch: [63][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.171880    
2025-01-06 21:34:23,296 - Epoch: [63][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.151760    
2025-01-06 21:34:23,608 - Epoch: [63][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.136686    
2025-01-06 21:34:23,921 - Epoch: [63][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.124976    
2025-01-06 21:34:24,229 - Epoch: [63][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.115562    
2025-01-06 21:34:24,544 - Epoch: [63][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.107918    
2025-01-06 21:34:24,858 - Epoch: [63][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.101523    
2025-01-06 21:34:25,174 - Epoch: [63][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.096142    
2025-01-06 21:34:25,502 - Epoch: [63][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091622    
2025-01-06 21:34:25,835 - Epoch: [63][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087730    
2025-01-06 21:34:26,143 - Epoch: [63][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084174    
2025-01-06 21:34:26,445 - Epoch: [63][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080998    
2025-01-06 21:34:26,757 - Epoch: [63][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078232    
2025-01-06 21:34:27,073 - Epoch: [63][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075779    
2025-01-06 21:34:27,376 - Epoch: [63][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073506    
2025-01-06 21:34:27,673 - Epoch: [63][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071409    
2025-01-06 21:34:28,003 - Epoch: [63][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069665    
2025-01-06 21:34:28,308 - Epoch: [63][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067960    
2025-01-06 21:34:28,622 - Epoch: [63][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066435    
2025-01-06 21:34:28,934 - Epoch: [63][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065029    
2025-01-06 21:34:29,240 - Epoch: [63][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063698    
2025-01-06 21:34:29,546 - Epoch: [63][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062472    
2025-01-06 21:34:29,864 - Epoch: [63][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061373    
2025-01-06 21:34:30,182 - Epoch: [63][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060356    
2025-01-06 21:34:30,485 - Epoch: [63][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059354    
2025-01-06 21:34:30,804 - Epoch: [63][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058466    
2025-01-06 21:34:31,099 - Epoch: [63][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057563    
2025-01-06 21:34:31,409 - Epoch: [63][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056757    
2025-01-06 21:34:31,748 - Epoch: [63][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 2.343750    Top5 12.500000    LR 0.001000    Time 0.056086    
2025-01-06 21:34:31,782 - Epoch: [63][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 2.518892    Top5 13.098237    LR 0.001000    Time 0.056019    
2025-01-06 21:34:33,412 - --- validate (epoch=63)-----------
2025-01-06 21:34:33,412 - 15217 samples (256 per mini-batch)
2025-01-06 21:34:42,581 - Epoch: [63][   10/   60]    Loss 3.044523    Top1 0.156250    Top5 0.234375    
2025-01-06 21:34:42,852 - Epoch: [63][   20/   60]    Loss 3.044524    Top1 0.214844    Top5 0.273437    
2025-01-06 21:34:43,108 - Epoch: [63][   30/   60]    Loss 3.044523    Top1 0.208333    Top5 0.286458    
2025-01-06 21:34:43,379 - Epoch: [63][   40/   60]    Loss 3.044524    Top1 0.185547    Top5 0.283203    
2025-01-06 21:34:43,629 - Epoch: [63][   50/   60]    Loss 3.044524    Top1 0.179688    Top5 0.289063    
2025-01-06 21:34:43,881 - Epoch: [63][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:34:45,345 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:34:45,345 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:34:45,814 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 63]
2025-01-06 21:34:45,814 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:34:45,867 - 

2025-01-06 21:34:45,868 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:34:54,403 - Epoch: [64][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.853470    
2025-01-06 21:34:54,714 - Epoch: [64][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.442262    
2025-01-06 21:34:55,025 - Epoch: [64][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.305221    
2025-01-06 21:34:55,339 - Epoch: [64][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.236767    
2025-01-06 21:34:55,646 - Epoch: [64][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.195535    
2025-01-06 21:34:55,965 - Epoch: [64][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.168269    
2025-01-06 21:34:56,271 - Epoch: [64][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.148607    
2025-01-06 21:34:56,584 - Epoch: [64][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.133945    
2025-01-06 21:34:56,896 - Epoch: [64][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.122503    
2025-01-06 21:34:57,213 - Epoch: [64][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.113422    
2025-01-06 21:34:57,546 - Epoch: [64][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.106136    
2025-01-06 21:34:57,850 - Epoch: [64][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.099824    
2025-01-06 21:34:58,170 - Epoch: [64][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094532    
2025-01-06 21:34:58,495 - Epoch: [64][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090101    
2025-01-06 21:34:58,812 - Epoch: [64][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086200    
2025-01-06 21:34:59,125 - Epoch: [64][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082770    
2025-01-06 21:34:59,449 - Epoch: [64][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079803    
2025-01-06 21:34:59,761 - Epoch: [64][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077106    
2025-01-06 21:35:00,076 - Epoch: [64][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074698    
2025-01-06 21:35:00,391 - Epoch: [64][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072538    
2025-01-06 21:35:00,699 - Epoch: [64][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070504    
2025-01-06 21:35:01,019 - Epoch: [64][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068754    
2025-01-06 21:35:01,324 - Epoch: [64][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067088    
2025-01-06 21:35:01,649 - Epoch: [64][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065647    
2025-01-06 21:35:01,973 - Epoch: [64][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064319    
2025-01-06 21:35:02,283 - Epoch: [64][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063037    
2025-01-06 21:35:02,608 - Epoch: [64][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061905    
2025-01-06 21:35:02,924 - Epoch: [64][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060822    
2025-01-06 21:35:03,236 - Epoch: [64][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059799    
2025-01-06 21:35:03,552 - Epoch: [64][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058860    
2025-01-06 21:35:03,880 - Epoch: [64][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058010    
2025-01-06 21:35:04,206 - Epoch: [64][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057218    
2025-01-06 21:35:04,528 - Epoch: [64][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056460    
2025-01-06 21:35:04,870 - Epoch: [64][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.906250    Top5 14.453125    LR 0.001000    Time 0.055798    
2025-01-06 21:35:04,898 - Epoch: [64][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.785894    Top5 13.853904    LR 0.001000    Time 0.055718    
2025-01-06 21:35:06,872 - --- validate (epoch=64)-----------
2025-01-06 21:35:06,872 - 15217 samples (256 per mini-batch)
2025-01-06 21:35:15,562 - Epoch: [64][   10/   60]    Loss 3.044523    Top1 0.117188    Top5 0.273437    
2025-01-06 21:35:15,819 - Epoch: [64][   20/   60]    Loss 3.044523    Top1 0.136719    Top5 0.292969    
2025-01-06 21:35:16,073 - Epoch: [64][   30/   60]    Loss 3.044523    Top1 0.143229    Top5 0.312500    
2025-01-06 21:35:16,334 - Epoch: [64][   40/   60]    Loss 3.044523    Top1 0.146484    Top5 0.292969    
2025-01-06 21:35:16,592 - Epoch: [64][   50/   60]    Loss 3.044523    Top1 0.148437    Top5 0.281250    
2025-01-06 21:35:16,853 - Epoch: [64][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:35:18,311 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:35:18,311 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:35:18,784 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 64]
2025-01-06 21:35:18,784 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:35:18,823 - 

2025-01-06 21:35:18,824 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:35:27,614 - Epoch: [65][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.878891    
2025-01-06 21:35:27,926 - Epoch: [65][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.455029    
2025-01-06 21:35:28,245 - Epoch: [65][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.314008    
2025-01-06 21:35:28,559 - Epoch: [65][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.243337    
2025-01-06 21:35:28,872 - Epoch: [65][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.200945    
2025-01-06 21:35:29,198 - Epoch: [65][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.172875    
2025-01-06 21:35:29,523 - Epoch: [65][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.152827    
2025-01-06 21:35:29,841 - Epoch: [65][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.137699    
2025-01-06 21:35:30,146 - Epoch: [65][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.125792    
2025-01-06 21:35:30,473 - Epoch: [65][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.116477    
2025-01-06 21:35:30,776 - Epoch: [65][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.108647    
2025-01-06 21:35:31,093 - Epoch: [65][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.102230    
2025-01-06 21:35:31,420 - Epoch: [65][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.096880    
2025-01-06 21:35:31,724 - Epoch: [65][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092121    
2025-01-06 21:35:32,039 - Epoch: [65][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.088065    
2025-01-06 21:35:32,345 - Epoch: [65][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084476    
2025-01-06 21:35:32,669 - Epoch: [65][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081409    
2025-01-06 21:35:32,974 - Epoch: [65][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078582    
2025-01-06 21:35:33,292 - Epoch: [65][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076121    
2025-01-06 21:35:33,606 - Epoch: [65][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073884    
2025-01-06 21:35:33,920 - Epoch: [65][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071860    
2025-01-06 21:35:34,221 - Epoch: [65][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069961    
2025-01-06 21:35:34,529 - Epoch: [65][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068262    
2025-01-06 21:35:34,865 - Epoch: [65][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066815    
2025-01-06 21:35:35,173 - Epoch: [65][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065367    
2025-01-06 21:35:35,494 - Epoch: [65][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064087    
2025-01-06 21:35:35,798 - Epoch: [65][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062833    
2025-01-06 21:35:36,123 - Epoch: [65][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061751    
2025-01-06 21:35:36,439 - Epoch: [65][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060708    
2025-01-06 21:35:36,762 - Epoch: [65][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059758    
2025-01-06 21:35:37,071 - Epoch: [65][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058827    
2025-01-06 21:35:37,382 - Epoch: [65][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057961    
2025-01-06 21:35:37,685 - Epoch: [65][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057124    
2025-01-06 21:35:38,037 - Epoch: [65][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.687500    Top5 11.718750    LR 0.001000    Time 0.056479    
2025-01-06 21:35:38,069 - Epoch: [65][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.289673    Top5 12.846348    LR 0.001000    Time 0.056405    
2025-01-06 21:35:40,173 - --- validate (epoch=65)-----------
2025-01-06 21:35:40,173 - 15217 samples (256 per mini-batch)
2025-01-06 21:35:48,738 - Epoch: [65][   10/   60]    Loss 3.044523    Top1 0.078125    Top5 0.156250    
2025-01-06 21:35:49,006 - Epoch: [65][   20/   60]    Loss 3.044524    Top1 0.097656    Top5 0.195312    
2025-01-06 21:35:49,279 - Epoch: [65][   30/   60]    Loss 3.044523    Top1 0.130208    Top5 0.208333    
2025-01-06 21:35:49,536 - Epoch: [65][   40/   60]    Loss 3.044523    Top1 0.195312    Top5 0.302734    
2025-01-06 21:35:49,797 - Epoch: [65][   50/   60]    Loss 3.044523    Top1 0.195312    Top5 0.320312    
2025-01-06 21:35:50,040 - Epoch: [65][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:35:51,577 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:35:51,579 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:35:52,404 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 65]
2025-01-06 21:35:52,404 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:35:52,445 - 

2025-01-06 21:35:52,445 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:36:01,230 - Epoch: [66][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.878371    
2025-01-06 21:36:01,546 - Epoch: [66][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.454971    
2025-01-06 21:36:01,851 - Epoch: [66][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.313478    
2025-01-06 21:36:02,168 - Epoch: [66][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.243028    
2025-01-06 21:36:02,496 - Epoch: [66][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.200982    
2025-01-06 21:36:02,831 - Epoch: [66][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.173076    
2025-01-06 21:36:03,155 - Epoch: [66][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.152970    
2025-01-06 21:36:03,459 - Epoch: [66][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.137649    
2025-01-06 21:36:03,760 - Epoch: [66][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.125698    
2025-01-06 21:36:04,064 - Epoch: [66][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.116166    
2025-01-06 21:36:04,371 - Epoch: [66][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.108396    
2025-01-06 21:36:04,675 - Epoch: [66][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.101894    
2025-01-06 21:36:04,977 - Epoch: [66][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.096382    
2025-01-06 21:36:05,322 - Epoch: [66][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091960    
2025-01-06 21:36:05,627 - Epoch: [66][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087861    
2025-01-06 21:36:05,941 - Epoch: [66][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084335    
2025-01-06 21:36:06,265 - Epoch: [66][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081276    
2025-01-06 21:36:06,570 - Epoch: [66][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078455    
2025-01-06 21:36:06,894 - Epoch: [66][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075981    
2025-01-06 21:36:07,208 - Epoch: [66][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073748    
2025-01-06 21:36:07,521 - Epoch: [66][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071729    
2025-01-06 21:36:07,815 - Epoch: [66][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069806    
2025-01-06 21:36:08,160 - Epoch: [66][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068227    
2025-01-06 21:36:08,466 - Epoch: [66][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066659    
2025-01-06 21:36:08,783 - Epoch: [66][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065259    
2025-01-06 21:36:09,101 - Epoch: [66][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063973    
2025-01-06 21:36:09,404 - Epoch: [66][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062723    
2025-01-06 21:36:09,709 - Epoch: [66][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061571    
2025-01-06 21:36:10,022 - Epoch: [66][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060493    
2025-01-06 21:36:10,329 - Epoch: [66][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059498    
2025-01-06 21:36:10,657 - Epoch: [66][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058636    
2025-01-06 21:36:10,973 - Epoch: [66][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057793    
2025-01-06 21:36:11,289 - Epoch: [66][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056998    
2025-01-06 21:36:11,668 - Epoch: [66][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 2.343750    Top5 10.546875    LR 0.001000    Time 0.056438    
2025-01-06 21:36:11,699 - Epoch: [66][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.022670    Top5 10.075567    LR 0.001000    Time 0.056359    
2025-01-06 21:36:13,708 - --- validate (epoch=66)-----------
2025-01-06 21:36:13,708 - 15217 samples (256 per mini-batch)
2025-01-06 21:36:22,530 - Epoch: [66][   10/   60]    Loss 3.044524    Top1 0.273437    Top5 0.429687    
2025-01-06 21:36:22,797 - Epoch: [66][   20/   60]    Loss 3.044524    Top1 0.214844    Top5 0.351563    
2025-01-06 21:36:23,057 - Epoch: [66][   30/   60]    Loss 3.044524    Top1 0.195312    Top5 0.312500    
2025-01-06 21:36:23,310 - Epoch: [66][   40/   60]    Loss 3.044524    Top1 0.195312    Top5 0.292969    
2025-01-06 21:36:23,573 - Epoch: [66][   50/   60]    Loss 3.044524    Top1 0.195312    Top5 0.312500    
2025-01-06 21:36:23,848 - Epoch: [66][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:36:25,401 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:36:25,411 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:36:26,216 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 66]
2025-01-06 21:36:26,221 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:36:26,253 - 

2025-01-06 21:36:26,254 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:36:34,805 - Epoch: [67][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.854989    
2025-01-06 21:36:35,156 - Epoch: [67][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.444809    
2025-01-06 21:36:35,483 - Epoch: [67][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.307432    
2025-01-06 21:36:35,794 - Epoch: [67][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.238348    
2025-01-06 21:36:36,099 - Epoch: [67][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.196784    
2025-01-06 21:36:36,407 - Epoch: [67][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.169118    
2025-01-06 21:36:36,728 - Epoch: [67][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.149543    
2025-01-06 21:36:37,039 - Epoch: [67][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.134745    
2025-01-06 21:36:37,354 - Epoch: [67][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.123272    
2025-01-06 21:36:37,658 - Epoch: [67][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.113965    
2025-01-06 21:36:37,977 - Epoch: [67][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.106498    
2025-01-06 21:36:38,291 - Epoch: [67][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100246    
2025-01-06 21:36:38,596 - Epoch: [67][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094881    
2025-01-06 21:36:38,919 - Epoch: [67][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090394    
2025-01-06 21:36:39,233 - Epoch: [67][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086434    
2025-01-06 21:36:39,551 - Epoch: [67][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083016    
2025-01-06 21:36:39,860 - Epoch: [67][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079926    
2025-01-06 21:36:40,173 - Epoch: [67][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077223    
2025-01-06 21:36:40,483 - Epoch: [67][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074775    
2025-01-06 21:36:40,796 - Epoch: [67][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072604    
2025-01-06 21:36:41,131 - Epoch: [67][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070730    
2025-01-06 21:36:41,433 - Epoch: [67][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068892    
2025-01-06 21:36:41,740 - Epoch: [67][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067228    
2025-01-06 21:36:42,062 - Epoch: [67][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065770    
2025-01-06 21:36:42,377 - Epoch: [67][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064393    
2025-01-06 21:36:42,695 - Epoch: [67][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063126    
2025-01-06 21:36:43,012 - Epoch: [67][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061964    
2025-01-06 21:36:43,310 - Epoch: [67][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060815    
2025-01-06 21:36:43,621 - Epoch: [67][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059781    
2025-01-06 21:36:43,927 - Epoch: [67][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058802    
2025-01-06 21:36:44,256 - Epoch: [67][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057962    
2025-01-06 21:36:44,581 - Epoch: [67][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057139    
2025-01-06 21:36:44,881 - Epoch: [67][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056318    
2025-01-06 21:36:45,230 - Epoch: [67][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.125000    Top5 12.890625    LR 0.001000    Time 0.055686    
2025-01-06 21:36:45,269 - Epoch: [67][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.022670    Top5 11.335013    LR 0.001000    Time 0.055640    
2025-01-06 21:36:46,973 - --- validate (epoch=67)-----------
2025-01-06 21:36:46,973 - 15217 samples (256 per mini-batch)
2025-01-06 21:36:55,884 - Epoch: [67][   10/   60]    Loss 3.044524    Top1 0.156250    Top5 0.273437    
2025-01-06 21:36:56,157 - Epoch: [67][   20/   60]    Loss 3.044524    Top1 0.156250    Top5 0.292969    
2025-01-06 21:36:56,419 - Epoch: [67][   30/   60]    Loss 3.044524    Top1 0.169271    Top5 0.286458    
2025-01-06 21:36:56,683 - Epoch: [67][   40/   60]    Loss 3.044524    Top1 0.185547    Top5 0.322266    
2025-01-06 21:36:56,934 - Epoch: [67][   50/   60]    Loss 3.044524    Top1 0.210937    Top5 0.335938    
2025-01-06 21:36:57,180 - Epoch: [67][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:36:58,707 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:36:58,707 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:36:59,173 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 67]
2025-01-06 21:36:59,173 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:36:59,209 - 

2025-01-06 21:36:59,209 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:37:07,558 - Epoch: [68][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.834899    
2025-01-06 21:37:07,867 - Epoch: [68][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.432784    
2025-01-06 21:37:08,177 - Epoch: [68][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.298862    
2025-01-06 21:37:08,501 - Epoch: [68][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.232227    
2025-01-06 21:37:08,806 - Epoch: [68][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.191889    
2025-01-06 21:37:09,121 - Epoch: [68][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.165156    
2025-01-06 21:37:09,443 - Epoch: [68][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.146158    
2025-01-06 21:37:09,740 - Epoch: [68][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.131612    
2025-01-06 21:37:10,050 - Epoch: [68][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.120410    
2025-01-06 21:37:10,369 - Epoch: [68][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.111530    
2025-01-06 21:37:10,677 - Epoch: [68][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.104198    
2025-01-06 21:37:10,986 - Epoch: [68][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098091    
2025-01-06 21:37:11,315 - Epoch: [68][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093061    
2025-01-06 21:37:11,632 - Epoch: [68][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.088676    
2025-01-06 21:37:11,940 - Epoch: [68][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084820    
2025-01-06 21:37:12,254 - Epoch: [68][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081483    
2025-01-06 21:37:12,558 - Epoch: [68][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078462    
2025-01-06 21:37:12,869 - Epoch: [68][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075834    
2025-01-06 21:37:13,198 - Epoch: [68][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073572    
2025-01-06 21:37:13,497 - Epoch: [68][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071390    
2025-01-06 21:37:13,820 - Epoch: [68][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069529    
2025-01-06 21:37:14,125 - Epoch: [68][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067751    
2025-01-06 21:37:14,443 - Epoch: [68][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066185    
2025-01-06 21:37:14,747 - Epoch: [68][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064697    
2025-01-06 21:37:15,073 - Epoch: [68][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063411    
2025-01-06 21:37:15,388 - Epoch: [68][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062182    
2025-01-06 21:37:15,690 - Epoch: [68][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061000    
2025-01-06 21:37:15,999 - Epoch: [68][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059924    
2025-01-06 21:37:16,304 - Epoch: [68][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058909    
2025-01-06 21:37:16,621 - Epoch: [68][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058002    
2025-01-06 21:37:16,930 - Epoch: [68][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057129    
2025-01-06 21:37:17,255 - Epoch: [68][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056360    
2025-01-06 21:37:17,572 - Epoch: [68][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.055612    
2025-01-06 21:37:17,947 - Epoch: [68][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.078125    Top5 13.671875    LR 0.001000    Time 0.055048    
2025-01-06 21:37:17,977 - Epoch: [68][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.037783    Top5 13.098237    LR 0.001000    Time 0.054975    
2025-01-06 21:37:19,642 - --- validate (epoch=68)-----------
2025-01-06 21:37:19,642 - 15217 samples (256 per mini-batch)
2025-01-06 21:37:28,171 - Epoch: [68][   10/   60]    Loss 3.044524    Top1 0.156250    Top5 0.195312    
2025-01-06 21:37:28,443 - Epoch: [68][   20/   60]    Loss 3.044524    Top1 0.175781    Top5 0.214844    
2025-01-06 21:37:28,686 - Epoch: [68][   30/   60]    Loss 3.044524    Top1 0.169271    Top5 0.208333    
2025-01-06 21:37:28,944 - Epoch: [68][   40/   60]    Loss 3.044524    Top1 0.175781    Top5 0.263672    
2025-01-06 21:37:29,201 - Epoch: [68][   50/   60]    Loss 3.044524    Top1 0.203125    Top5 0.304688    
2025-01-06 21:37:29,445 - Epoch: [68][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:37:30,893 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:37:30,893 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:37:31,375 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 68]
2025-01-06 21:37:31,375 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:37:31,405 - 

2025-01-06 21:37:31,405 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:37:39,981 - Epoch: [69][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.856958    
2025-01-06 21:37:40,305 - Epoch: [69][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.444642    
2025-01-06 21:37:40,610 - Epoch: [69][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.306600    
2025-01-06 21:37:40,920 - Epoch: [69][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.237701    
2025-01-06 21:37:41,227 - Epoch: [69][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.196296    
2025-01-06 21:37:41,532 - Epoch: [69][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.168639    
2025-01-06 21:37:41,882 - Epoch: [69][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.149553    
2025-01-06 21:37:42,188 - Epoch: [69][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.134650    
2025-01-06 21:37:42,497 - Epoch: [69][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.123122    
2025-01-06 21:37:42,796 - Epoch: [69][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.113808    
2025-01-06 21:37:43,114 - Epoch: [69][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.106350    
2025-01-06 21:37:43,426 - Epoch: [69][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100086    
2025-01-06 21:37:43,741 - Epoch: [69][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094805    
2025-01-06 21:37:44,059 - Epoch: [69][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090305    
2025-01-06 21:37:44,372 - Epoch: [69][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086371    
2025-01-06 21:37:44,696 - Epoch: [69][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082983    
2025-01-06 21:37:45,008 - Epoch: [69][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079937    
2025-01-06 21:37:45,318 - Epoch: [69][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077220    
2025-01-06 21:37:45,628 - Epoch: [69][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074788    
2025-01-06 21:37:45,956 - Epoch: [69][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072691    
2025-01-06 21:37:46,268 - Epoch: [69][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070711    
2025-01-06 21:37:46,577 - Epoch: [69][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068892    
2025-01-06 21:37:46,887 - Epoch: [69][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067249    
2025-01-06 21:37:47,195 - Epoch: [69][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065727    
2025-01-06 21:37:47,503 - Epoch: [69][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064331    
2025-01-06 21:37:47,833 - Epoch: [69][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063125    
2025-01-06 21:37:48,150 - Epoch: [69][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061955    
2025-01-06 21:37:48,475 - Epoch: [69][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060902    
2025-01-06 21:37:48,797 - Epoch: [69][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059914    
2025-01-06 21:37:49,122 - Epoch: [69][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058992    
2025-01-06 21:37:49,426 - Epoch: [69][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058070    
2025-01-06 21:37:49,739 - Epoch: [69][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057233    
2025-01-06 21:37:50,048 - Epoch: [69][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056436    
2025-01-06 21:37:50,399 - Epoch: [69][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.125000    Top5 9.765625    LR 0.001000    Time 0.055808    
2025-01-06 21:37:50,448 - Epoch: [69][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.778338    Top5 9.823678    LR 0.001000    Time 0.055787    
2025-01-06 21:37:52,240 - --- validate (epoch=69)-----------
2025-01-06 21:37:52,242 - 15217 samples (256 per mini-batch)
2025-01-06 21:38:01,059 - Epoch: [69][   10/   60]    Loss 3.044523    Top1 0.156250    Top5 0.234375    
2025-01-06 21:38:01,342 - Epoch: [69][   20/   60]    Loss 3.044523    Top1 0.175781    Top5 0.351563    
2025-01-06 21:38:01,601 - Epoch: [69][   30/   60]    Loss 3.044523    Top1 0.182292    Top5 0.338542    
2025-01-06 21:38:01,856 - Epoch: [69][   40/   60]    Loss 3.044523    Top1 0.185547    Top5 0.322266    
2025-01-06 21:38:02,114 - Epoch: [69][   50/   60]    Loss 3.044523    Top1 0.195312    Top5 0.320312    
2025-01-06 21:38:02,366 - Epoch: [69][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:38:03,868 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:38:03,868 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:38:04,354 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 69]
2025-01-06 21:38:04,354 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:38:04,390 - 

2025-01-06 21:38:04,391 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:38:13,386 - Epoch: [70][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.899381    
2025-01-06 21:38:13,703 - Epoch: [70][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.465528    
2025-01-06 21:38:14,020 - Epoch: [70][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.320848    
2025-01-06 21:38:14,339 - Epoch: [70][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.248562    
2025-01-06 21:38:14,655 - Epoch: [70][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.205177    
2025-01-06 21:38:14,968 - Epoch: [70][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.176204    
2025-01-06 21:38:15,306 - Epoch: [70][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.155861    
2025-01-06 21:38:15,624 - Epoch: [70][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.140330    
2025-01-06 21:38:15,937 - Epoch: [70][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.128207    
2025-01-06 21:38:16,242 - Epoch: [70][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.118439    
2025-01-06 21:38:16,563 - Epoch: [70][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.110552    
2025-01-06 21:38:16,871 - Epoch: [70][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.103904    
2025-01-06 21:38:17,184 - Epoch: [70][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098309    
2025-01-06 21:38:17,500 - Epoch: [70][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093549    
2025-01-06 21:38:17,819 - Epoch: [70][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089394    
2025-01-06 21:38:18,124 - Epoch: [70][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085711    
2025-01-06 21:38:18,432 - Epoch: [70][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082484    
2025-01-06 21:38:18,750 - Epoch: [70][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079664    
2025-01-06 21:38:19,061 - Epoch: [70][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077113    
2025-01-06 21:38:19,380 - Epoch: [70][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074851    
2025-01-06 21:38:19,695 - Epoch: [70][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072786    
2025-01-06 21:38:20,029 - Epoch: [70][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070997    
2025-01-06 21:38:20,347 - Epoch: [70][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069293    
2025-01-06 21:38:20,664 - Epoch: [70][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067725    
2025-01-06 21:38:20,969 - Epoch: [70][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066236    
2025-01-06 21:38:21,292 - Epoch: [70][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064931    
2025-01-06 21:38:21,633 - Epoch: [70][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063780    
2025-01-06 21:38:21,943 - Epoch: [70][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062610    
2025-01-06 21:38:22,270 - Epoch: [70][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061581    
2025-01-06 21:38:22,599 - Epoch: [70][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060622    
2025-01-06 21:38:22,911 - Epoch: [70][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059674    
2025-01-06 21:38:23,222 - Epoch: [70][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058783    
2025-01-06 21:38:23,532 - Epoch: [70][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057938    
2025-01-06 21:38:23,865 - Epoch: [70][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.125000    Top5 12.109375    LR 0.001000    Time 0.057215    
2025-01-06 21:38:23,891 - Epoch: [70][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.526448    Top5 12.594458    LR 0.001000    Time 0.057123    
2025-01-06 21:38:25,687 - --- validate (epoch=70)-----------
2025-01-06 21:38:25,697 - 15217 samples (256 per mini-batch)
2025-01-06 21:38:34,244 - Epoch: [70][   10/   60]    Loss 3.044524    Top1 0.117188    Top5 0.312500    
2025-01-06 21:38:34,499 - Epoch: [70][   20/   60]    Loss 3.044524    Top1 0.117188    Top5 0.253906    
2025-01-06 21:38:34,756 - Epoch: [70][   30/   60]    Loss 3.044524    Top1 0.143229    Top5 0.299479    
2025-01-06 21:38:35,020 - Epoch: [70][   40/   60]    Loss 3.044524    Top1 0.156250    Top5 0.283203    
2025-01-06 21:38:35,288 - Epoch: [70][   50/   60]    Loss 3.044524    Top1 0.148437    Top5 0.265625    
2025-01-06 21:38:35,558 - Epoch: [70][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:38:37,183 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:38:37,193 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:38:37,658 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 70]
2025-01-06 21:38:37,658 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:38:37,694 - 

2025-01-06 21:38:37,694 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:38:46,345 - Epoch: [71][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.865006    
2025-01-06 21:38:46,670 - Epoch: [71][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.448736    
2025-01-06 21:38:46,984 - Epoch: [71][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.309639    
2025-01-06 21:38:47,305 - Epoch: [71][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.240240    
2025-01-06 21:38:47,621 - Epoch: [71][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.198514    
2025-01-06 21:38:47,943 - Epoch: [71][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.170793    
2025-01-06 21:38:48,261 - Epoch: [71][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.150914    
2025-01-06 21:38:48,585 - Epoch: [71][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.136094    
2025-01-06 21:38:48,914 - Epoch: [71][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.124628    
2025-01-06 21:38:49,236 - Epoch: [71][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.115368    
2025-01-06 21:38:49,542 - Epoch: [71][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.107659    
2025-01-06 21:38:49,859 - Epoch: [71][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.101328    
2025-01-06 21:38:50,172 - Epoch: [71][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095946    
2025-01-06 21:38:50,501 - Epoch: [71][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091438    
2025-01-06 21:38:50,811 - Epoch: [71][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087414    
2025-01-06 21:38:51,132 - Epoch: [71][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083953    
2025-01-06 21:38:51,435 - Epoch: [71][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080784    
2025-01-06 21:38:51,750 - Epoch: [71][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078047    
2025-01-06 21:38:52,057 - Epoch: [71][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075557    
2025-01-06 21:38:52,368 - Epoch: [71][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073332    
2025-01-06 21:38:52,692 - Epoch: [71][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071373    
2025-01-06 21:38:53,020 - Epoch: [71][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069621    
2025-01-06 21:38:53,332 - Epoch: [71][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067949    
2025-01-06 21:38:53,654 - Epoch: [71][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066460    
2025-01-06 21:38:53,963 - Epoch: [71][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065038    
2025-01-06 21:38:54,266 - Epoch: [71][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063700    
2025-01-06 21:38:54,567 - Epoch: [71][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062456    
2025-01-06 21:38:54,888 - Epoch: [71][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061336    
2025-01-06 21:38:55,201 - Epoch: [71][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060294    
2025-01-06 21:38:55,511 - Epoch: [71][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059319    
2025-01-06 21:38:55,833 - Epoch: [71][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058444    
2025-01-06 21:38:56,133 - Epoch: [71][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057553    
2025-01-06 21:38:56,482 - Epoch: [71][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056863    
2025-01-06 21:38:56,831 - Epoch: [71][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.515625    Top5 16.406250    LR 0.001000    Time 0.056217    
2025-01-06 21:38:56,866 - Epoch: [71][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.030227    Top5 15.113350    LR 0.001000    Time 0.056154    
2025-01-06 21:38:58,734 - --- validate (epoch=71)-----------
2025-01-06 21:38:58,734 - 15217 samples (256 per mini-batch)
2025-01-06 21:39:07,867 - Epoch: [71][   10/   60]    Loss 3.044524    Top1 0.312500    Top5 0.585938    
2025-01-06 21:39:08,135 - Epoch: [71][   20/   60]    Loss 3.044524    Top1 0.234375    Top5 0.390625    
2025-01-06 21:39:08,404 - Epoch: [71][   30/   60]    Loss 3.044524    Top1 0.195312    Top5 0.312500    
2025-01-06 21:39:08,657 - Epoch: [71][   40/   60]    Loss 3.044524    Top1 0.224609    Top5 0.341797    
2025-01-06 21:39:08,909 - Epoch: [71][   50/   60]    Loss 3.044524    Top1 0.203125    Top5 0.312500    
2025-01-06 21:39:09,161 - Epoch: [71][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:39:10,737 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:39:10,739 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:39:11,199 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 71]
2025-01-06 21:39:11,199 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:39:11,230 - 

2025-01-06 21:39:11,231 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:39:20,153 - Epoch: [72][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.892118    
2025-01-06 21:39:20,475 - Epoch: [72][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.462127    
2025-01-06 21:39:20,809 - Epoch: [72][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.319215    
2025-01-06 21:39:21,133 - Epoch: [72][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.247515    
2025-01-06 21:39:21,450 - Epoch: [72][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.204363    
2025-01-06 21:39:21,754 - Epoch: [72][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.175365    
2025-01-06 21:39:22,067 - Epoch: [72][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.154783    
2025-01-06 21:39:22,370 - Epoch: [72][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.139218    
2025-01-06 21:39:22,683 - Epoch: [72][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.127119    
2025-01-06 21:39:22,997 - Epoch: [72][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.117530    
2025-01-06 21:39:23,319 - Epoch: [72][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.109773    
2025-01-06 21:39:23,633 - Epoch: [72][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.103241    
2025-01-06 21:39:23,947 - Epoch: [72][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.097712    
2025-01-06 21:39:24,263 - Epoch: [72][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092991    
2025-01-06 21:39:24,587 - Epoch: [72][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.088949    
2025-01-06 21:39:24,889 - Epoch: [72][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085274    
2025-01-06 21:39:25,192 - Epoch: [72][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082039    
2025-01-06 21:39:25,504 - Epoch: [72][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079213    
2025-01-06 21:39:25,817 - Epoch: [72][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076649    
2025-01-06 21:39:26,124 - Epoch: [72][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074350    
2025-01-06 21:39:26,446 - Epoch: [72][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072343    
2025-01-06 21:39:26,762 - Epoch: [72][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070486    
2025-01-06 21:39:27,100 - Epoch: [72][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068892    
2025-01-06 21:39:27,412 - Epoch: [72][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067323    
2025-01-06 21:39:27,727 - Epoch: [72][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065847    
2025-01-06 21:39:28,042 - Epoch: [72][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064526    
2025-01-06 21:39:28,381 - Epoch: [72][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063395    
2025-01-06 21:39:28,697 - Epoch: [72][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062256    
2025-01-06 21:39:29,012 - Epoch: [72][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061193    
2025-01-06 21:39:29,315 - Epoch: [72][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060159    
2025-01-06 21:39:29,648 - Epoch: [72][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059291    
2025-01-06 21:39:29,958 - Epoch: [72][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058393    
2025-01-06 21:39:30,268 - Epoch: [72][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057563    
2025-01-06 21:39:30,603 - Epoch: [72][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.687500    Top5 14.062500    LR 0.001000    Time 0.056855    
2025-01-06 21:39:30,630 - Epoch: [72][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.282116    Top5 12.846348    LR 0.001000    Time 0.056765    
2025-01-06 21:39:32,262 - --- validate (epoch=72)-----------
2025-01-06 21:39:32,262 - 15217 samples (256 per mini-batch)
2025-01-06 21:39:41,013 - Epoch: [72][   10/   60]    Loss 3.044523    Top1 0.312500    Top5 0.468750    
2025-01-06 21:39:41,277 - Epoch: [72][   20/   60]    Loss 3.044524    Top1 0.312500    Top5 0.488281    
2025-01-06 21:39:41,530 - Epoch: [72][   30/   60]    Loss 3.044524    Top1 0.221354    Top5 0.351563    
2025-01-06 21:39:41,786 - Epoch: [72][   40/   60]    Loss 3.044524    Top1 0.185547    Top5 0.302734    
2025-01-06 21:39:42,035 - Epoch: [72][   50/   60]    Loss 3.044524    Top1 0.210937    Top5 0.335938    
2025-01-06 21:39:42,285 - Epoch: [72][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:39:43,800 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:39:43,800 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:39:44,480 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 72]
2025-01-06 21:39:44,487 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:39:44,521 - 

2025-01-06 21:39:44,522 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:39:53,003 - Epoch: [73][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.848021    
2025-01-06 21:39:53,327 - Epoch: [73][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.440228    
2025-01-06 21:39:53,643 - Epoch: [73][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.304016    
2025-01-06 21:39:53,962 - Epoch: [73][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.235993    
2025-01-06 21:39:54,274 - Epoch: [73][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.195026    
2025-01-06 21:39:54,583 - Epoch: [73][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.167558    
2025-01-06 21:39:54,916 - Epoch: [73][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.148382    
2025-01-06 21:39:55,236 - Epoch: [73][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.133804    
2025-01-06 21:39:55,555 - Epoch: [73][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.122476    
2025-01-06 21:39:55,884 - Epoch: [73][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.113523    
2025-01-06 21:39:56,191 - Epoch: [73][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.105992    
2025-01-06 21:39:56,502 - Epoch: [73][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.099752    
2025-01-06 21:39:56,812 - Epoch: [73][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094462    
2025-01-06 21:39:57,124 - Epoch: [73][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089946    
2025-01-06 21:39:57,442 - Epoch: [73][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086071    
2025-01-06 21:39:57,761 - Epoch: [73][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082681    
2025-01-06 21:39:58,068 - Epoch: [73][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079626    
2025-01-06 21:39:58,416 - Epoch: [73][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077131    
2025-01-06 21:39:58,728 - Epoch: [73][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074702    
2025-01-06 21:39:59,062 - Epoch: [73][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072629    
2025-01-06 21:39:59,378 - Epoch: [73][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070676    
2025-01-06 21:39:59,687 - Epoch: [73][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068866    
2025-01-06 21:39:59,997 - Epoch: [73][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067210    
2025-01-06 21:40:00,306 - Epoch: [73][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065697    
2025-01-06 21:40:00,617 - Epoch: [73][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064316    
2025-01-06 21:40:00,931 - Epoch: [73][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063050    
2025-01-06 21:40:01,239 - Epoch: [73][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061854    
2025-01-06 21:40:01,549 - Epoch: [73][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060752    
2025-01-06 21:40:01,867 - Epoch: [73][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059751    
2025-01-06 21:40:02,177 - Epoch: [73][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058793    
2025-01-06 21:40:02,488 - Epoch: [73][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057900    
2025-01-06 21:40:02,796 - Epoch: [73][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057053    
2025-01-06 21:40:03,101 - Epoch: [73][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056250    
2025-01-06 21:40:03,448 - Epoch: [73][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.078125    Top5 13.671875    LR 0.001000    Time 0.055615    
2025-01-06 21:40:03,484 - Epoch: [73][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.282116    Top5 13.098237    LR 0.001000    Time 0.055558    
2025-01-06 21:40:05,166 - --- validate (epoch=73)-----------
2025-01-06 21:40:05,166 - 15217 samples (256 per mini-batch)
2025-01-06 21:40:14,031 - Epoch: [73][   10/   60]    Loss 3.044523    Top1 0.117188    Top5 0.156250    
2025-01-06 21:40:14,297 - Epoch: [73][   20/   60]    Loss 3.044523    Top1 0.175781    Top5 0.234375    
2025-01-06 21:40:14,553 - Epoch: [73][   30/   60]    Loss 3.044523    Top1 0.195312    Top5 0.273437    
2025-01-06 21:40:14,826 - Epoch: [73][   40/   60]    Loss 3.044523    Top1 0.205078    Top5 0.332031    
2025-01-06 21:40:15,074 - Epoch: [73][   50/   60]    Loss 3.044523    Top1 0.195312    Top5 0.328125    
2025-01-06 21:40:15,320 - Epoch: [73][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:40:16,774 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:40:16,774 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:40:17,231 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 73]
2025-01-06 21:40:17,238 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:40:17,266 - 

2025-01-06 21:40:17,267 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:40:26,323 - Epoch: [74][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.905457    
2025-01-06 21:40:26,658 - Epoch: [74][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.469401    
2025-01-06 21:40:26,961 - Epoch: [74][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.323038    
2025-01-06 21:40:27,270 - Epoch: [74][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.250011    
2025-01-06 21:40:27,601 - Epoch: [74][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.206418    
2025-01-06 21:40:27,925 - Epoch: [74][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.177418    
2025-01-06 21:40:28,247 - Epoch: [74][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.156672    
2025-01-06 21:40:28,564 - Epoch: [74][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.141045    
2025-01-06 21:40:28,869 - Epoch: [74][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.128767    
2025-01-06 21:40:29,212 - Epoch: [74][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.119298    
2025-01-06 21:40:29,529 - Epoch: [74][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.111337    
2025-01-06 21:40:29,838 - Epoch: [74][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.104544    
2025-01-06 21:40:30,151 - Epoch: [74][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098855    
2025-01-06 21:40:30,477 - Epoch: [74][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094120    
2025-01-06 21:40:30,796 - Epoch: [74][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089975    
2025-01-06 21:40:31,096 - Epoch: [74][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086224    
2025-01-06 21:40:31,410 - Epoch: [74][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083000    
2025-01-06 21:40:31,747 - Epoch: [74][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080262    
2025-01-06 21:40:32,062 - Epoch: [74][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077694    
2025-01-06 21:40:32,371 - Epoch: [74][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075354    
2025-01-06 21:40:32,689 - Epoch: [74][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073283    
2025-01-06 21:40:33,010 - Epoch: [74][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071407    
2025-01-06 21:40:33,333 - Epoch: [74][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069663    
2025-01-06 21:40:33,662 - Epoch: [74][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068130    
2025-01-06 21:40:33,980 - Epoch: [74][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066675    
2025-01-06 21:40:34,290 - Epoch: [74][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065305    
2025-01-06 21:40:34,620 - Epoch: [74][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064108    
2025-01-06 21:40:34,953 - Epoch: [74][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063007    
2025-01-06 21:40:35,269 - Epoch: [74][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061925    
2025-01-06 21:40:35,581 - Epoch: [74][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060901    
2025-01-06 21:40:35,895 - Epoch: [74][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059949    
2025-01-06 21:40:36,208 - Epoch: [74][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059053    
2025-01-06 21:40:36,551 - Epoch: [74][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058304    
2025-01-06 21:40:36,914 - Epoch: [74][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.906250    Top5 12.109375    LR 0.001000    Time 0.057654    
2025-01-06 21:40:36,947 - Epoch: [74][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.030227    Top5 12.342569    LR 0.001000    Time 0.057583    
2025-01-06 21:40:38,637 - --- validate (epoch=74)-----------
2025-01-06 21:40:38,647 - 15217 samples (256 per mini-batch)
2025-01-06 21:40:47,340 - Epoch: [74][   10/   60]    Loss 3.044524    Top1 0.195312    Top5 0.234375    
2025-01-06 21:40:47,637 - Epoch: [74][   20/   60]    Loss 3.044524    Top1 0.214844    Top5 0.312500    
2025-01-06 21:40:47,906 - Epoch: [74][   30/   60]    Loss 3.044524    Top1 0.195312    Top5 0.286458    
2025-01-06 21:40:48,159 - Epoch: [74][   40/   60]    Loss 3.044524    Top1 0.224609    Top5 0.351563    
2025-01-06 21:40:48,417 - Epoch: [74][   50/   60]    Loss 3.044524    Top1 0.195312    Top5 0.320312    
2025-01-06 21:40:48,647 - Epoch: [74][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:40:50,180 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:40:50,180 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:40:50,646 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 74]
2025-01-06 21:40:50,646 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:40:50,690 - 

2025-01-06 21:40:50,690 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:40:59,258 - Epoch: [75][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.856819    
2025-01-06 21:40:59,592 - Epoch: [75][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.445121    
2025-01-06 21:40:59,913 - Epoch: [75][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.307462    
2025-01-06 21:41:00,227 - Epoch: [75][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.238433    
2025-01-06 21:41:00,562 - Epoch: [75][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.197441    
2025-01-06 21:41:00,893 - Epoch: [75][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.170049    
2025-01-06 21:41:01,215 - Epoch: [75][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.150365    
2025-01-06 21:41:01,518 - Epoch: [75][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.135355    
2025-01-06 21:41:01,836 - Epoch: [75][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.123846    
2025-01-06 21:41:02,149 - Epoch: [75][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.114596    
2025-01-06 21:41:02,473 - Epoch: [75][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.107118    
2025-01-06 21:41:02,791 - Epoch: [75][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100848    
2025-01-06 21:41:03,087 - Epoch: [75][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095319    
2025-01-06 21:41:03,402 - Epoch: [75][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090744    
2025-01-06 21:41:03,715 - Epoch: [75][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086785    
2025-01-06 21:41:04,024 - Epoch: [75][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083284    
2025-01-06 21:41:04,334 - Epoch: [75][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080209    
2025-01-06 21:41:04,647 - Epoch: [75][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077490    
2025-01-06 21:41:04,974 - Epoch: [75][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075124    
2025-01-06 21:41:05,293 - Epoch: [75][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072962    
2025-01-06 21:41:05,605 - Epoch: [75][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070972    
2025-01-06 21:41:05,923 - Epoch: [75][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069191    
2025-01-06 21:41:06,228 - Epoch: [75][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067493    
2025-01-06 21:41:06,563 - Epoch: [75][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066077    
2025-01-06 21:41:06,878 - Epoch: [75][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064691    
2025-01-06 21:41:07,193 - Epoch: [75][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063376    
2025-01-06 21:41:07,517 - Epoch: [75][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062229    
2025-01-06 21:41:07,847 - Epoch: [75][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061183    
2025-01-06 21:41:08,156 - Epoch: [75][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060140    
2025-01-06 21:41:08,467 - Epoch: [75][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059172    
2025-01-06 21:41:08,773 - Epoch: [75][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058251    
2025-01-06 21:41:09,076 - Epoch: [75][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057376    
2025-01-06 21:41:09,407 - Epoch: [75][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056642    
2025-01-06 21:41:09,760 - Epoch: [75][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.687500    Top5 17.187500    LR 0.001000    Time 0.056012    
2025-01-06 21:41:09,783 - Epoch: [75][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.030227    Top5 15.617128    LR 0.001000    Time 0.055916    
2025-01-06 21:41:12,001 - --- validate (epoch=75)-----------
2025-01-06 21:41:12,001 - 15217 samples (256 per mini-batch)
2025-01-06 21:41:21,038 - Epoch: [75][   10/   60]    Loss 3.044524    Top1 0.156250    Top5 0.273437    
2025-01-06 21:41:21,311 - Epoch: [75][   20/   60]    Loss 3.044524    Top1 0.195312    Top5 0.351563    
2025-01-06 21:41:21,569 - Epoch: [75][   30/   60]    Loss 3.044523    Top1 0.182292    Top5 0.325521    
2025-01-06 21:41:21,844 - Epoch: [75][   40/   60]    Loss 3.044523    Top1 0.205078    Top5 0.332031    
2025-01-06 21:41:22,100 - Epoch: [75][   50/   60]    Loss 3.044523    Top1 0.210937    Top5 0.335938    
2025-01-06 21:41:22,345 - Epoch: [75][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:41:23,823 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:41:23,823 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:41:24,300 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 75]
2025-01-06 21:41:24,303 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:41:24,335 - 

2025-01-06 21:41:24,336 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:41:33,511 - Epoch: [76][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.917367    
2025-01-06 21:41:33,824 - Epoch: [76][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.474349    
2025-01-06 21:41:34,136 - Epoch: [76][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.326629    
2025-01-06 21:41:34,446 - Epoch: [76][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.252735    
2025-01-06 21:41:34,773 - Epoch: [76][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.208712    
2025-01-06 21:41:35,103 - Epoch: [76][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.179430    
2025-01-06 21:41:35,426 - Epoch: [76][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.158412    
2025-01-06 21:41:35,740 - Epoch: [76][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.142538    
2025-01-06 21:41:36,047 - Epoch: [76][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.130115    
2025-01-06 21:41:36,359 - Epoch: [76][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.120219    
2025-01-06 21:41:36,686 - Epoch: [76][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.112262    
2025-01-06 21:41:36,999 - Epoch: [76][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.105517    
2025-01-06 21:41:37,313 - Epoch: [76][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.099735    
2025-01-06 21:41:37,624 - Epoch: [76][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094837    
2025-01-06 21:41:37,969 - Epoch: [76][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090810    
2025-01-06 21:41:38,296 - Epoch: [76][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087179    
2025-01-06 21:41:38,599 - Epoch: [76][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083834    
2025-01-06 21:41:38,913 - Epoch: [76][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080921    
2025-01-06 21:41:39,236 - Epoch: [76][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078365    
2025-01-06 21:41:39,561 - Epoch: [76][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076068    
2025-01-06 21:41:39,893 - Epoch: [76][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074027    
2025-01-06 21:41:40,206 - Epoch: [76][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072084    
2025-01-06 21:41:40,528 - Epoch: [76][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070351    
2025-01-06 21:41:40,835 - Epoch: [76][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068701    
2025-01-06 21:41:41,151 - Epoch: [76][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067217    
2025-01-06 21:41:41,474 - Epoch: [76][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065872    
2025-01-06 21:41:41,795 - Epoch: [76][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064622    
2025-01-06 21:41:42,110 - Epoch: [76][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063402    
2025-01-06 21:41:42,410 - Epoch: [76][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062245    
2025-01-06 21:41:42,744 - Epoch: [76][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061247    
2025-01-06 21:41:43,068 - Epoch: [76][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060317    
2025-01-06 21:41:43,378 - Epoch: [76][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059403    
2025-01-06 21:41:43,693 - Epoch: [76][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058556    
2025-01-06 21:41:44,056 - Epoch: [76][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.906250    Top5 10.546875    LR 0.001000    Time 0.057902    
2025-01-06 21:41:44,083 - Epoch: [76][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.282116    Top5 11.586902    LR 0.001000    Time 0.057810    
2025-01-06 21:41:45,790 - --- validate (epoch=76)-----------
2025-01-06 21:41:45,790 - 15217 samples (256 per mini-batch)
2025-01-06 21:41:54,658 - Epoch: [76][   10/   60]    Loss 3.044523    Top1 0.156250    Top5 0.234375    
2025-01-06 21:41:54,923 - Epoch: [76][   20/   60]    Loss 3.044524    Top1 0.195312    Top5 0.351563    
2025-01-06 21:41:55,186 - Epoch: [76][   30/   60]    Loss 3.044523    Top1 0.182292    Top5 0.312500    
2025-01-06 21:41:55,438 - Epoch: [76][   40/   60]    Loss 3.044523    Top1 0.185547    Top5 0.322266    
2025-01-06 21:41:55,708 - Epoch: [76][   50/   60]    Loss 3.044524    Top1 0.179688    Top5 0.304688    
2025-01-06 21:41:55,955 - Epoch: [76][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:41:57,415 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:41:57,415 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:41:57,905 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 76]
2025-01-06 21:41:57,905 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:41:57,942 - 

2025-01-06 21:41:57,943 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:42:06,519 - Epoch: [77][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.857561    
2025-01-06 21:42:06,837 - Epoch: [77][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.444661    
2025-01-06 21:42:07,173 - Epoch: [77][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.307637    
2025-01-06 21:42:07,485 - Epoch: [77][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.238533    
2025-01-06 21:42:07,800 - Epoch: [77][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.197138    
2025-01-06 21:42:08,143 - Epoch: [77][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.169990    
2025-01-06 21:42:08,447 - Epoch: [77][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.150050    
2025-01-06 21:42:08,746 - Epoch: [77][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.135034    
2025-01-06 21:42:09,052 - Epoch: [77][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.123318    
2025-01-06 21:42:09,355 - Epoch: [77][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.114015    
2025-01-06 21:42:09,683 - Epoch: [77][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.106542    
2025-01-06 21:42:09,988 - Epoch: [77][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100202    
2025-01-06 21:42:10,296 - Epoch: [77][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094784    
2025-01-06 21:42:10,609 - Epoch: [77][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090250    
2025-01-06 21:42:10,923 - Epoch: [77][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086323    
2025-01-06 21:42:11,242 - Epoch: [77][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082923    
2025-01-06 21:42:11,555 - Epoch: [77][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079872    
2025-01-06 21:42:11,878 - Epoch: [77][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077231    
2025-01-06 21:42:12,191 - Epoch: [77][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074811    
2025-01-06 21:42:12,496 - Epoch: [77][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072593    
2025-01-06 21:42:12,822 - Epoch: [77][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070640    
2025-01-06 21:42:13,145 - Epoch: [77][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068899    
2025-01-06 21:42:13,448 - Epoch: [77][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067219    
2025-01-06 21:42:13,772 - Epoch: [77][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065766    
2025-01-06 21:42:14,074 - Epoch: [77][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064344    
2025-01-06 21:42:14,398 - Epoch: [77][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063116    
2025-01-06 21:42:14,721 - Epoch: [77][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061975    
2025-01-06 21:42:15,039 - Epoch: [77][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060897    
2025-01-06 21:42:15,345 - Epoch: [77][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059854    
2025-01-06 21:42:15,644 - Epoch: [77][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058853    
2025-01-06 21:42:15,974 - Epoch: [77][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058021    
2025-01-06 21:42:16,302 - Epoch: [77][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057232    
2025-01-06 21:42:16,615 - Epoch: [77][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056442    
2025-01-06 21:42:16,959 - Epoch: [77][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.296875    Top5 15.625000    LR 0.001000    Time 0.055794    
2025-01-06 21:42:17,002 - Epoch: [77][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.030227    Top5 14.861461    LR 0.001000    Time 0.055759    
2025-01-06 21:42:18,874 - --- validate (epoch=77)-----------
2025-01-06 21:42:18,874 - 15217 samples (256 per mini-batch)
2025-01-06 21:42:27,507 - Epoch: [77][   10/   60]    Loss 3.044523    Top1 0.195312    Top5 0.234375    
2025-01-06 21:42:27,776 - Epoch: [77][   20/   60]    Loss 3.044524    Top1 0.214844    Top5 0.234375    
2025-01-06 21:42:28,025 - Epoch: [77][   30/   60]    Loss 3.044524    Top1 0.234375    Top5 0.260417    
2025-01-06 21:42:28,288 - Epoch: [77][   40/   60]    Loss 3.044524    Top1 0.214844    Top5 0.283203    
2025-01-06 21:42:28,545 - Epoch: [77][   50/   60]    Loss 3.044524    Top1 0.210937    Top5 0.312500    
2025-01-06 21:42:28,779 - Epoch: [77][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:42:30,249 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:42:30,249 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:42:30,708 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 77]
2025-01-06 21:42:30,717 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:42:30,749 - 

2025-01-06 21:42:30,750 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:42:39,690 - Epoch: [78][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.893815    
2025-01-06 21:42:40,019 - Epoch: [78][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.463387    
2025-01-06 21:42:40,363 - Epoch: [78][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.320395    
2025-01-06 21:42:40,663 - Epoch: [78][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.247788    
2025-01-06 21:42:40,995 - Epoch: [78][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.204875    
2025-01-06 21:42:41,309 - Epoch: [78][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.175959    
2025-01-06 21:42:41,608 - Epoch: [78][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.155086    
2025-01-06 21:42:41,919 - Epoch: [78][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.139556    
2025-01-06 21:42:42,245 - Epoch: [78][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.127653    
2025-01-06 21:42:42,545 - Epoch: [78][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.117884    
2025-01-06 21:42:42,857 - Epoch: [78][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.110004    
2025-01-06 21:42:43,181 - Epoch: [78][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.103537    
2025-01-06 21:42:43,485 - Epoch: [78][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.097916    
2025-01-06 21:42:43,810 - Epoch: [78][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093239    
2025-01-06 21:42:44,114 - Epoch: [78][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089052    
2025-01-06 21:42:44,455 - Epoch: [78][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085618    
2025-01-06 21:42:44,800 - Epoch: [78][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082612    
2025-01-06 21:42:45,120 - Epoch: [78][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079785    
2025-01-06 21:42:45,431 - Epoch: [78][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077223    
2025-01-06 21:42:45,736 - Epoch: [78][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074889    
2025-01-06 21:42:46,054 - Epoch: [78][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072837    
2025-01-06 21:42:46,372 - Epoch: [78][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070921    
2025-01-06 21:42:46,709 - Epoch: [78][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069303    
2025-01-06 21:42:47,033 - Epoch: [78][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067764    
2025-01-06 21:42:47,348 - Epoch: [78][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066304    
2025-01-06 21:42:47,667 - Epoch: [78][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064981    
2025-01-06 21:42:47,982 - Epoch: [78][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063743    
2025-01-06 21:42:48,300 - Epoch: [78][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062602    
2025-01-06 21:42:48,634 - Epoch: [78][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061594    
2025-01-06 21:42:48,968 - Epoch: [78][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060655    
2025-01-06 21:42:49,291 - Epoch: [78][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059740    
2025-01-06 21:42:49,609 - Epoch: [78][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058868    
2025-01-06 21:42:49,929 - Epoch: [78][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058049    
2025-01-06 21:42:50,273 - Epoch: [78][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.515625    Top5 14.453125    LR 0.001000    Time 0.057353    
2025-01-06 21:42:50,302 - Epoch: [78][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 2.770781    Top5 14.105793    LR 0.001000    Time 0.057270    
2025-01-06 21:42:51,956 - --- validate (epoch=78)-----------
2025-01-06 21:42:51,956 - 15217 samples (256 per mini-batch)
2025-01-06 21:43:01,018 - Epoch: [78][   10/   60]    Loss 3.044523    Top1 0.234375    Top5 0.390625    
2025-01-06 21:43:01,271 - Epoch: [78][   20/   60]    Loss 3.044523    Top1 0.136719    Top5 0.234375    
2025-01-06 21:43:01,545 - Epoch: [78][   30/   60]    Loss 3.044523    Top1 0.143229    Top5 0.247396    
2025-01-06 21:43:01,796 - Epoch: [78][   40/   60]    Loss 3.044523    Top1 0.156250    Top5 0.263672    
2025-01-06 21:43:02,068 - Epoch: [78][   50/   60]    Loss 3.044523    Top1 0.187500    Top5 0.296875    
2025-01-06 21:43:02,325 - Epoch: [78][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:43:03,803 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:43:03,803 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:43:04,502 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 78]
2025-01-06 21:43:04,502 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:43:04,534 - 

2025-01-06 21:43:04,535 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:43:13,206 - Epoch: [79][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.866882    
2025-01-06 21:43:13,536 - Epoch: [79][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.449968    
2025-01-06 21:43:13,849 - Epoch: [79][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.310403    
2025-01-06 21:43:14,167 - Epoch: [79][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.240746    
2025-01-06 21:43:14,466 - Epoch: [79][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.198580    
2025-01-06 21:43:14,781 - Epoch: [79][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.170737    
2025-01-06 21:43:15,085 - Epoch: [79][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.150683    
2025-01-06 21:43:15,403 - Epoch: [79][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.135822    
2025-01-06 21:43:15,710 - Epoch: [79][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.124119    
2025-01-06 21:43:16,020 - Epoch: [79][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.114816    
2025-01-06 21:43:16,321 - Epoch: [79][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.107109    
2025-01-06 21:43:16,642 - Epoch: [79][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100862    
2025-01-06 21:43:16,962 - Epoch: [79][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095552    
2025-01-06 21:43:17,290 - Epoch: [79][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091073    
2025-01-06 21:43:17,600 - Epoch: [79][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087068    
2025-01-06 21:43:17,921 - Epoch: [79][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083632    
2025-01-06 21:43:18,226 - Epoch: [79][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080508    
2025-01-06 21:43:18,536 - Epoch: [79][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077759    
2025-01-06 21:43:18,841 - Epoch: [79][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075256    
2025-01-06 21:43:19,162 - Epoch: [79][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073101    
2025-01-06 21:43:19,476 - Epoch: [79][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071113    
2025-01-06 21:43:19,785 - Epoch: [79][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069280    
2025-01-06 21:43:20,091 - Epoch: [79][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067601    
2025-01-06 21:43:20,404 - Epoch: [79][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066087    
2025-01-06 21:43:20,716 - Epoch: [79][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064691    
2025-01-06 21:43:21,036 - Epoch: [79][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063436    
2025-01-06 21:43:21,346 - Epoch: [79][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062232    
2025-01-06 21:43:21,660 - Epoch: [79][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061132    
2025-01-06 21:43:22,001 - Epoch: [79][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060201    
2025-01-06 21:43:22,312 - Epoch: [79][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059230    
2025-01-06 21:43:22,624 - Epoch: [79][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058324    
2025-01-06 21:43:22,952 - Epoch: [79][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057527    
2025-01-06 21:43:23,256 - Epoch: [79][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056704    
2025-01-06 21:43:23,586 - Epoch: [79][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.125000    Top5 8.984375    LR 0.001000    Time 0.056007    
2025-01-06 21:43:23,622 - Epoch: [79][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.534005    Top5 12.090680    LR 0.001000    Time 0.055919    
2025-01-06 21:43:25,476 - --- validate (epoch=79)-----------
2025-01-06 21:43:25,476 - 15217 samples (256 per mini-batch)
2025-01-06 21:43:33,928 - Epoch: [79][   10/   60]    Loss 3.044524    Top1 0.156250    Top5 0.195312    
2025-01-06 21:43:34,196 - Epoch: [79][   20/   60]    Loss 3.044524    Top1 0.136719    Top5 0.195312    
2025-01-06 21:43:34,452 - Epoch: [79][   30/   60]    Loss 3.044524    Top1 0.169271    Top5 0.247396    
2025-01-06 21:43:34,706 - Epoch: [79][   40/   60]    Loss 3.044524    Top1 0.195312    Top5 0.302734    
2025-01-06 21:43:34,969 - Epoch: [79][   50/   60]    Loss 3.044524    Top1 0.203125    Top5 0.304688    
2025-01-06 21:43:35,208 - Epoch: [79][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:43:36,691 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:43:36,691 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:43:37,147 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 79]
2025-01-06 21:43:37,157 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:43:37,189 - 

2025-01-06 21:43:37,190 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:43:45,891 - Epoch: [80][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.869962    
2025-01-06 21:43:46,220 - Epoch: [80][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.451404    
2025-01-06 21:43:46,543 - Epoch: [80][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.311702    
2025-01-06 21:43:46,864 - Epoch: [80][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.241811    
2025-01-06 21:43:47,189 - Epoch: [80][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.199755    
2025-01-06 21:43:47,510 - Epoch: [80][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.171812    
2025-01-06 21:43:47,815 - Epoch: [80][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.151621    
2025-01-06 21:43:48,112 - Epoch: [80][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.136376    
2025-01-06 21:43:48,429 - Epoch: [80][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.124751    
2025-01-06 21:43:48,741 - Epoch: [80][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.115374    
2025-01-06 21:43:49,061 - Epoch: [80][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.107800    
2025-01-06 21:43:49,364 - Epoch: [80][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.101333    
2025-01-06 21:43:49,671 - Epoch: [80][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095904    
2025-01-06 21:43:49,982 - Epoch: [80][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091275    
2025-01-06 21:43:50,299 - Epoch: [80][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087303    
2025-01-06 21:43:50,600 - Epoch: [80][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083714    
2025-01-06 21:43:50,910 - Epoch: [80][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080553    
2025-01-06 21:43:51,222 - Epoch: [80][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077803    
2025-01-06 21:43:51,532 - Epoch: [80][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075337    
2025-01-06 21:43:51,850 - Epoch: [80][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073163    
2025-01-06 21:43:52,161 - Epoch: [80][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071159    
2025-01-06 21:43:52,480 - Epoch: [80][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069375    
2025-01-06 21:43:52,778 - Epoch: [80][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067651    
2025-01-06 21:43:53,085 - Epoch: [80][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066112    
2025-01-06 21:43:53,396 - Epoch: [80][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064713    
2025-01-06 21:43:53,700 - Epoch: [80][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063385    
2025-01-06 21:43:54,006 - Epoch: [80][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062169    
2025-01-06 21:43:54,308 - Epoch: [80][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061027    
2025-01-06 21:43:54,617 - Epoch: [80][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059988    
2025-01-06 21:43:54,933 - Epoch: [80][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059044    
2025-01-06 21:43:55,260 - Epoch: [80][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058194    
2025-01-06 21:43:55,585 - Epoch: [80][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057384    
2025-01-06 21:43:55,890 - Epoch: [80][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056570    
2025-01-06 21:43:56,246 - Epoch: [80][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.906250    Top5 12.500000    LR 0.001000    Time 0.055953    
2025-01-06 21:43:56,294 - Epoch: [80][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.526448    Top5 11.083123    LR 0.001000    Time 0.055929    
2025-01-06 21:43:58,028 - --- validate (epoch=80)-----------
2025-01-06 21:43:58,028 - 15217 samples (256 per mini-batch)
2025-01-06 21:44:07,196 - Epoch: [80][   10/   60]    Loss 3.044524    Top1 0.234375    Top5 0.312500    
2025-01-06 21:44:07,455 - Epoch: [80][   20/   60]    Loss 3.044524    Top1 0.253906    Top5 0.371094    
2025-01-06 21:44:07,719 - Epoch: [80][   30/   60]    Loss 3.044524    Top1 0.221354    Top5 0.364583    
2025-01-06 21:44:07,999 - Epoch: [80][   40/   60]    Loss 3.044523    Top1 0.214844    Top5 0.341797    
2025-01-06 21:44:08,281 - Epoch: [80][   50/   60]    Loss 3.044523    Top1 0.218750    Top5 0.320312    
2025-01-06 21:44:08,529 - Epoch: [80][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:44:09,982 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:44:09,993 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:44:10,454 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 80]
2025-01-06 21:44:10,454 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:44:10,493 - 

2025-01-06 21:44:10,493 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:44:19,059 - Epoch: [81][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.856651    
2025-01-06 21:44:19,394 - Epoch: [81][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.445068    
2025-01-06 21:44:19,703 - Epoch: [81][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.306997    
2025-01-06 21:44:20,036 - Epoch: [81][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.238533    
2025-01-06 21:44:20,360 - Epoch: [81][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.197310    
2025-01-06 21:44:20,683 - Epoch: [81][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.169796    
2025-01-06 21:44:20,989 - Epoch: [81][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.149913    
2025-01-06 21:44:21,312 - Epoch: [81][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.135219    
2025-01-06 21:44:21,622 - Epoch: [81][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.123635    
2025-01-06 21:44:21,928 - Epoch: [81][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.114322    
2025-01-06 21:44:22,233 - Epoch: [81][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.106701    
2025-01-06 21:44:22,547 - Epoch: [81][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100429    
2025-01-06 21:44:22,861 - Epoch: [81][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095118    
2025-01-06 21:44:23,179 - Epoch: [81][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090594    
2025-01-06 21:44:23,494 - Epoch: [81][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086653    
2025-01-06 21:44:23,805 - Epoch: [81][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083184    
2025-01-06 21:44:24,123 - Epoch: [81][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080158    
2025-01-06 21:44:24,448 - Epoch: [81][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077511    
2025-01-06 21:44:24,767 - Epoch: [81][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075099    
2025-01-06 21:44:25,075 - Epoch: [81][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072888    
2025-01-06 21:44:25,388 - Epoch: [81][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070907    
2025-01-06 21:44:25,694 - Epoch: [81][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069072    
2025-01-06 21:44:26,009 - Epoch: [81][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067440    
2025-01-06 21:44:26,334 - Epoch: [81][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065985    
2025-01-06 21:44:26,648 - Epoch: [81][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064593    
2025-01-06 21:44:26,995 - Epoch: [81][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063444    
2025-01-06 21:44:27,302 - Epoch: [81][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062231    
2025-01-06 21:44:27,618 - Epoch: [81][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061127    
2025-01-06 21:44:27,930 - Epoch: [81][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060096    
2025-01-06 21:44:28,247 - Epoch: [81][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059148    
2025-01-06 21:44:28,568 - Epoch: [81][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058236    
2025-01-06 21:44:28,887 - Epoch: [81][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057415    
2025-01-06 21:44:29,209 - Epoch: [81][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056635    
2025-01-06 21:44:29,553 - Epoch: [81][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.125000    Top5 12.890625    LR 0.001000    Time 0.055981    
2025-01-06 21:44:29,592 - Epoch: [81][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.030227    Top5 12.846348    LR 0.001000    Time 0.055929    
2025-01-06 21:44:31,376 - --- validate (epoch=81)-----------
2025-01-06 21:44:31,376 - 15217 samples (256 per mini-batch)
2025-01-06 21:44:40,185 - Epoch: [81][   10/   60]    Loss 3.044524    Top1 0.117188    Top5 0.312500    
2025-01-06 21:44:40,447 - Epoch: [81][   20/   60]    Loss 3.044524    Top1 0.136719    Top5 0.273437    
2025-01-06 21:44:40,698 - Epoch: [81][   30/   60]    Loss 3.044524    Top1 0.156250    Top5 0.260417    
2025-01-06 21:44:40,957 - Epoch: [81][   40/   60]    Loss 3.044524    Top1 0.156250    Top5 0.273437    
2025-01-06 21:44:41,212 - Epoch: [81][   50/   60]    Loss 3.044524    Top1 0.195312    Top5 0.320312    
2025-01-06 21:44:41,473 - Epoch: [81][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:44:42,912 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:44:42,916 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:44:43,390 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 81]
2025-01-06 21:44:43,390 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:44:43,425 - 

2025-01-06 21:44:43,425 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:44:52,016 - Epoch: [82][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.858711    
2025-01-06 21:44:52,336 - Epoch: [82][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.445359    
2025-01-06 21:44:52,636 - Epoch: [82][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.306913    
2025-01-06 21:44:52,958 - Epoch: [82][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.238225    
2025-01-06 21:44:53,275 - Epoch: [82][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.196927    
2025-01-06 21:44:53,574 - Epoch: [82][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.169086    
2025-01-06 21:44:53,928 - Epoch: [82][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.149993    
2025-01-06 21:44:54,237 - Epoch: [82][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.135105    
2025-01-06 21:44:54,546 - Epoch: [82][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.123529    
2025-01-06 21:44:54,870 - Epoch: [82][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.114416    
2025-01-06 21:44:55,205 - Epoch: [82][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.107059    
2025-01-06 21:44:55,523 - Epoch: [82][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100701    
2025-01-06 21:44:55,847 - Epoch: [82][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095449    
2025-01-06 21:44:56,174 - Epoch: [82][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090964    
2025-01-06 21:44:56,486 - Epoch: [82][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086980    
2025-01-06 21:44:56,804 - Epoch: [82][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083532    
2025-01-06 21:44:57,126 - Epoch: [82][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080501    
2025-01-06 21:44:57,435 - Epoch: [82][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077745    
2025-01-06 21:44:57,741 - Epoch: [82][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075263    
2025-01-06 21:44:58,064 - Epoch: [82][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073114    
2025-01-06 21:44:58,367 - Epoch: [82][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071078    
2025-01-06 21:44:58,675 - Epoch: [82][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069249    
2025-01-06 21:44:58,979 - Epoch: [82][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067559    
2025-01-06 21:44:59,302 - Epoch: [82][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066089    
2025-01-06 21:44:59,615 - Epoch: [82][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064697    
2025-01-06 21:44:59,919 - Epoch: [82][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063377    
2025-01-06 21:45:00,267 - Epoch: [82][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062292    
2025-01-06 21:45:00,592 - Epoch: [82][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061229    
2025-01-06 21:45:00,909 - Epoch: [82][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060210    
2025-01-06 21:45:01,210 - Epoch: [82][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059206    
2025-01-06 21:45:01,512 - Epoch: [82][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058268    
2025-01-06 21:45:01,814 - Epoch: [82][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057390    
2025-01-06 21:45:02,117 - Epoch: [82][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056563    
2025-01-06 21:45:02,460 - Epoch: [82][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.906250    Top5 10.546875    LR 0.001000    Time 0.055907    
2025-01-06 21:45:02,487 - Epoch: [82][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.282116    Top5 12.090680    LR 0.001000    Time 0.055823    
2025-01-06 21:45:04,183 - --- validate (epoch=82)-----------
2025-01-06 21:45:04,191 - 15217 samples (256 per mini-batch)
2025-01-06 21:45:13,174 - Epoch: [82][   10/   60]    Loss 3.044523    Top1 0.156250    Top5 0.312500    
2025-01-06 21:45:13,434 - Epoch: [82][   20/   60]    Loss 3.044524    Top1 0.195312    Top5 0.312500    
2025-01-06 21:45:13,683 - Epoch: [82][   30/   60]    Loss 3.044524    Top1 0.182292    Top5 0.312500    
2025-01-06 21:45:13,957 - Epoch: [82][   40/   60]    Loss 3.044524    Top1 0.175781    Top5 0.312500    
2025-01-06 21:45:14,226 - Epoch: [82][   50/   60]    Loss 3.044524    Top1 0.195312    Top5 0.312500    
2025-01-06 21:45:14,482 - Epoch: [82][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:45:16,001 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:45:16,001 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:45:16,469 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 82]
2025-01-06 21:45:16,469 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:45:16,503 - 

2025-01-06 21:45:16,503 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:45:25,620 - Epoch: [83][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.911583    
2025-01-06 21:45:25,934 - Epoch: [83][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.471495    
2025-01-06 21:45:26,259 - Epoch: [83][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.325087    
2025-01-06 21:45:26,572 - Epoch: [83][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.251648    
2025-01-06 21:45:26,876 - Epoch: [83][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.207400    
2025-01-06 21:45:27,207 - Epoch: [83][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.178351    
2025-01-06 21:45:27,515 - Epoch: [83][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.157276    
2025-01-06 21:45:27,822 - Epoch: [83][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.141450    
2025-01-06 21:45:28,145 - Epoch: [83][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.129305    
2025-01-06 21:45:28,475 - Epoch: [83][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.119672    
2025-01-06 21:45:28,786 - Epoch: [83][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.111616    
2025-01-06 21:45:29,083 - Epoch: [83][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.104794    
2025-01-06 21:45:29,394 - Epoch: [83][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.099127    
2025-01-06 21:45:29,700 - Epoch: [83][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094231    
2025-01-06 21:45:30,010 - Epoch: [83][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090015    
2025-01-06 21:45:30,318 - Epoch: [83][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086316    
2025-01-06 21:45:30,628 - Epoch: [83][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083061    
2025-01-06 21:45:30,947 - Epoch: [83][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080215    
2025-01-06 21:45:31,258 - Epoch: [83][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077630    
2025-01-06 21:45:31,567 - Epoch: [83][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075295    
2025-01-06 21:45:31,865 - Epoch: [83][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073130    
2025-01-06 21:45:32,174 - Epoch: [83][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071210    
2025-01-06 21:45:32,489 - Epoch: [83][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069481    
2025-01-06 21:45:32,799 - Epoch: [83][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067869    
2025-01-06 21:45:33,103 - Epoch: [83][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066372    
2025-01-06 21:45:33,417 - Epoch: [83][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065028    
2025-01-06 21:45:33,756 - Epoch: [83][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063868    
2025-01-06 21:45:34,058 - Epoch: [83][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062657    
2025-01-06 21:45:34,379 - Epoch: [83][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061597    
2025-01-06 21:45:34,688 - Epoch: [83][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060575    
2025-01-06 21:45:34,998 - Epoch: [83][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059614    
2025-01-06 21:45:35,305 - Epoch: [83][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058710    
2025-01-06 21:45:35,631 - Epoch: [83][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057913    
2025-01-06 21:45:35,955 - Epoch: [83][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.515625    Top5 10.937500    LR 0.001000    Time 0.057163    
2025-01-06 21:45:35,980 - Epoch: [83][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.274559    Top5 10.327456    LR 0.001000    Time 0.057063    
2025-01-06 21:45:37,741 - --- validate (epoch=83)-----------
2025-01-06 21:45:37,741 - 15217 samples (256 per mini-batch)
2025-01-06 21:45:46,579 - Epoch: [83][   10/   60]    Loss 3.044524    Top1 0.390625    Top5 0.546875    
2025-01-06 21:45:46,826 - Epoch: [83][   20/   60]    Loss 3.044524    Top1 0.253906    Top5 0.351563    
2025-01-06 21:45:47,098 - Epoch: [83][   30/   60]    Loss 3.044524    Top1 0.208333    Top5 0.338542    
2025-01-06 21:45:47,370 - Epoch: [83][   40/   60]    Loss 3.044524    Top1 0.195312    Top5 0.322266    
2025-01-06 21:45:47,627 - Epoch: [83][   50/   60]    Loss 3.044524    Top1 0.203125    Top5 0.328125    
2025-01-06 21:45:47,880 - Epoch: [83][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:45:49,441 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:45:49,441 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:45:49,905 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 83]
2025-01-06 21:45:49,905 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:45:49,942 - 

2025-01-06 21:45:49,942 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:45:58,634 - Epoch: [84][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.869057    
2025-01-06 21:45:58,952 - Epoch: [84][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.450461    
2025-01-06 21:45:59,280 - Epoch: [84][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.311215    
2025-01-06 21:45:59,588 - Epoch: [84][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.241133    
2025-01-06 21:45:59,911 - Epoch: [84][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.199354    
2025-01-06 21:46:00,228 - Epoch: [84][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.171419    
2025-01-06 21:46:00,544 - Epoch: [84][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.151407    
2025-01-06 21:46:00,860 - Epoch: [84][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.136437    
2025-01-06 21:46:01,182 - Epoch: [84][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.124855    
2025-01-06 21:46:01,498 - Epoch: [84][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.115524    
2025-01-06 21:46:01,813 - Epoch: [84][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.107886    
2025-01-06 21:46:02,149 - Epoch: [84][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.101698    
2025-01-06 21:46:02,448 - Epoch: [84][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.096177    
2025-01-06 21:46:02,782 - Epoch: [84][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091694    
2025-01-06 21:46:03,104 - Epoch: [84][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087726    
2025-01-06 21:46:03,417 - Epoch: [84][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084201    
2025-01-06 21:46:03,731 - Epoch: [84][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081080    
2025-01-06 21:46:04,038 - Epoch: [84][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078285    
2025-01-06 21:46:04,342 - Epoch: [84][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075762    
2025-01-06 21:46:04,659 - Epoch: [84][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073560    
2025-01-06 21:46:04,971 - Epoch: [84][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071541    
2025-01-06 21:46:05,281 - Epoch: [84][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069699    
2025-01-06 21:46:05,596 - Epoch: [84][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068038    
2025-01-06 21:46:05,906 - Epoch: [84][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066496    
2025-01-06 21:46:06,213 - Epoch: [84][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065064    
2025-01-06 21:46:06,527 - Epoch: [84][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063731    
2025-01-06 21:46:06,844 - Epoch: [84][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062545    
2025-01-06 21:46:07,168 - Epoch: [84][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061466    
2025-01-06 21:46:07,491 - Epoch: [84][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060462    
2025-01-06 21:46:07,817 - Epoch: [84][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059534    
2025-01-06 21:46:08,131 - Epoch: [84][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058626    
2025-01-06 21:46:08,434 - Epoch: [84][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057739    
2025-01-06 21:46:08,752 - Epoch: [84][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056952    
2025-01-06 21:46:09,085 - Epoch: [84][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.906250    Top5 13.671875    LR 0.001000    Time 0.056257    
2025-01-06 21:46:09,121 - Epoch: [84][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.526448    Top5 13.098237    LR 0.001000    Time 0.056168    
2025-01-06 21:46:10,824 - --- validate (epoch=84)-----------
2025-01-06 21:46:10,824 - 15217 samples (256 per mini-batch)
2025-01-06 21:46:19,527 - Epoch: [84][   10/   60]    Loss 3.044523    Top1 0.195312    Top5 0.429687    
2025-01-06 21:46:19,790 - Epoch: [84][   20/   60]    Loss 3.044523    Top1 0.234375    Top5 0.371094    
2025-01-06 21:46:20,068 - Epoch: [84][   30/   60]    Loss 3.044523    Top1 0.208333    Top5 0.338542    
2025-01-06 21:46:20,320 - Epoch: [84][   40/   60]    Loss 3.044523    Top1 0.185547    Top5 0.292969    
2025-01-06 21:46:20,590 - Epoch: [84][   50/   60]    Loss 3.044523    Top1 0.179688    Top5 0.296875    
2025-01-06 21:46:20,820 - Epoch: [84][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:46:22,308 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:46:22,308 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:46:23,008 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 84]
2025-01-06 21:46:23,008 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:46:23,039 - 

2025-01-06 21:46:23,039 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:46:31,527 - Epoch: [85][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.848686    
2025-01-06 21:46:31,834 - Epoch: [85][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.439718    
2025-01-06 21:46:32,140 - Epoch: [85][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.303331    
2025-01-06 21:46:32,466 - Epoch: [85][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.235657    
2025-01-06 21:46:32,788 - Epoch: [85][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.194961    
2025-01-06 21:46:33,100 - Epoch: [85][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.167560    
2025-01-06 21:46:33,409 - Epoch: [85][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.148039    
2025-01-06 21:46:33,739 - Epoch: [85][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.133650    
2025-01-06 21:46:34,037 - Epoch: [85][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.122120    
2025-01-06 21:46:34,368 - Epoch: [85][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.113119    
2025-01-06 21:46:34,678 - Epoch: [85][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.105646    
2025-01-06 21:46:34,994 - Epoch: [85][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.099408    
2025-01-06 21:46:35,306 - Epoch: [85][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094165    
2025-01-06 21:46:35,638 - Epoch: [85][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089763    
2025-01-06 21:46:35,951 - Epoch: [85][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085865    
2025-01-06 21:46:36,253 - Epoch: [85][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082389    
2025-01-06 21:46:36,575 - Epoch: [85][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079435    
2025-01-06 21:46:36,888 - Epoch: [85][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076761    
2025-01-06 21:46:37,184 - Epoch: [85][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074279    
2025-01-06 21:46:37,498 - Epoch: [85][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072134    
2025-01-06 21:46:37,815 - Epoch: [85][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070160    
2025-01-06 21:46:38,133 - Epoch: [85][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068416    
2025-01-06 21:46:38,450 - Epoch: [85][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066821    
2025-01-06 21:46:38,764 - Epoch: [85][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065346    
2025-01-06 21:46:39,074 - Epoch: [85][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063971    
2025-01-06 21:46:39,426 - Epoch: [85][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062863    
2025-01-06 21:46:39,757 - Epoch: [85][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061764    
2025-01-06 21:46:40,080 - Epoch: [85][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060709    
2025-01-06 21:46:40,390 - Epoch: [85][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059686    
2025-01-06 21:46:40,698 - Epoch: [85][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058724    
2025-01-06 21:46:41,033 - Epoch: [85][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057909    
2025-01-06 21:46:41,355 - Epoch: [85][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057103    
2025-01-06 21:46:41,711 - Epoch: [85][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056452    
2025-01-06 21:46:42,077 - Epoch: [85][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 2.734375    Top5 11.328125    LR 0.001000    Time 0.055840    
2025-01-06 21:46:42,105 - Epoch: [85][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 2.770781    Top5 11.083123    LR 0.001000    Time 0.055760    
2025-01-06 21:46:43,967 - --- validate (epoch=85)-----------
2025-01-06 21:46:43,969 - 15217 samples (256 per mini-batch)
2025-01-06 21:46:52,950 - Epoch: [85][   10/   60]    Loss 3.044524    Top1 0.234375    Top5 0.390625    
2025-01-06 21:46:53,220 - Epoch: [85][   20/   60]    Loss 3.044523    Top1 0.214844    Top5 0.332031    
2025-01-06 21:46:53,484 - Epoch: [85][   30/   60]    Loss 3.044523    Top1 0.182292    Top5 0.312500    
2025-01-06 21:46:53,749 - Epoch: [85][   40/   60]    Loss 3.044523    Top1 0.205078    Top5 0.341797    
2025-01-06 21:46:54,011 - Epoch: [85][   50/   60]    Loss 3.044523    Top1 0.203125    Top5 0.320312    
2025-01-06 21:46:54,263 - Epoch: [85][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:46:55,774 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:46:55,774 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:46:56,248 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 85]
2025-01-06 21:46:56,254 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:46:56,290 - 

2025-01-06 21:46:56,290 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:47:05,209 - Epoch: [86][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.891923    
2025-01-06 21:47:05,519 - Epoch: [86][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.461447    
2025-01-06 21:47:05,870 - Epoch: [86][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.319343    
2025-01-06 21:47:06,193 - Epoch: [86][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.247582    
2025-01-06 21:47:06,528 - Epoch: [86][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.204753    
2025-01-06 21:47:06,858 - Epoch: [86][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.176135    
2025-01-06 21:47:07,162 - Epoch: [86][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.155314    
2025-01-06 21:47:07,487 - Epoch: [86][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.139964    
2025-01-06 21:47:07,813 - Epoch: [86][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.128028    
2025-01-06 21:47:08,127 - Epoch: [86][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.118364    
2025-01-06 21:47:08,440 - Epoch: [86][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.110453    
2025-01-06 21:47:08,750 - Epoch: [86][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.103829    
2025-01-06 21:47:09,067 - Epoch: [86][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098286    
2025-01-06 21:47:09,381 - Epoch: [86][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093504    
2025-01-06 21:47:09,708 - Epoch: [86][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089451    
2025-01-06 21:47:10,014 - Epoch: [86][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085776    
2025-01-06 21:47:10,325 - Epoch: [86][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082560    
2025-01-06 21:47:10,645 - Epoch: [86][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079749    
2025-01-06 21:47:10,951 - Epoch: [86][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077162    
2025-01-06 21:47:11,268 - Epoch: [86][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074837    
2025-01-06 21:47:11,607 - Epoch: [86][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072889    
2025-01-06 21:47:11,932 - Epoch: [86][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071045    
2025-01-06 21:47:12,250 - Epoch: [86][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069339    
2025-01-06 21:47:12,553 - Epoch: [86][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067712    
2025-01-06 21:47:12,900 - Epoch: [86][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066386    
2025-01-06 21:47:13,215 - Epoch: [86][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065044    
2025-01-06 21:47:13,525 - Epoch: [86][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063783    
2025-01-06 21:47:13,843 - Epoch: [86][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062642    
2025-01-06 21:47:14,158 - Epoch: [86][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061568    
2025-01-06 21:47:14,470 - Epoch: [86][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060554    
2025-01-06 21:47:14,798 - Epoch: [86][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059660    
2025-01-06 21:47:15,103 - Epoch: [86][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058749    
2025-01-06 21:47:15,407 - Epoch: [86][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057888    
2025-01-06 21:47:15,741 - Epoch: [86][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 1.953125    Top5 13.671875    LR 0.001000    Time 0.057169    
2025-01-06 21:47:15,773 - Epoch: [86][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 2.015113    Top5 13.098237    LR 0.001000    Time 0.057096    
2025-01-06 21:47:17,418 - --- validate (epoch=86)-----------
2025-01-06 21:47:17,418 - 15217 samples (256 per mini-batch)
2025-01-06 21:47:26,254 - Epoch: [86][   10/   60]    Loss 3.044524    Top1 0.312500    Top5 0.468750    
2025-01-06 21:47:26,541 - Epoch: [86][   20/   60]    Loss 3.044524    Top1 0.214844    Top5 0.312500    
2025-01-06 21:47:26,803 - Epoch: [86][   30/   60]    Loss 3.044524    Top1 0.221354    Top5 0.338542    
2025-01-06 21:47:27,068 - Epoch: [86][   40/   60]    Loss 3.044524    Top1 0.185547    Top5 0.332031    
2025-01-06 21:47:27,332 - Epoch: [86][   50/   60]    Loss 3.044524    Top1 0.187500    Top5 0.320312    
2025-01-06 21:47:27,572 - Epoch: [86][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:47:29,084 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:47:29,094 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:47:29,566 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 86]
2025-01-06 21:47:29,566 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:47:29,614 - 

2025-01-06 21:47:29,615 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:47:38,193 - Epoch: [87][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.857686    
2025-01-06 21:47:38,506 - Epoch: [87][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.444524    
2025-01-06 21:47:38,825 - Epoch: [87][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.306961    
2025-01-06 21:47:39,130 - Epoch: [87][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.237850    
2025-01-06 21:47:39,469 - Epoch: [87][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.197057    
2025-01-06 21:47:39,794 - Epoch: [87][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.169641    
2025-01-06 21:47:40,118 - Epoch: [87][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.150038    
2025-01-06 21:47:40,425 - Epoch: [87][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.135117    
2025-01-06 21:47:40,738 - Epoch: [87][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.123585    
2025-01-06 21:47:41,047 - Epoch: [87][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.114307    
2025-01-06 21:47:41,355 - Epoch: [87][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.106719    
2025-01-06 21:47:41,687 - Epoch: [87][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100596    
2025-01-06 21:47:41,992 - Epoch: [87][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095200    
2025-01-06 21:47:42,304 - Epoch: [87][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090629    
2025-01-06 21:47:42,610 - Epoch: [87][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086628    
2025-01-06 21:47:42,924 - Epoch: [87][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083178    
2025-01-06 21:47:43,239 - Epoch: [87][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080135    
2025-01-06 21:47:43,564 - Epoch: [87][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077490    
2025-01-06 21:47:43,864 - Epoch: [87][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074993    
2025-01-06 21:47:44,171 - Epoch: [87][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072777    
2025-01-06 21:47:44,497 - Epoch: [87][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070861    
2025-01-06 21:47:44,811 - Epoch: [87][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069071    
2025-01-06 21:47:45,134 - Epoch: [87][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067469    
2025-01-06 21:47:45,441 - Epoch: [87][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065940    
2025-01-06 21:47:45,754 - Epoch: [87][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064553    
2025-01-06 21:47:46,077 - Epoch: [87][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063311    
2025-01-06 21:47:46,400 - Epoch: [87][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062164    
2025-01-06 21:47:46,705 - Epoch: [87][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061031    
2025-01-06 21:47:47,017 - Epoch: [87][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060005    
2025-01-06 21:47:47,333 - Epoch: [87][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059057    
2025-01-06 21:47:47,637 - Epoch: [87][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058134    
2025-01-06 21:47:47,938 - Epoch: [87][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057258    
2025-01-06 21:47:48,243 - Epoch: [87][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056445    
2025-01-06 21:47:48,579 - Epoch: [87][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.687500    Top5 10.937500    LR 0.001000    Time 0.055774    
2025-01-06 21:47:48,606 - Epoch: [87][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.282116    Top5 11.838791    LR 0.001000    Time 0.055691    
2025-01-06 21:47:50,368 - --- validate (epoch=87)-----------
2025-01-06 21:47:50,368 - 15217 samples (256 per mini-batch)
2025-01-06 21:47:59,078 - Epoch: [87][   10/   60]    Loss 3.044524    Top1 0.234375    Top5 0.312500    
2025-01-06 21:47:59,339 - Epoch: [87][   20/   60]    Loss 3.044524    Top1 0.253906    Top5 0.371094    
2025-01-06 21:47:59,603 - Epoch: [87][   30/   60]    Loss 3.044524    Top1 0.195312    Top5 0.299479    
2025-01-06 21:47:59,867 - Epoch: [87][   40/   60]    Loss 3.044524    Top1 0.195312    Top5 0.302734    
2025-01-06 21:48:00,134 - Epoch: [87][   50/   60]    Loss 3.044524    Top1 0.210937    Top5 0.312500    
2025-01-06 21:48:00,385 - Epoch: [87][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:48:01,925 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:48:01,927 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:48:02,394 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 87]
2025-01-06 21:48:02,394 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:48:02,427 - 

2025-01-06 21:48:02,430 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:48:10,969 - Epoch: [88][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.853837    
2025-01-06 21:48:11,260 - Epoch: [88][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.441403    
2025-01-06 21:48:11,589 - Epoch: [88][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.304377    
2025-01-06 21:48:11,912 - Epoch: [88][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.236368    
2025-01-06 21:48:12,218 - Epoch: [88][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.195214    
2025-01-06 21:48:12,539 - Epoch: [88][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.168025    
2025-01-06 21:48:12,855 - Epoch: [88][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.148530    
2025-01-06 21:48:13,170 - Epoch: [88][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.133901    
2025-01-06 21:48:13,509 - Epoch: [88][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.122789    
2025-01-06 21:48:13,836 - Epoch: [88][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.113785    
2025-01-06 21:48:14,150 - Epoch: [88][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.106290    
2025-01-06 21:48:14,455 - Epoch: [88][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.099969    
2025-01-06 21:48:14,775 - Epoch: [88][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094742    
2025-01-06 21:48:15,082 - Epoch: [88][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090170    
2025-01-06 21:48:15,385 - Epoch: [88][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086178    
2025-01-06 21:48:15,720 - Epoch: [88][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082883    
2025-01-06 21:48:16,039 - Epoch: [88][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079884    
2025-01-06 21:48:16,345 - Epoch: [88][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077145    
2025-01-06 21:48:16,677 - Epoch: [88][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074831    
2025-01-06 21:48:17,001 - Epoch: [88][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072703    
2025-01-06 21:48:17,326 - Epoch: [88][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070789    
2025-01-06 21:48:17,630 - Epoch: [88][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068953    
2025-01-06 21:48:17,949 - Epoch: [88][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067341    
2025-01-06 21:48:18,263 - Epoch: [88][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065843    
2025-01-06 21:48:18,590 - Epoch: [88][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064518    
2025-01-06 21:48:18,893 - Epoch: [88][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063200    
2025-01-06 21:48:19,221 - Epoch: [88][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062037    
2025-01-06 21:48:19,522 - Epoch: [88][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060897    
2025-01-06 21:48:19,838 - Epoch: [88][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059888    
2025-01-06 21:48:20,153 - Epoch: [88][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058942    
2025-01-06 21:48:20,452 - Epoch: [88][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058004    
2025-01-06 21:48:20,778 - Epoch: [88][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057209    
2025-01-06 21:48:21,095 - Epoch: [88][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056438    
2025-01-06 21:48:21,450 - Epoch: [88][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.296875    Top5 12.500000    LR 0.001000    Time 0.055820    
2025-01-06 21:48:21,496 - Epoch: [88][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.037783    Top5 14.357683    LR 0.001000    Time 0.055791    
2025-01-06 21:48:23,107 - --- validate (epoch=88)-----------
2025-01-06 21:48:23,107 - 15217 samples (256 per mini-batch)
2025-01-06 21:48:32,154 - Epoch: [88][   10/   60]    Loss 3.044524    Top1 0.273437    Top5 0.312500    
2025-01-06 21:48:32,426 - Epoch: [88][   20/   60]    Loss 3.044524    Top1 0.253906    Top5 0.312500    
2025-01-06 21:48:32,688 - Epoch: [88][   30/   60]    Loss 3.044524    Top1 0.234375    Top5 0.299479    
2025-01-06 21:48:32,945 - Epoch: [88][   40/   60]    Loss 3.044524    Top1 0.214844    Top5 0.341797    
2025-01-06 21:48:33,199 - Epoch: [88][   50/   60]    Loss 3.044524    Top1 0.210937    Top5 0.320312    
2025-01-06 21:48:33,448 - Epoch: [88][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:48:34,942 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:48:34,942 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:48:35,405 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 88]
2025-01-06 21:48:35,407 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:48:35,439 - 

2025-01-06 21:48:35,439 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:48:44,103 - Epoch: [89][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.866222    
2025-01-06 21:48:44,411 - Epoch: [89][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.448509    
2025-01-06 21:48:44,743 - Epoch: [89][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.310056    
2025-01-06 21:48:45,038 - Epoch: [89][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.239917    
2025-01-06 21:48:45,359 - Epoch: [89][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.198368    
2025-01-06 21:48:45,682 - Epoch: [89][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.170682    
2025-01-06 21:48:45,988 - Epoch: [89][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.150670    
2025-01-06 21:48:46,307 - Epoch: [89][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.135822    
2025-01-06 21:48:46,609 - Epoch: [89][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.124086    
2025-01-06 21:48:46,913 - Epoch: [89][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.114719    
2025-01-06 21:48:47,215 - Epoch: [89][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.107033    
2025-01-06 21:48:47,529 - Epoch: [89][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100736    
2025-01-06 21:48:47,842 - Epoch: [89][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095393    
2025-01-06 21:48:48,161 - Epoch: [89][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090855    
2025-01-06 21:48:48,472 - Epoch: [89][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086876    
2025-01-06 21:48:48,787 - Epoch: [89][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083412    
2025-01-06 21:48:49,096 - Epoch: [89][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080265    
2025-01-06 21:48:49,414 - Epoch: [89][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077574    
2025-01-06 21:48:49,730 - Epoch: [89][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075153    
2025-01-06 21:48:50,043 - Epoch: [89][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072958    
2025-01-06 21:48:50,355 - Epoch: [89][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070924    
2025-01-06 21:48:50,717 - Epoch: [89][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069347    
2025-01-06 21:48:51,012 - Epoch: [89][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067610    
2025-01-06 21:48:51,337 - Epoch: [89][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066148    
2025-01-06 21:48:51,643 - Epoch: [89][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064688    
2025-01-06 21:48:51,960 - Epoch: [89][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063378    
2025-01-06 21:48:52,276 - Epoch: [89][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062202    
2025-01-06 21:48:52,575 - Epoch: [89][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061047    
2025-01-06 21:48:52,886 - Epoch: [89][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060016    
2025-01-06 21:48:53,209 - Epoch: [89][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059092    
2025-01-06 21:48:53,527 - Epoch: [89][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058211    
2025-01-06 21:48:53,840 - Epoch: [89][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057371    
2025-01-06 21:48:54,171 - Epoch: [89][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056636    
2025-01-06 21:48:54,509 - Epoch: [89][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 1.953125    Top5 14.453125    LR 0.001000    Time 0.055962    
2025-01-06 21:48:54,540 - Epoch: [89][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.778338    Top5 15.113350    LR 0.001000    Time 0.055891    
2025-01-06 21:48:56,217 - --- validate (epoch=89)-----------
2025-01-06 21:48:56,227 - 15217 samples (256 per mini-batch)
2025-01-06 21:49:05,003 - Epoch: [89][   10/   60]    Loss 3.044523    Top1 0.273437    Top5 0.390625    
2025-01-06 21:49:05,278 - Epoch: [89][   20/   60]    Loss 3.044523    Top1 0.234375    Top5 0.312500    
2025-01-06 21:49:05,548 - Epoch: [89][   30/   60]    Loss 3.044523    Top1 0.234375    Top5 0.325521    
2025-01-06 21:49:05,801 - Epoch: [89][   40/   60]    Loss 3.044523    Top1 0.234375    Top5 0.371094    
2025-01-06 21:49:06,059 - Epoch: [89][   50/   60]    Loss 3.044523    Top1 0.226563    Top5 0.351563    
2025-01-06 21:49:06,294 - Epoch: [89][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:49:07,826 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:49:07,837 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:49:08,303 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 89]
2025-01-06 21:49:08,303 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:49:08,334 - 

2025-01-06 21:49:08,335 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:49:16,760 - Epoch: [90][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.842493    
2025-01-06 21:49:17,087 - Epoch: [90][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.437612    
2025-01-06 21:49:17,411 - Epoch: [90][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.302207    
2025-01-06 21:49:17,718 - Epoch: [90][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.234318    
2025-01-06 21:49:18,038 - Epoch: [90][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.193848    
2025-01-06 21:49:18,357 - Epoch: [90][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.166858    
2025-01-06 21:49:18,675 - Epoch: [90][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.147572    
2025-01-06 21:49:18,981 - Epoch: [90][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.132944    
2025-01-06 21:49:19,291 - Epoch: [90][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.121620    
2025-01-06 21:49:19,597 - Epoch: [90][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.112521    
2025-01-06 21:49:19,900 - Epoch: [90][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.105040    
2025-01-06 21:49:20,222 - Epoch: [90][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098977    
2025-01-06 21:49:20,548 - Epoch: [90][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093864    
2025-01-06 21:49:20,876 - Epoch: [90][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089503    
2025-01-06 21:49:21,176 - Epoch: [90][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085538    
2025-01-06 21:49:21,490 - Epoch: [90][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082156    
2025-01-06 21:49:21,816 - Epoch: [90][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079228    
2025-01-06 21:49:22,131 - Epoch: [90][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076569    
2025-01-06 21:49:22,444 - Epoch: [90][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074190    
2025-01-06 21:49:22,777 - Epoch: [90][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072144    
2025-01-06 21:49:23,090 - Epoch: [90][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070152    
2025-01-06 21:49:23,411 - Epoch: [90][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068421    
2025-01-06 21:49:23,729 - Epoch: [90][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066831    
2025-01-06 21:49:24,040 - Epoch: [90][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065340    
2025-01-06 21:49:24,346 - Epoch: [90][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063952    
2025-01-06 21:49:24,670 - Epoch: [90][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062737    
2025-01-06 21:49:24,976 - Epoch: [90][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061545    
2025-01-06 21:49:25,299 - Epoch: [90][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060503    
2025-01-06 21:49:25,620 - Epoch: [90][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059524    
2025-01-06 21:49:25,926 - Epoch: [90][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058559    
2025-01-06 21:49:26,230 - Epoch: [90][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057631    
2025-01-06 21:49:26,543 - Epoch: [90][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056810    
2025-01-06 21:49:26,866 - Epoch: [90][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056065    
2025-01-06 21:49:27,242 - Epoch: [90][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.468750    Top5 13.281250    LR 0.001000    Time 0.055523    
2025-01-06 21:49:27,276 - Epoch: [90][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.282116    Top5 12.594458    LR 0.001000    Time 0.055458    
2025-01-06 21:49:29,028 - --- validate (epoch=90)-----------
2025-01-06 21:49:29,028 - 15217 samples (256 per mini-batch)
2025-01-06 21:49:37,872 - Epoch: [90][   10/   60]    Loss 3.044523    Top1 0.273437    Top5 0.390625    
2025-01-06 21:49:38,134 - Epoch: [90][   20/   60]    Loss 3.044523    Top1 0.234375    Top5 0.371094    
2025-01-06 21:49:38,396 - Epoch: [90][   30/   60]    Loss 3.044523    Top1 0.221354    Top5 0.351563    
2025-01-06 21:49:38,652 - Epoch: [90][   40/   60]    Loss 3.044524    Top1 0.195312    Top5 0.302734    
2025-01-06 21:49:38,908 - Epoch: [90][   50/   60]    Loss 3.044524    Top1 0.203125    Top5 0.328125    
2025-01-06 21:49:39,150 - Epoch: [90][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:49:40,659 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:49:40,659 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:49:41,359 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 90]
2025-01-06 21:49:41,359 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:49:41,400 - 

2025-01-06 21:49:41,401 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:49:50,346 - Epoch: [91][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.894296    
2025-01-06 21:49:50,669 - Epoch: [91][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.463339    
2025-01-06 21:49:50,993 - Epoch: [91][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.319672    
2025-01-06 21:49:51,306 - Epoch: [91][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.247580    
2025-01-06 21:49:51,628 - Epoch: [91][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.204511    
2025-01-06 21:49:51,946 - Epoch: [91][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.175717    
2025-01-06 21:49:52,267 - Epoch: [91][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.155063    
2025-01-06 21:49:52,593 - Epoch: [91][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.139759    
2025-01-06 21:49:52,896 - Epoch: [91][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.127595    
2025-01-06 21:49:53,218 - Epoch: [91][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.118055    
2025-01-06 21:49:53,541 - Epoch: [91][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.110257    
2025-01-06 21:49:53,849 - Epoch: [91][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.103636    
2025-01-06 21:49:54,164 - Epoch: [91][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098086    
2025-01-06 21:49:54,489 - Epoch: [91][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093402    
2025-01-06 21:49:54,791 - Epoch: [91][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089187    
2025-01-06 21:49:55,104 - Epoch: [91][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085510    
2025-01-06 21:49:55,418 - Epoch: [91][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082327    
2025-01-06 21:49:55,725 - Epoch: [91][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079451    
2025-01-06 21:49:56,025 - Epoch: [91][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076849    
2025-01-06 21:49:56,325 - Epoch: [91][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074506    
2025-01-06 21:49:56,642 - Epoch: [91][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072466    
2025-01-06 21:49:56,943 - Epoch: [91][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070540    
2025-01-06 21:49:57,253 - Epoch: [91][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068822    
2025-01-06 21:49:57,553 - Epoch: [91][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067203    
2025-01-06 21:49:57,856 - Epoch: [91][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065728    
2025-01-06 21:49:58,159 - Epoch: [91][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064367    
2025-01-06 21:49:58,463 - Epoch: [91][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063109    
2025-01-06 21:49:58,770 - Epoch: [91][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061949    
2025-01-06 21:49:59,065 - Epoch: [91][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060831    
2025-01-06 21:49:59,377 - Epoch: [91][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059808    
2025-01-06 21:49:59,681 - Epoch: [91][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058860    
2025-01-06 21:49:59,996 - Epoch: [91][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058004    
2025-01-06 21:50:00,364 - Epoch: [91][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057362    
2025-01-06 21:50:00,717 - Epoch: [91][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.859375    Top5 14.453125    LR 0.001000    Time 0.056681    
2025-01-06 21:50:00,746 - Epoch: [91][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.541562    Top5 13.602015    LR 0.001000    Time 0.056601    
2025-01-06 21:50:02,553 - --- validate (epoch=91)-----------
2025-01-06 21:50:02,553 - 15217 samples (256 per mini-batch)
2025-01-06 21:50:11,460 - Epoch: [91][   10/   60]    Loss 3.044523    Top1 0.273437    Top5 0.390625    
2025-01-06 21:50:11,746 - Epoch: [91][   20/   60]    Loss 3.044524    Top1 0.273437    Top5 0.351563    
2025-01-06 21:50:12,013 - Epoch: [91][   30/   60]    Loss 3.044524    Top1 0.273437    Top5 0.390625    
2025-01-06 21:50:12,270 - Epoch: [91][   40/   60]    Loss 3.044523    Top1 0.234375    Top5 0.371094    
2025-01-06 21:50:12,513 - Epoch: [91][   50/   60]    Loss 3.044523    Top1 0.218750    Top5 0.351563    
2025-01-06 21:50:12,765 - Epoch: [91][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:50:14,270 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:50:14,270 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:50:14,732 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 91]
2025-01-06 21:50:14,738 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:50:14,771 - 

2025-01-06 21:50:14,772 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:50:23,738 - Epoch: [92][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.896617    
2025-01-06 21:50:24,066 - Epoch: [92][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.464699    
2025-01-06 21:50:24,410 - Epoch: [92][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.321270    
2025-01-06 21:50:24,725 - Epoch: [92][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.248828    
2025-01-06 21:50:25,048 - Epoch: [92][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.205525    
2025-01-06 21:50:25,362 - Epoch: [92][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.176510    
2025-01-06 21:50:25,671 - Epoch: [92][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.155713    
2025-01-06 21:50:25,989 - Epoch: [92][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.140215    
2025-01-06 21:50:26,291 - Epoch: [92][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.127994    
2025-01-06 21:50:26,596 - Epoch: [92][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.118240    
2025-01-06 21:50:26,928 - Epoch: [92][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.110518    
2025-01-06 21:50:27,238 - Epoch: [92][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.103890    
2025-01-06 21:50:27,543 - Epoch: [92][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098244    
2025-01-06 21:50:27,846 - Epoch: [92][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093386    
2025-01-06 21:50:28,170 - Epoch: [92][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089257    
2025-01-06 21:50:28,477 - Epoch: [92][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.085587    
2025-01-06 21:50:28,782 - Epoch: [92][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082343    
2025-01-06 21:50:29,090 - Epoch: [92][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079478    
2025-01-06 21:50:29,394 - Epoch: [92][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076895    
2025-01-06 21:50:29,692 - Epoch: [92][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074537    
2025-01-06 21:50:30,005 - Epoch: [92][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072477    
2025-01-06 21:50:30,320 - Epoch: [92][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070611    
2025-01-06 21:50:30,638 - Epoch: [92][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068926    
2025-01-06 21:50:30,958 - Epoch: [92][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067385    
2025-01-06 21:50:31,261 - Epoch: [92][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065894    
2025-01-06 21:50:31,566 - Epoch: [92][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064532    
2025-01-06 21:50:31,892 - Epoch: [92][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063351    
2025-01-06 21:50:32,213 - Epoch: [92][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062233    
2025-01-06 21:50:32,514 - Epoch: [92][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061127    
2025-01-06 21:50:32,821 - Epoch: [92][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060112    
2025-01-06 21:50:33,128 - Epoch: [92][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059164    
2025-01-06 21:50:33,435 - Epoch: [92][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058275    
2025-01-06 21:50:33,757 - Epoch: [92][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057483    
2025-01-06 21:50:34,100 - Epoch: [92][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.687500    Top5 14.453125    LR 0.001000    Time 0.056801    
2025-01-06 21:50:34,137 - Epoch: [92][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.778338    Top5 15.617128    LR 0.001000    Time 0.056744    
2025-01-06 21:50:36,331 - --- validate (epoch=92)-----------
2025-01-06 21:50:36,331 - 15217 samples (256 per mini-batch)
2025-01-06 21:50:45,047 - Epoch: [92][   10/   60]    Loss 3.044524    Top1 0.234375    Top5 0.273437    
2025-01-06 21:50:45,310 - Epoch: [92][   20/   60]    Loss 3.044524    Top1 0.175781    Top5 0.273437    
2025-01-06 21:50:45,565 - Epoch: [92][   30/   60]    Loss 3.044524    Top1 0.195312    Top5 0.312500    
2025-01-06 21:50:45,824 - Epoch: [92][   40/   60]    Loss 3.044524    Top1 0.205078    Top5 0.312500    
2025-01-06 21:50:46,096 - Epoch: [92][   50/   60]    Loss 3.044524    Top1 0.210937    Top5 0.335938    
2025-01-06 21:50:46,335 - Epoch: [92][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:50:47,839 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:50:47,839 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:50:48,342 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 92]
2025-01-06 21:50:48,342 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:50:48,380 - 

2025-01-06 21:50:48,380 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:50:56,989 - Epoch: [93][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.860930    
2025-01-06 21:50:57,329 - Epoch: [93][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.447469    
2025-01-06 21:50:57,644 - Epoch: [93][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.308813    
2025-01-06 21:50:57,968 - Epoch: [93][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.239721    
2025-01-06 21:50:58,290 - Epoch: [93][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.198214    
2025-01-06 21:50:58,615 - Epoch: [93][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.170582    
2025-01-06 21:50:58,937 - Epoch: [93][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.150819    
2025-01-06 21:50:59,232 - Epoch: [93][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.135658    
2025-01-06 21:50:59,537 - Epoch: [93][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.123853    
2025-01-06 21:50:59,840 - Epoch: [93][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.114498    
2025-01-06 21:51:00,154 - Epoch: [93][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.106942    
2025-01-06 21:51:00,490 - Epoch: [93][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100836    
2025-01-06 21:51:00,803 - Epoch: [93][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095486    
2025-01-06 21:51:01,125 - Epoch: [93][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090963    
2025-01-06 21:51:01,451 - Epoch: [93][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087073    
2025-01-06 21:51:01,751 - Epoch: [93][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083497    
2025-01-06 21:51:02,074 - Epoch: [93][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080482    
2025-01-06 21:51:02,384 - Epoch: [93][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077731    
2025-01-06 21:51:02,698 - Epoch: [93][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075241    
2025-01-06 21:51:03,011 - Epoch: [93][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073047    
2025-01-06 21:51:03,325 - Epoch: [93][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071016    
2025-01-06 21:51:03,647 - Epoch: [93][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069241    
2025-01-06 21:51:03,951 - Epoch: [93][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067545    
2025-01-06 21:51:04,271 - Epoch: [93][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066067    
2025-01-06 21:51:04,588 - Epoch: [93][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064687    
2025-01-06 21:51:04,914 - Epoch: [93][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063452    
2025-01-06 21:51:05,227 - Epoch: [93][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062264    
2025-01-06 21:51:05,543 - Epoch: [93][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061166    
2025-01-06 21:51:05,888 - Epoch: [93][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060247    
2025-01-06 21:51:06,220 - Epoch: [93][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059346    
2025-01-06 21:51:06,535 - Epoch: [93][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058447    
2025-01-06 21:51:06,849 - Epoch: [93][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057604    
2025-01-06 21:51:07,195 - Epoch: [93][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056907    
2025-01-06 21:51:07,530 - Epoch: [93][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.296875    Top5 10.156250    LR 0.001000    Time 0.056216    
2025-01-06 21:51:07,562 - Epoch: [93][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.282116    Top5 10.075567    LR 0.001000    Time 0.056147    
2025-01-06 21:51:09,655 - --- validate (epoch=93)-----------
2025-01-06 21:51:09,655 - 15217 samples (256 per mini-batch)
2025-01-06 21:51:18,454 - Epoch: [93][   10/   60]    Loss 3.044524    Top1 0.156250    Top5 0.195312    
2025-01-06 21:51:18,718 - Epoch: [93][   20/   60]    Loss 3.044524    Top1 0.214844    Top5 0.312500    
2025-01-06 21:51:18,984 - Epoch: [93][   30/   60]    Loss 3.044524    Top1 0.221354    Top5 0.312500    
2025-01-06 21:51:19,267 - Epoch: [93][   40/   60]    Loss 3.044524    Top1 0.195312    Top5 0.292969    
2025-01-06 21:51:19,531 - Epoch: [93][   50/   60]    Loss 3.044524    Top1 0.218750    Top5 0.335938    
2025-01-06 21:51:19,790 - Epoch: [93][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:51:21,311 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:51:21,311 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:51:21,808 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 93]
2025-01-06 21:51:21,823 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:51:21,852 - 

2025-01-06 21:51:21,852 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:51:30,428 - Epoch: [94][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.857279    
2025-01-06 21:51:30,791 - Epoch: [94][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.446762    
2025-01-06 21:51:31,101 - Epoch: [94][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.308174    
2025-01-06 21:51:31,429 - Epoch: [94][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.239326    
2025-01-06 21:51:31,750 - Epoch: [94][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.197885    
2025-01-06 21:51:32,067 - Epoch: [94][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.170190    
2025-01-06 21:51:32,391 - Epoch: [94][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.150508    
2025-01-06 21:51:32,701 - Epoch: [94][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.135566    
2025-01-06 21:51:33,038 - Epoch: [94][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.124248    
2025-01-06 21:51:33,347 - Epoch: [94][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.114919    
2025-01-06 21:51:33,653 - Epoch: [94][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.107254    
2025-01-06 21:51:33,979 - Epoch: [94][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.101028    
2025-01-06 21:51:34,290 - Epoch: [94][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095638    
2025-01-06 21:51:34,603 - Epoch: [94][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091039    
2025-01-06 21:51:34,921 - Epoch: [94][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087089    
2025-01-06 21:51:35,246 - Epoch: [94][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083677    
2025-01-06 21:51:35,551 - Epoch: [94][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080552    
2025-01-06 21:51:35,892 - Epoch: [94][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077967    
2025-01-06 21:51:36,220 - Epoch: [94][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075591    
2025-01-06 21:51:36,541 - Epoch: [94][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073405    
2025-01-06 21:51:36,847 - Epoch: [94][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071366    
2025-01-06 21:51:37,171 - Epoch: [94][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069596    
2025-01-06 21:51:37,494 - Epoch: [94][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067974    
2025-01-06 21:51:37,818 - Epoch: [94][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066492    
2025-01-06 21:51:38,129 - Epoch: [94][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065076    
2025-01-06 21:51:38,454 - Epoch: [94][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063825    
2025-01-06 21:51:38,765 - Epoch: [94][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062612    
2025-01-06 21:51:39,087 - Epoch: [94][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061527    
2025-01-06 21:51:39,400 - Epoch: [94][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060485    
2025-01-06 21:51:39,710 - Epoch: [94][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059501    
2025-01-06 21:51:40,036 - Epoch: [94][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058635    
2025-01-06 21:51:40,366 - Epoch: [94][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057832    
2025-01-06 21:51:40,676 - Epoch: [94][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057021    
2025-01-06 21:51:41,027 - Epoch: [94][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.125000    Top5 10.937500    LR 0.001000    Time 0.056376    
2025-01-06 21:51:41,051 - Epoch: [94][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 2.770781    Top5 11.586902    LR 0.001000    Time 0.056280    
2025-01-06 21:51:42,748 - --- validate (epoch=94)-----------
2025-01-06 21:51:42,748 - 15217 samples (256 per mini-batch)
2025-01-06 21:51:51,844 - Epoch: [94][   10/   60]    Loss 3.044524    Top1 0.273437    Top5 0.351563    
2025-01-06 21:51:52,092 - Epoch: [94][   20/   60]    Loss 3.044524    Top1 0.175781    Top5 0.292969    
2025-01-06 21:51:52,362 - Epoch: [94][   30/   60]    Loss 3.044524    Top1 0.182292    Top5 0.299479    
2025-01-06 21:51:52,630 - Epoch: [94][   40/   60]    Loss 3.044524    Top1 0.185547    Top5 0.292969    
2025-01-06 21:51:52,880 - Epoch: [94][   50/   60]    Loss 3.044524    Top1 0.195312    Top5 0.304688    
2025-01-06 21:51:53,130 - Epoch: [94][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:51:54,607 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:51:54,607 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:51:55,081 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 94]
2025-01-06 21:51:55,081 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:51:55,115 - 

2025-01-06 21:51:55,116 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:52:04,117 - Epoch: [95][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.899950    
2025-01-06 21:52:04,445 - Epoch: [95][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.466388    
2025-01-06 21:52:04,771 - Epoch: [95][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.321731    
2025-01-06 21:52:05,073 - Epoch: [95][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.248832    
2025-01-06 21:52:05,388 - Epoch: [95][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.205157    
2025-01-06 21:52:05,695 - Epoch: [95][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.176083    
2025-01-06 21:52:06,007 - Epoch: [95][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.155397    
2025-01-06 21:52:06,353 - Epoch: [95][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.140288    
2025-01-06 21:52:06,652 - Epoch: [95][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.128024    
2025-01-06 21:52:06,967 - Epoch: [95][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.118377    
2025-01-06 21:52:07,299 - Epoch: [95][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.110629    
2025-01-06 21:52:07,619 - Epoch: [95][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.104063    
2025-01-06 21:52:07,939 - Epoch: [95][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.098518    
2025-01-06 21:52:08,259 - Epoch: [95][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.093769    
2025-01-06 21:52:08,601 - Epoch: [95][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.089767    
2025-01-06 21:52:08,924 - Epoch: [95][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086115    
2025-01-06 21:52:09,242 - Epoch: [95][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082916    
2025-01-06 21:52:09,551 - Epoch: [95][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080029    
2025-01-06 21:52:09,860 - Epoch: [95][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077446    
2025-01-06 21:52:10,174 - Epoch: [95][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075140    
2025-01-06 21:52:10,487 - Epoch: [95][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073052    
2025-01-06 21:52:10,793 - Epoch: [95][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071113    
2025-01-06 21:52:11,101 - Epoch: [95][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069353    
2025-01-06 21:52:11,423 - Epoch: [95][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067806    
2025-01-06 21:52:11,745 - Epoch: [95][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066339    
2025-01-06 21:52:12,053 - Epoch: [95][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064972    
2025-01-06 21:52:12,368 - Epoch: [95][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063733    
2025-01-06 21:52:12,669 - Epoch: [95][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062532    
2025-01-06 21:52:13,002 - Epoch: [95][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061524    
2025-01-06 21:52:13,337 - Epoch: [95][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060591    
2025-01-06 21:52:13,658 - Epoch: [95][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059670    
2025-01-06 21:52:13,964 - Epoch: [95][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058760    
2025-01-06 21:52:14,267 - Epoch: [95][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057900    
2025-01-06 21:52:14,620 - Epoch: [95][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.078125    Top5 17.578125    LR 0.001000    Time 0.057235    
2025-01-06 21:52:14,648 - Epoch: [95][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.030227    Top5 13.350126    LR 0.001000    Time 0.057149    
2025-01-06 21:52:16,407 - --- validate (epoch=95)-----------
2025-01-06 21:52:16,407 - 15217 samples (256 per mini-batch)
2025-01-06 21:52:25,693 - Epoch: [95][   10/   60]    Loss 3.044523    Top1 0.195312    Top5 0.390625    
2025-01-06 21:52:25,963 - Epoch: [95][   20/   60]    Loss 3.044523    Top1 0.253906    Top5 0.429687    
2025-01-06 21:52:26,241 - Epoch: [95][   30/   60]    Loss 3.044524    Top1 0.286458    Top5 0.455729    
2025-01-06 21:52:26,505 - Epoch: [95][   40/   60]    Loss 3.044524    Top1 0.244141    Top5 0.390625    
2025-01-06 21:52:26,777 - Epoch: [95][   50/   60]    Loss 3.044524    Top1 0.218750    Top5 0.351563    
2025-01-06 21:52:27,031 - Epoch: [95][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:52:28,497 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:52:28,497 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:52:28,967 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 95]
2025-01-06 21:52:28,977 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:52:29,009 - 

2025-01-06 21:52:29,009 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:52:37,682 - Epoch: [96][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.867165    
2025-01-06 21:52:37,985 - Epoch: [96][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.448756    
2025-01-06 21:52:38,302 - Epoch: [96][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.309737    
2025-01-06 21:52:38,622 - Epoch: [96][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.240308    
2025-01-06 21:52:38,933 - Epoch: [96][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.198465    
2025-01-06 21:52:39,267 - Epoch: [96][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.170946    
2025-01-06 21:52:39,571 - Epoch: [96][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.150864    
2025-01-06 21:52:39,895 - Epoch: [96][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.136057    
2025-01-06 21:52:40,207 - Epoch: [96][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.124408    
2025-01-06 21:52:40,512 - Epoch: [96][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.115010    
2025-01-06 21:52:40,832 - Epoch: [96][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.107446    
2025-01-06 21:52:41,131 - Epoch: [96][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100969    
2025-01-06 21:52:41,472 - Epoch: [96][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.095821    
2025-01-06 21:52:41,779 - Epoch: [96][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091170    
2025-01-06 21:52:42,096 - Epoch: [96][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087207    
2025-01-06 21:52:42,403 - Epoch: [96][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.083673    
2025-01-06 21:52:42,716 - Epoch: [96][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.080535    
2025-01-06 21:52:43,031 - Epoch: [96][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077750    
2025-01-06 21:52:43,351 - Epoch: [96][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075342    
2025-01-06 21:52:43,670 - Epoch: [96][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073174    
2025-01-06 21:52:43,978 - Epoch: [96][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071153    
2025-01-06 21:52:44,304 - Epoch: [96][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069399    
2025-01-06 21:52:44,633 - Epoch: [96][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067816    
2025-01-06 21:52:44,966 - Epoch: [96][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066378    
2025-01-06 21:52:45,281 - Epoch: [96][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064981    
2025-01-06 21:52:45,600 - Epoch: [96][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063708    
2025-01-06 21:52:45,907 - Epoch: [96][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062485    
2025-01-06 21:52:46,240 - Epoch: [96][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061445    
2025-01-06 21:52:46,578 - Epoch: [96][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060490    
2025-01-06 21:52:46,899 - Epoch: [96][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059545    
2025-01-06 21:52:47,216 - Epoch: [96][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058646    
2025-01-06 21:52:47,559 - Epoch: [96][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057885    
2025-01-06 21:52:47,945 - Epoch: [96][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057300    
2025-01-06 21:52:48,374 - Epoch: [96][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.687500    Top5 14.453125    LR 0.001000    Time 0.056876    
2025-01-06 21:52:48,417 - Epoch: [96][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 3.778338    Top5 12.090680    LR 0.001000    Time 0.056837    
2025-01-06 21:52:50,186 - --- validate (epoch=96)-----------
2025-01-06 21:52:50,186 - 15217 samples (256 per mini-batch)
2025-01-06 21:52:59,210 - Epoch: [96][   10/   60]    Loss 3.044523    Top1 0.156250    Top5 0.195312    
2025-01-06 21:52:59,463 - Epoch: [96][   20/   60]    Loss 3.044523    Top1 0.195312    Top5 0.273437    
2025-01-06 21:52:59,725 - Epoch: [96][   30/   60]    Loss 3.044523    Top1 0.182292    Top5 0.247396    
2025-01-06 21:52:59,986 - Epoch: [96][   40/   60]    Loss 3.044523    Top1 0.175781    Top5 0.263672    
2025-01-06 21:53:00,262 - Epoch: [96][   50/   60]    Loss 3.044523    Top1 0.187500    Top5 0.281250    
2025-01-06 21:53:00,497 - Epoch: [96][   60/   60]    Loss 3.044523    Top1 0.197148    Top5 0.315437    
2025-01-06 21:53:02,023 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:53:02,025 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:53:02,490 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 96]
2025-01-06 21:53:02,500 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:53:02,531 - 

2025-01-06 21:53:02,532 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:53:11,293 - Epoch: [97][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.876008    
2025-01-06 21:53:11,599 - Epoch: [97][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.453305    
2025-01-06 21:53:11,929 - Epoch: [97][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.313215    
2025-01-06 21:53:12,249 - Epoch: [97][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.242898    
2025-01-06 21:53:12,563 - Epoch: [97][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.200600    
2025-01-06 21:53:12,888 - Epoch: [97][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.172592    
2025-01-06 21:53:13,202 - Epoch: [97][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.152413    
2025-01-06 21:53:13,524 - Epoch: [97][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.137386    
2025-01-06 21:53:13,851 - Epoch: [97][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.125759    
2025-01-06 21:53:14,157 - Epoch: [97][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.116240    
2025-01-06 21:53:14,462 - Epoch: [97][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.108449    
2025-01-06 21:53:14,772 - Epoch: [97][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.101992    
2025-01-06 21:53:15,077 - Epoch: [97][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.096491    
2025-01-06 21:53:15,393 - Epoch: [97][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.091856    
2025-01-06 21:53:15,712 - Epoch: [97][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087851    
2025-01-06 21:53:16,018 - Epoch: [97][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084268    
2025-01-06 21:53:16,342 - Epoch: [97][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081220    
2025-01-06 21:53:16,649 - Epoch: [97][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078412    
2025-01-06 21:53:16,961 - Epoch: [97][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.075930    
2025-01-06 21:53:17,283 - Epoch: [97][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073692    
2025-01-06 21:53:17,596 - Epoch: [97][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071671    
2025-01-06 21:53:17,900 - Epoch: [97][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.069788    
2025-01-06 21:53:18,221 - Epoch: [97][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068150    
2025-01-06 21:53:18,547 - Epoch: [97][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066668    
2025-01-06 21:53:18,869 - Epoch: [97][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065281    
2025-01-06 21:53:19,183 - Epoch: [97][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063978    
2025-01-06 21:53:19,504 - Epoch: [97][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062797    
2025-01-06 21:53:19,811 - Epoch: [97][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061652    
2025-01-06 21:53:20,130 - Epoch: [97][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060625    
2025-01-06 21:53:20,458 - Epoch: [97][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059697    
2025-01-06 21:53:20,768 - Epoch: [97][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058772    
2025-01-06 21:53:21,082 - Epoch: [97][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057917    
2025-01-06 21:53:21,383 - Epoch: [97][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057072    
2025-01-06 21:53:21,718 - Epoch: [97][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.078125    Top5 12.890625    LR 0.001000    Time 0.056380    
2025-01-06 21:53:21,747 - Epoch: [97][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.037783    Top5 13.602015    LR 0.001000    Time 0.056298    
2025-01-06 21:53:23,522 - --- validate (epoch=97)-----------
2025-01-06 21:53:23,522 - 15217 samples (256 per mini-batch)
2025-01-06 21:53:32,613 - Epoch: [97][   10/   60]    Loss 3.044523    Top1 0.078125    Top5 0.234375    
2025-01-06 21:53:32,870 - Epoch: [97][   20/   60]    Loss 3.044524    Top1 0.156250    Top5 0.273437    
2025-01-06 21:53:33,148 - Epoch: [97][   30/   60]    Loss 3.044523    Top1 0.208333    Top5 0.325521    
2025-01-06 21:53:33,425 - Epoch: [97][   40/   60]    Loss 3.044524    Top1 0.205078    Top5 0.332031    
2025-01-06 21:53:33,686 - Epoch: [97][   50/   60]    Loss 3.044524    Top1 0.203125    Top5 0.343750    
2025-01-06 21:53:33,947 - Epoch: [97][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:53:35,418 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:53:35,418 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:53:35,884 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 97]
2025-01-06 21:53:35,884 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:53:35,923 - 

2025-01-06 21:53:35,924 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:53:44,678 - Epoch: [98][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.875334    
2025-01-06 21:53:45,014 - Epoch: [98][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.454499    
2025-01-06 21:53:45,326 - Epoch: [98][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.313402    
2025-01-06 21:53:45,643 - Epoch: [98][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.242957    
2025-01-06 21:53:45,956 - Epoch: [98][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.200633    
2025-01-06 21:53:46,271 - Epoch: [98][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.172451    
2025-01-06 21:53:46,601 - Epoch: [98][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.152525    
2025-01-06 21:53:46,927 - Epoch: [98][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.137529    
2025-01-06 21:53:47,243 - Epoch: [98][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.125766    
2025-01-06 21:53:47,559 - Epoch: [98][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.116349    
2025-01-06 21:53:47,862 - Epoch: [98][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.108525    
2025-01-06 21:53:48,184 - Epoch: [98][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.102165    
2025-01-06 21:53:48,496 - Epoch: [98][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.096706    
2025-01-06 21:53:48,825 - Epoch: [98][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.092077    
2025-01-06 21:53:49,128 - Epoch: [98][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.087957    
2025-01-06 21:53:49,434 - Epoch: [98][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.084370    
2025-01-06 21:53:49,787 - Epoch: [98][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.081488    
2025-01-06 21:53:50,099 - Epoch: [98][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.078693    
2025-01-06 21:53:50,407 - Epoch: [98][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.076171    
2025-01-06 21:53:50,728 - Epoch: [98][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.073917    
2025-01-06 21:53:51,050 - Epoch: [98][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.071930    
2025-01-06 21:53:51,365 - Epoch: [98][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070094    
2025-01-06 21:53:51,679 - Epoch: [98][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068412    
2025-01-06 21:53:51,994 - Epoch: [98][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.066874    
2025-01-06 21:53:52,298 - Epoch: [98][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065412    
2025-01-06 21:53:52,609 - Epoch: [98][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064094    
2025-01-06 21:53:52,916 - Epoch: [98][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.062856    
2025-01-06 21:53:53,237 - Epoch: [98][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061758    
2025-01-06 21:53:53,545 - Epoch: [98][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060654    
2025-01-06 21:53:53,863 - Epoch: [98][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059695    
2025-01-06 21:53:54,165 - Epoch: [98][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058743    
2025-01-06 21:53:54,475 - Epoch: [98][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057856    
2025-01-06 21:53:54,795 - Epoch: [98][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057073    
2025-01-06 21:53:55,134 - Epoch: [98][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 1.953125    Top5 10.156250    LR 0.001000    Time 0.056391    
2025-01-06 21:53:55,177 - Epoch: [98][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 2.518892    Top5 12.594458    LR 0.001000    Time 0.056322    
2025-01-06 21:53:56,878 - --- validate (epoch=98)-----------
2025-01-06 21:53:56,878 - 15217 samples (256 per mini-batch)
2025-01-06 21:54:05,818 - Epoch: [98][   10/   60]    Loss 3.044524    Top1 0.312500    Top5 0.507813    
2025-01-06 21:54:06,077 - Epoch: [98][   20/   60]    Loss 3.044524    Top1 0.253906    Top5 0.449219    
2025-01-06 21:54:06,331 - Epoch: [98][   30/   60]    Loss 3.044524    Top1 0.221354    Top5 0.364583    
2025-01-06 21:54:06,584 - Epoch: [98][   40/   60]    Loss 3.044524    Top1 0.234375    Top5 0.371094    
2025-01-06 21:54:06,839 - Epoch: [98][   50/   60]    Loss 3.044524    Top1 0.218750    Top5 0.343750    
2025-01-06 21:54:07,076 - Epoch: [98][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:54:08,553 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:54:08,553 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:54:09,234 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 98]
2025-01-06 21:54:09,234 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:54:09,259 - 

2025-01-06 21:54:09,265 - Training epoch: 87181 samples (256 per mini-batch, world size: 1)
2025-01-06 21:54:17,862 - Epoch: [99][   10/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.859718    
2025-01-06 21:54:18,183 - Epoch: [99][   20/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.445106    
2025-01-06 21:54:18,501 - Epoch: [99][   30/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.307295    
2025-01-06 21:54:18,811 - Epoch: [99][   40/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.238204    
2025-01-06 21:54:19,122 - Epoch: [99][   50/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.196779    
2025-01-06 21:54:19,468 - Epoch: [99][   60/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.169749    
2025-01-06 21:54:19,770 - Epoch: [99][   70/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.149817    
2025-01-06 21:54:20,077 - Epoch: [99][   80/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.134928    
2025-01-06 21:54:20,391 - Epoch: [99][   90/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.123419    
2025-01-06 21:54:20,699 - Epoch: [99][  100/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.114138    
2025-01-06 21:54:21,008 - Epoch: [99][  110/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.106570    
2025-01-06 21:54:21,324 - Epoch: [99][  120/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.100323    
2025-01-06 21:54:21,625 - Epoch: [99][  130/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.094924    
2025-01-06 21:54:21,941 - Epoch: [99][  140/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.090400    
2025-01-06 21:54:22,244 - Epoch: [99][  150/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.086392    
2025-01-06 21:54:22,550 - Epoch: [99][  160/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.082906    
2025-01-06 21:54:22,864 - Epoch: [99][  170/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.079874    
2025-01-06 21:54:23,184 - Epoch: [99][  180/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.077210    
2025-01-06 21:54:23,487 - Epoch: [99][  190/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.074734    
2025-01-06 21:54:23,804 - Epoch: [99][  200/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.072582    
2025-01-06 21:54:24,106 - Epoch: [99][  210/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.070562    
2025-01-06 21:54:24,427 - Epoch: [99][  220/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.068813    
2025-01-06 21:54:24,739 - Epoch: [99][  230/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.067178    
2025-01-06 21:54:25,065 - Epoch: [99][  240/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.065721    
2025-01-06 21:54:25,371 - Epoch: [99][  250/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.064308    
2025-01-06 21:54:25,696 - Epoch: [99][  260/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.063062    
2025-01-06 21:54:26,006 - Epoch: [99][  270/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.061869    
2025-01-06 21:54:26,338 - Epoch: [99][  280/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.060847    
2025-01-06 21:54:26,658 - Epoch: [99][  290/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.059851    
2025-01-06 21:54:26,986 - Epoch: [99][  300/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058948    
2025-01-06 21:54:27,299 - Epoch: [99][  310/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.058059    
2025-01-06 21:54:27,619 - Epoch: [99][  320/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.057243    
2025-01-06 21:54:27,932 - Epoch: [99][  330/  341]    Overall Loss 3.044522    Objective Loss 3.044522                                        LR 0.001000    Time 0.056450    
2025-01-06 21:54:28,271 - Epoch: [99][  340/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 5.468750    Top5 13.671875    LR 0.001000    Time 0.055788    
2025-01-06 21:54:28,306 - Epoch: [99][  341/  341]    Overall Loss 3.044522    Objective Loss 3.044522    Top1 4.534005    Top5 13.098237    LR 0.001000    Time 0.055727    
2025-01-06 21:54:30,040 - --- validate (epoch=99)-----------
2025-01-06 21:54:30,040 - 15217 samples (256 per mini-batch)
2025-01-06 21:54:38,695 - Epoch: [99][   10/   60]    Loss 3.044523    Top1 0.351563    Top5 0.546875    
2025-01-06 21:54:38,957 - Epoch: [99][   20/   60]    Loss 3.044523    Top1 0.234375    Top5 0.390625    
2025-01-06 21:54:39,238 - Epoch: [99][   30/   60]    Loss 3.044524    Top1 0.156250    Top5 0.299479    
2025-01-06 21:54:39,499 - Epoch: [99][   40/   60]    Loss 3.044524    Top1 0.224609    Top5 0.341797    
2025-01-06 21:54:39,759 - Epoch: [99][   50/   60]    Loss 3.044524    Top1 0.195312    Top5 0.296875    
2025-01-06 21:54:39,991 - Epoch: [99][   60/   60]    Loss 3.044524    Top1 0.197148    Top5 0.315437    
2025-01-06 21:54:41,528 - ==> Top1: 0.197    Top5: 0.315    Loss: 3.045

2025-01-06 21:54:41,528 - ==> Confusion:
[[  30    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  16    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  11    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1410    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  18    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1403    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1404    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [1453    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [9401    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]]

2025-01-06 21:54:42,002 - ==> Best [Top1: 0.197   Top5: 0.315   Params: 126490 on epoch: 99]
2025-01-06 21:54:42,002 - Saving checkpoint to: logs\2025.01.06-205828\qat_checkpoint.pth.tar
2025-01-06 21:54:42,033 - --- test (ckpt) ---------------------
2025-01-06 21:54:42,034 - 358 samples (256 per mini-batch)
2025-01-06 21:54:50,504 - Test: [    2/    2]    Loss 3.044522    Top1 9.497207    Top5 16.480447    
2025-01-06 21:54:52,010 - ==> Top1: 9.497    Top5: 16.480    Loss: 3.045

2025-01-06 21:54:52,010 - ==> Confusion:
[[ 34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 15   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [129   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2025-01-06 21:54:52,010 - --- test (best) ---------------------
2025-01-06 21:54:52,010 - => loading checkpoint logs\2025.01.06-205828\qat_best.pth.tar
2025-01-06 21:54:52,048 - => Checkpoint contents:
+----------------------+-------------+--------------+
| Key                  | Type        | Value        |
|----------------------+-------------+--------------|
| arch                 | str         | ai85kws20net |
| compression_sched    | dict        |              |
| epoch                | int         | 99           |
| extras               | dict        |              |
| optimizer_state_dict | dict        |              |
| optimizer_type       | type        | Adam         |
| state_dict           | OrderedDict |              |
+----------------------+-------------+--------------+

2025-01-06 21:54:52,049 - => Checkpoint['extras'] contents:
+--------------+--------+-----------+
| Key          | Type   |     Value |
|--------------+--------+-----------|
| best_epoch   | int    | 99        |
| best_mAP     | int    |  0        |
| best_top1    | float  |  0.197148 |
| current_mAP  | int    |  0        |
| current_top1 | float  |  0.197148 |
+--------------+--------+-----------+

2025-01-06 21:54:52,050 - Loaded compression schedule from checkpoint (epoch 99)
2025-01-06 21:54:52,058 - => loaded 'state_dict' from checkpoint 'logs\2025.01.06-205828\qat_best.pth.tar'
2025-01-06 21:54:52,062 - torch.compile() successful, mode=default, cache limit=8
2025-01-06 21:54:52,063 - 358 samples (256 per mini-batch)
2025-01-06 21:55:03,941 - Test: [    2/    2]    Loss 3.044522    Top1 9.497207    Top5 16.480447    
2025-01-06 21:55:05,440 - ==> Top1: 9.497    Top5: 16.480    Loss: 3.045

2025-01-06 21:55:05,440 - ==> Confusion:
[[ 34   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 15   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [ 21   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [129   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]

2025-01-06 21:55:05,662 - 
2025-01-06 21:55:05,672 - Log file for this run: C:\Users\ADMIN\Desktop\AweFiles\ai8x-training\logs\2025.01.06-205828\2025.01.06-205828.log
